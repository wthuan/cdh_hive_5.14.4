From f6be49638db14fd05c0d65ef56aabe0159b472bd Mon Sep 17 00:00:00 2001
From: Vihang Karajgaonkar <vihang@cloudera.com>
Date: Wed, 4 Oct 2017 18:09:47 -0700
Subject: [PATCH 1295/1363] Revert "CDH-59283: HIVE-12730: MetadataUpdater:
 provide a mechanism to edit the basic statistics
 of a table (or a partition) (Pengcheng Xiong,
 reviewed by Ashutosh Chauhan)"

This reverts commit 90974b389c0c06ad36005f8dba8ed6275c442703.

Change-Id: Iead1a065d37f1226fe6d22b71d1e92ecf0785c7f
---
 .../apache/hadoop/hive/common/StatsSetupConst.java |   12 +-
 .../listener/TestDbNotificationListener.java       |    4 +-
 .../hadoop/hive/metastore/TestHiveMetaStore.java   |    6 +-
 .../TestHiveMetaStoreWithEnvironmentContext.java   |    4 +-
 metastore/if/hive_metastore.thrift                 |    1 -
 .../src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp |  985 ++----
 .../src/gen/thrift/gen-cpp/ThriftHiveMetastore.h   |  163 -
 .../ThriftHiveMetastore_server.skeleton.cpp        |    5 -
 .../hive/metastore/api/ThriftHiveMetastore.java    | 3422 ++++++--------------
 .../gen-php/metastore/ThriftHiveMetastore.php      |  655 +---
 .../hive_metastore/ThriftHiveMetastore-remote      |    7 -
 .../gen-py/hive_metastore/ThriftHiveMetastore.py   |  467 +--
 .../src/gen/thrift/gen-rb/thrift_hive_metastore.rb |   69 -
 .../apache/hadoop/hive/metastore/AlterHandler.java |   20 +-
 .../hadoop/hive/metastore/HiveAlterHandler.java    |   53 +-
 .../hadoop/hive/metastore/HiveMetaStore.java       |   39 +-
 .../hadoop/hive/metastore/HiveMetaStoreClient.java |   19 +-
 .../hadoop/hive/metastore/IMetaStoreClient.java    |   12 +-
 .../hadoop/hive/metastore/MetaStoreUtils.java      |   54 +-
 .../metastore/SynchronizedMetaStoreClient.java     |    2 +-
 .../org/apache/hadoop/hive/ql/exec/DDLTask.java    |   50 +-
 .../org/apache/hadoop/hive/ql/exec/MoveTask.java   |    2 +-
 .../apache/hadoop/hive/ql/exec/StatsNoJobTask.java |   12 +-
 .../org/apache/hadoop/hive/ql/exec/StatsTask.java  |   13 +-
 .../hive/ql/hooks/UpdateInputAccessTimeHook.java   |    6 +-
 .../hive/ql/index/IndexMetadataChangeTask.java     |    4 +-
 .../org/apache/hadoop/hive/ql/metadata/Hive.java   |   45 +-
 .../ql/metadata/SessionHiveMetaStoreClient.java    |   19 +-
 .../hadoop/hive/ql/parse/DDLSemanticAnalyzer.java  |   54 +-
 .../org/apache/hadoop/hive/ql/parse/HiveParser.g   |    9 -
 .../hive/ql/parse/SemanticAnalyzerFactory.java     |    3 -
 .../apache/hadoop/hive/ql/plan/AlterTableDesc.java |   16 +-
 .../test/queries/clientnegative/updateBasicStats.q |    5 -
 .../test/queries/clientpositive/updateBasicStats.q |   54 -
 .../results/clientnegative/updateBasicStats.q.out  |   11 -
 .../results/clientpositive/updateBasicStats.q.out  |  375 ---
 36 files changed, 1813 insertions(+), 4864 deletions(-)
 delete mode 100644 ql/src/test/queries/clientnegative/updateBasicStats.q
 delete mode 100644 ql/src/test/queries/clientpositive/updateBasicStats.q
 delete mode 100644 ql/src/test/results/clientnegative/updateBasicStats.q.out
 delete mode 100644 ql/src/test/results/clientpositive/updateBasicStats.q.out

diff --git a/common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java b/common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java
index 5b9b370..88869ac 100644
--- a/common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java
+++ b/common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java
@@ -139,13 +139,9 @@ public String getAggregator(Configuration conf) {
    */
   public static final String[] fastStats = new String[] {NUM_FILES,TOTAL_SIZE};
 
-  // This string constant is used to indicate to AlterHandler that
-  // alterPartition/alterTable is happening via statsTask or via user.
-  public static final String STATS_GENERATED = "STATS_GENERATED";
-
-  public static final String TASK = "TASK";
-
-  public static final String USER = "USER";
+  // This string constant is used by stats task to indicate to AlterHandler that
+  // alterPartition/alterTable is happening via statsTask.
+  public static final String STATS_GENERATED_VIA_STATS_TASK = "STATS_GENERATED_VIA_STATS_TASK";
 
   // This string constant is used by AlterHandler to figure out that it should not attempt to
   // update stats. It is set by any client-side task which wishes to signal that no stats
@@ -160,8 +156,6 @@ public String getAggregator(Configuration conf) {
 
   public static final String BASIC_STATS = "BASIC_STATS";
 
-  public static final String CASCADE = "CASCADE";
-
   public static final String TRUE = "true";
 
   public static final String FALSE = "false";
diff --git a/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java b/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java
index 7643008..7ef8f75 100644
--- a/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java
+++ b/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java
@@ -488,7 +488,7 @@ public void alterPartition() throws Exception {
 
     Partition newPart = new Partition(Arrays.asList("today"), "default", "alterparttable",
         startTime, startTime + 1, sd, emptyParameters);
-    msClient.alter_partition("default", "alterparttable", newPart, null);
+    msClient.alter_partition("default", "alterparttable", newPart);
 
     NotificationEventResponse rsp = msClient.getNextNotification(firstEventId, 0, null);
     assertEquals(3, rsp.getEventsSize());
@@ -509,7 +509,7 @@ public void alterPartition() throws Exception {
 
     DummyRawStoreFailEvent.setEventSucceed(false);
     try {
-      msClient.alter_partition("default", "alterparttable", newPart, null);
+      msClient.alter_partition("default", "alterparttable", newPart);
     } catch (Exception ex) {
       // expected
     }
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
index 80a06c1..ba59776 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
@@ -527,7 +527,7 @@ private static Partition makePartitionObject(String dbName, String tblName,
     part4.setSd(tbl.getSd().deepCopy());
     part4.getSd().setSerdeInfo(tbl.getSd().getSerdeInfo().deepCopy());
     part4.getSd().setLocation(tbl.getSd().getLocation() + ptnLocationSuffix);
-    MetaStoreUtils.updatePartitionStatsFast(part4, warehouse, null);
+    MetaStoreUtils.updatePartitionStatsFast(part4, warehouse);
     return part4;
   }
 
@@ -776,7 +776,7 @@ public void testAlterViewParititon() throws Throwable {
 
     part2.getParameters().put("a", "b");
 
-    client.alter_partition(dbName, viewName, part2, null);
+    client.alter_partition(dbName, viewName, part2);
 
     Partition part3 = client.getPartition(dbName, viewName, part.getValues());
     assertEquals("couldn't view alter partition", part3.getParameters().get(
@@ -863,7 +863,7 @@ public void testAlterPartition() throws Throwable {
       part2.getParameters().put("retention", "10");
       part2.getSd().setNumBuckets(12);
       part2.getSd().getSerdeInfo().getParameters().put("abc", "1");
-      client.alter_partition(dbName, tblName, part2, null);
+      client.alter_partition(dbName, tblName, part2);
 
       Partition part3 = client.getPartition(dbName, tblName, part.getValues());
       assertEquals("couldn't alter partition", part3.getParameters().get(
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java
index cca546e..c0f0d26 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreWithEnvironmentContext.java
@@ -178,7 +178,7 @@ public void testEnvironmentContext() throws Exception {
 
     Log.debug("Renaming table");
     table.setTableName(renamed);
-    msc.alter_table_with_environmentContext(dbName, tblName, table, envContext);
+    msc.alter_table(dbName, tblName, table, envContext);
     listSize++;
     assertEquals(notifyList.size(), listSize);
     AlterTableEvent alterTableEvent = (AlterTableEvent) notifyList.get(listSize-1);
@@ -187,7 +187,7 @@ public void testEnvironmentContext() throws Exception {
 
     Log.debug("Renaming table back");
     table.setTableName(tblName);
-    msc.alter_table_with_environmentContext(dbName, renamed, table, envContext);
+    msc.alter_table(dbName, renamed, table, envContext);
     listSize++;
     assertEquals(notifyList.size(), listSize);
 
diff --git a/metastore/if/hive_metastore.thrift b/metastore/if/hive_metastore.thrift
index ebebb92..ddb93f0 100755
--- a/metastore/if/hive_metastore.thrift
+++ b/metastore/if/hive_metastore.thrift
@@ -998,7 +998,6 @@ service ThriftHiveMetastore extends fb303.FacebookService
   // prehooks are fired together followed by all post hooks
   void alter_partitions(1:string db_name, 2:string tbl_name, 3:list<Partition> new_parts)
                        throws (1:InvalidOperationException o1, 2:MetaException o2)
-  void alter_partitions_with_environment_context(1:string db_name, 2:string tbl_name, 3:list<Partition> new_parts, 4:EnvironmentContext environment_context) throws (1:InvalidOperationException o1, 2:MetaException o2)
 
   void alter_partition_with_environment_context(1:string db_name,
       2:string tbl_name, 3:Partition new_part,
diff --git a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
index 9cfc240..7bde091 100644
--- a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
+++ b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
@@ -15616,264 +15616,6 @@ uint32_t ThriftHiveMetastore_alter_partitions_presult::read(::apache::thrift::pr
   return xfer;
 }
 
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_args::read(::apache::thrift::protocol::TProtocol* iprot) {
-
-  uint32_t xfer = 0;
-  std::string fname;
-  ::apache::thrift::protocol::TType ftype;
-  int16_t fid;
-
-  xfer += iprot->readStructBegin(fname);
-
-  using ::apache::thrift::protocol::TProtocolException;
-
-
-  while (true)
-  {
-    xfer += iprot->readFieldBegin(fname, ftype, fid);
-    if (ftype == ::apache::thrift::protocol::T_STOP) {
-      break;
-    }
-    switch (fid)
-    {
-      case 1:
-        if (ftype == ::apache::thrift::protocol::T_STRING) {
-          xfer += iprot->readString(this->db_name);
-          this->__isset.db_name = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      case 2:
-        if (ftype == ::apache::thrift::protocol::T_STRING) {
-          xfer += iprot->readString(this->tbl_name);
-          this->__isset.tbl_name = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      case 3:
-        if (ftype == ::apache::thrift::protocol::T_LIST) {
-          {
-            this->new_parts.clear();
-            uint32_t _size826;
-            ::apache::thrift::protocol::TType _etype829;
-            xfer += iprot->readListBegin(_etype829, _size826);
-            this->new_parts.resize(_size826);
-            uint32_t _i830;
-            for (_i830 = 0; _i830 < _size826; ++_i830)
-            {
-              xfer += this->new_parts[_i830].read(iprot);
-            }
-            xfer += iprot->readListEnd();
-          }
-          this->__isset.new_parts = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      case 4:
-        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
-          xfer += this->environment_context.read(iprot);
-          this->__isset.environment_context = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      default:
-        xfer += iprot->skip(ftype);
-        break;
-    }
-    xfer += iprot->readFieldEnd();
-  }
-
-  xfer += iprot->readStructEnd();
-
-  return xfer;
-}
-
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_args::write(::apache::thrift::protocol::TProtocol* oprot) const {
-  uint32_t xfer = 0;
-  xfer += oprot->writeStructBegin("ThriftHiveMetastore_alter_partitions_with_environment_context_args");
-
-  xfer += oprot->writeFieldBegin("db_name", ::apache::thrift::protocol::T_STRING, 1);
-  xfer += oprot->writeString(this->db_name);
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("tbl_name", ::apache::thrift::protocol::T_STRING, 2);
-  xfer += oprot->writeString(this->tbl_name);
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("new_parts", ::apache::thrift::protocol::T_LIST, 3);
-  {
-    xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(this->new_parts.size()));
-    std::vector<Partition> ::const_iterator _iter831;
-    for (_iter831 = this->new_parts.begin(); _iter831 != this->new_parts.end(); ++_iter831)
-    {
-      xfer += (*_iter831).write(oprot);
-    }
-    xfer += oprot->writeListEnd();
-  }
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("environment_context", ::apache::thrift::protocol::T_STRUCT, 4);
-  xfer += this->environment_context.write(oprot);
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldStop();
-  xfer += oprot->writeStructEnd();
-  return xfer;
-}
-
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_pargs::write(::apache::thrift::protocol::TProtocol* oprot) const {
-  uint32_t xfer = 0;
-  xfer += oprot->writeStructBegin("ThriftHiveMetastore_alter_partitions_with_environment_context_pargs");
-
-  xfer += oprot->writeFieldBegin("db_name", ::apache::thrift::protocol::T_STRING, 1);
-  xfer += oprot->writeString((*(this->db_name)));
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("tbl_name", ::apache::thrift::protocol::T_STRING, 2);
-  xfer += oprot->writeString((*(this->tbl_name)));
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("new_parts", ::apache::thrift::protocol::T_LIST, 3);
-  {
-    xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>((*(this->new_parts)).size()));
-    std::vector<Partition> ::const_iterator _iter832;
-    for (_iter832 = (*(this->new_parts)).begin(); _iter832 != (*(this->new_parts)).end(); ++_iter832)
-    {
-      xfer += (*_iter832).write(oprot);
-    }
-    xfer += oprot->writeListEnd();
-  }
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldBegin("environment_context", ::apache::thrift::protocol::T_STRUCT, 4);
-  xfer += (*(this->environment_context)).write(oprot);
-  xfer += oprot->writeFieldEnd();
-
-  xfer += oprot->writeFieldStop();
-  xfer += oprot->writeStructEnd();
-  return xfer;
-}
-
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_result::read(::apache::thrift::protocol::TProtocol* iprot) {
-
-  uint32_t xfer = 0;
-  std::string fname;
-  ::apache::thrift::protocol::TType ftype;
-  int16_t fid;
-
-  xfer += iprot->readStructBegin(fname);
-
-  using ::apache::thrift::protocol::TProtocolException;
-
-
-  while (true)
-  {
-    xfer += iprot->readFieldBegin(fname, ftype, fid);
-    if (ftype == ::apache::thrift::protocol::T_STOP) {
-      break;
-    }
-    switch (fid)
-    {
-      case 1:
-        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
-          xfer += this->o1.read(iprot);
-          this->__isset.o1 = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      case 2:
-        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
-          xfer += this->o2.read(iprot);
-          this->__isset.o2 = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      default:
-        xfer += iprot->skip(ftype);
-        break;
-    }
-    xfer += iprot->readFieldEnd();
-  }
-
-  xfer += iprot->readStructEnd();
-
-  return xfer;
-}
-
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_result::write(::apache::thrift::protocol::TProtocol* oprot) const {
-
-  uint32_t xfer = 0;
-
-  xfer += oprot->writeStructBegin("ThriftHiveMetastore_alter_partitions_with_environment_context_result");
-
-  if (this->__isset.o1) {
-    xfer += oprot->writeFieldBegin("o1", ::apache::thrift::protocol::T_STRUCT, 1);
-    xfer += this->o1.write(oprot);
-    xfer += oprot->writeFieldEnd();
-  } else if (this->__isset.o2) {
-    xfer += oprot->writeFieldBegin("o2", ::apache::thrift::protocol::T_STRUCT, 2);
-    xfer += this->o2.write(oprot);
-    xfer += oprot->writeFieldEnd();
-  }
-  xfer += oprot->writeFieldStop();
-  xfer += oprot->writeStructEnd();
-  return xfer;
-}
-
-uint32_t ThriftHiveMetastore_alter_partitions_with_environment_context_presult::read(::apache::thrift::protocol::TProtocol* iprot) {
-
-  uint32_t xfer = 0;
-  std::string fname;
-  ::apache::thrift::protocol::TType ftype;
-  int16_t fid;
-
-  xfer += iprot->readStructBegin(fname);
-
-  using ::apache::thrift::protocol::TProtocolException;
-
-
-  while (true)
-  {
-    xfer += iprot->readFieldBegin(fname, ftype, fid);
-    if (ftype == ::apache::thrift::protocol::T_STOP) {
-      break;
-    }
-    switch (fid)
-    {
-      case 1:
-        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
-          xfer += this->o1.read(iprot);
-          this->__isset.o1 = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      case 2:
-        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
-          xfer += this->o2.read(iprot);
-          this->__isset.o2 = true;
-        } else {
-          xfer += iprot->skip(ftype);
-        }
-        break;
-      default:
-        xfer += iprot->skip(ftype);
-        break;
-    }
-    xfer += iprot->readFieldEnd();
-  }
-
-  xfer += iprot->readStructEnd();
-
-  return xfer;
-}
-
 uint32_t ThriftHiveMetastore_alter_partition_with_environment_context_args::read(::apache::thrift::protocol::TProtocol* iprot) {
 
   uint32_t xfer = 0;
@@ -16144,14 +15886,14 @@ uint32_t ThriftHiveMetastore_rename_partition_args::read(::apache::thrift::proto
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->part_vals.clear();
-            uint32_t _size833;
-            ::apache::thrift::protocol::TType _etype836;
-            xfer += iprot->readListBegin(_etype836, _size833);
-            this->part_vals.resize(_size833);
-            uint32_t _i837;
-            for (_i837 = 0; _i837 < _size833; ++_i837)
+            uint32_t _size826;
+            ::apache::thrift::protocol::TType _etype829;
+            xfer += iprot->readListBegin(_etype829, _size826);
+            this->part_vals.resize(_size826);
+            uint32_t _i830;
+            for (_i830 = 0; _i830 < _size826; ++_i830)
             {
-              xfer += iprot->readString(this->part_vals[_i837]);
+              xfer += iprot->readString(this->part_vals[_i830]);
             }
             xfer += iprot->readListEnd();
           }
@@ -16195,10 +15937,10 @@ uint32_t ThriftHiveMetastore_rename_partition_args::write(::apache::thrift::prot
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_LIST, 3);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->part_vals.size()));
-    std::vector<std::string> ::const_iterator _iter838;
-    for (_iter838 = this->part_vals.begin(); _iter838 != this->part_vals.end(); ++_iter838)
+    std::vector<std::string> ::const_iterator _iter831;
+    for (_iter831 = this->part_vals.begin(); _iter831 != this->part_vals.end(); ++_iter831)
     {
-      xfer += oprot->writeString((*_iter838));
+      xfer += oprot->writeString((*_iter831));
     }
     xfer += oprot->writeListEnd();
   }
@@ -16228,10 +15970,10 @@ uint32_t ThriftHiveMetastore_rename_partition_pargs::write(::apache::thrift::pro
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_LIST, 3);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->part_vals)).size()));
-    std::vector<std::string> ::const_iterator _iter839;
-    for (_iter839 = (*(this->part_vals)).begin(); _iter839 != (*(this->part_vals)).end(); ++_iter839)
+    std::vector<std::string> ::const_iterator _iter832;
+    for (_iter832 = (*(this->part_vals)).begin(); _iter832 != (*(this->part_vals)).end(); ++_iter832)
     {
-      xfer += oprot->writeString((*_iter839));
+      xfer += oprot->writeString((*_iter832));
     }
     xfer += oprot->writeListEnd();
   }
@@ -16386,14 +16128,14 @@ uint32_t ThriftHiveMetastore_partition_name_has_valid_characters_args::read(::ap
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->part_vals.clear();
-            uint32_t _size840;
-            ::apache::thrift::protocol::TType _etype843;
-            xfer += iprot->readListBegin(_etype843, _size840);
-            this->part_vals.resize(_size840);
-            uint32_t _i844;
-            for (_i844 = 0; _i844 < _size840; ++_i844)
+            uint32_t _size833;
+            ::apache::thrift::protocol::TType _etype836;
+            xfer += iprot->readListBegin(_etype836, _size833);
+            this->part_vals.resize(_size833);
+            uint32_t _i837;
+            for (_i837 = 0; _i837 < _size833; ++_i837)
             {
-              xfer += iprot->readString(this->part_vals[_i844]);
+              xfer += iprot->readString(this->part_vals[_i837]);
             }
             xfer += iprot->readListEnd();
           }
@@ -16429,10 +16171,10 @@ uint32_t ThriftHiveMetastore_partition_name_has_valid_characters_args::write(::a
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_LIST, 1);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->part_vals.size()));
-    std::vector<std::string> ::const_iterator _iter845;
-    for (_iter845 = this->part_vals.begin(); _iter845 != this->part_vals.end(); ++_iter845)
+    std::vector<std::string> ::const_iterator _iter838;
+    for (_iter838 = this->part_vals.begin(); _iter838 != this->part_vals.end(); ++_iter838)
     {
-      xfer += oprot->writeString((*_iter845));
+      xfer += oprot->writeString((*_iter838));
     }
     xfer += oprot->writeListEnd();
   }
@@ -16454,10 +16196,10 @@ uint32_t ThriftHiveMetastore_partition_name_has_valid_characters_pargs::write(::
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_LIST, 1);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->part_vals)).size()));
-    std::vector<std::string> ::const_iterator _iter846;
-    for (_iter846 = (*(this->part_vals)).begin(); _iter846 != (*(this->part_vals)).end(); ++_iter846)
+    std::vector<std::string> ::const_iterator _iter839;
+    for (_iter839 = (*(this->part_vals)).begin(); _iter839 != (*(this->part_vals)).end(); ++_iter839)
     {
-      xfer += oprot->writeString((*_iter846));
+      xfer += oprot->writeString((*_iter839));
     }
     xfer += oprot->writeListEnd();
   }
@@ -16876,14 +16618,14 @@ uint32_t ThriftHiveMetastore_partition_name_to_vals_result::read(::apache::thrif
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size847;
-            ::apache::thrift::protocol::TType _etype850;
-            xfer += iprot->readListBegin(_etype850, _size847);
-            this->success.resize(_size847);
-            uint32_t _i851;
-            for (_i851 = 0; _i851 < _size847; ++_i851)
+            uint32_t _size840;
+            ::apache::thrift::protocol::TType _etype843;
+            xfer += iprot->readListBegin(_etype843, _size840);
+            this->success.resize(_size840);
+            uint32_t _i844;
+            for (_i844 = 0; _i844 < _size840; ++_i844)
             {
-              xfer += iprot->readString(this->success[_i851]);
+              xfer += iprot->readString(this->success[_i844]);
             }
             xfer += iprot->readListEnd();
           }
@@ -16922,10 +16664,10 @@ uint32_t ThriftHiveMetastore_partition_name_to_vals_result::write(::apache::thri
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter852;
-      for (_iter852 = this->success.begin(); _iter852 != this->success.end(); ++_iter852)
+      std::vector<std::string> ::const_iterator _iter845;
+      for (_iter845 = this->success.begin(); _iter845 != this->success.end(); ++_iter845)
       {
-        xfer += oprot->writeString((*_iter852));
+        xfer += oprot->writeString((*_iter845));
       }
       xfer += oprot->writeListEnd();
     }
@@ -16964,14 +16706,14 @@ uint32_t ThriftHiveMetastore_partition_name_to_vals_presult::read(::apache::thri
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size853;
-            ::apache::thrift::protocol::TType _etype856;
-            xfer += iprot->readListBegin(_etype856, _size853);
-            (*(this->success)).resize(_size853);
-            uint32_t _i857;
-            for (_i857 = 0; _i857 < _size853; ++_i857)
+            uint32_t _size846;
+            ::apache::thrift::protocol::TType _etype849;
+            xfer += iprot->readListBegin(_etype849, _size846);
+            (*(this->success)).resize(_size846);
+            uint32_t _i850;
+            for (_i850 = 0; _i850 < _size846; ++_i850)
             {
-              xfer += iprot->readString((*(this->success))[_i857]);
+              xfer += iprot->readString((*(this->success))[_i850]);
             }
             xfer += iprot->readListEnd();
           }
@@ -17090,17 +16832,17 @@ uint32_t ThriftHiveMetastore_partition_name_to_spec_result::read(::apache::thrif
         if (ftype == ::apache::thrift::protocol::T_MAP) {
           {
             this->success.clear();
-            uint32_t _size858;
-            ::apache::thrift::protocol::TType _ktype859;
-            ::apache::thrift::protocol::TType _vtype860;
-            xfer += iprot->readMapBegin(_ktype859, _vtype860, _size858);
-            uint32_t _i862;
-            for (_i862 = 0; _i862 < _size858; ++_i862)
+            uint32_t _size851;
+            ::apache::thrift::protocol::TType _ktype852;
+            ::apache::thrift::protocol::TType _vtype853;
+            xfer += iprot->readMapBegin(_ktype852, _vtype853, _size851);
+            uint32_t _i855;
+            for (_i855 = 0; _i855 < _size851; ++_i855)
             {
-              std::string _key863;
-              xfer += iprot->readString(_key863);
-              std::string& _val864 = this->success[_key863];
-              xfer += iprot->readString(_val864);
+              std::string _key856;
+              xfer += iprot->readString(_key856);
+              std::string& _val857 = this->success[_key856];
+              xfer += iprot->readString(_val857);
             }
             xfer += iprot->readMapEnd();
           }
@@ -17139,11 +16881,11 @@ uint32_t ThriftHiveMetastore_partition_name_to_spec_result::write(::apache::thri
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_MAP, 0);
     {
       xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::map<std::string, std::string> ::const_iterator _iter865;
-      for (_iter865 = this->success.begin(); _iter865 != this->success.end(); ++_iter865)
+      std::map<std::string, std::string> ::const_iterator _iter858;
+      for (_iter858 = this->success.begin(); _iter858 != this->success.end(); ++_iter858)
       {
-        xfer += oprot->writeString(_iter865->first);
-        xfer += oprot->writeString(_iter865->second);
+        xfer += oprot->writeString(_iter858->first);
+        xfer += oprot->writeString(_iter858->second);
       }
       xfer += oprot->writeMapEnd();
     }
@@ -17182,17 +16924,17 @@ uint32_t ThriftHiveMetastore_partition_name_to_spec_presult::read(::apache::thri
         if (ftype == ::apache::thrift::protocol::T_MAP) {
           {
             (*(this->success)).clear();
-            uint32_t _size866;
-            ::apache::thrift::protocol::TType _ktype867;
-            ::apache::thrift::protocol::TType _vtype868;
-            xfer += iprot->readMapBegin(_ktype867, _vtype868, _size866);
-            uint32_t _i870;
-            for (_i870 = 0; _i870 < _size866; ++_i870)
+            uint32_t _size859;
+            ::apache::thrift::protocol::TType _ktype860;
+            ::apache::thrift::protocol::TType _vtype861;
+            xfer += iprot->readMapBegin(_ktype860, _vtype861, _size859);
+            uint32_t _i863;
+            for (_i863 = 0; _i863 < _size859; ++_i863)
             {
-              std::string _key871;
-              xfer += iprot->readString(_key871);
-              std::string& _val872 = (*(this->success))[_key871];
-              xfer += iprot->readString(_val872);
+              std::string _key864;
+              xfer += iprot->readString(_key864);
+              std::string& _val865 = (*(this->success))[_key864];
+              xfer += iprot->readString(_val865);
             }
             xfer += iprot->readMapEnd();
           }
@@ -17261,17 +17003,17 @@ uint32_t ThriftHiveMetastore_markPartitionForEvent_args::read(::apache::thrift::
         if (ftype == ::apache::thrift::protocol::T_MAP) {
           {
             this->part_vals.clear();
-            uint32_t _size873;
-            ::apache::thrift::protocol::TType _ktype874;
-            ::apache::thrift::protocol::TType _vtype875;
-            xfer += iprot->readMapBegin(_ktype874, _vtype875, _size873);
-            uint32_t _i877;
-            for (_i877 = 0; _i877 < _size873; ++_i877)
+            uint32_t _size866;
+            ::apache::thrift::protocol::TType _ktype867;
+            ::apache::thrift::protocol::TType _vtype868;
+            xfer += iprot->readMapBegin(_ktype867, _vtype868, _size866);
+            uint32_t _i870;
+            for (_i870 = 0; _i870 < _size866; ++_i870)
             {
-              std::string _key878;
-              xfer += iprot->readString(_key878);
-              std::string& _val879 = this->part_vals[_key878];
-              xfer += iprot->readString(_val879);
+              std::string _key871;
+              xfer += iprot->readString(_key871);
+              std::string& _val872 = this->part_vals[_key871];
+              xfer += iprot->readString(_val872);
             }
             xfer += iprot->readMapEnd();
           }
@@ -17282,9 +17024,9 @@ uint32_t ThriftHiveMetastore_markPartitionForEvent_args::read(::apache::thrift::
         break;
       case 4:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast880;
-          xfer += iprot->readI32(ecast880);
-          this->eventType = (PartitionEventType::type)ecast880;
+          int32_t ecast873;
+          xfer += iprot->readI32(ecast873);
+          this->eventType = (PartitionEventType::type)ecast873;
           this->__isset.eventType = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -17317,11 +17059,11 @@ uint32_t ThriftHiveMetastore_markPartitionForEvent_args::write(::apache::thrift:
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_MAP, 3);
   {
     xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->part_vals.size()));
-    std::map<std::string, std::string> ::const_iterator _iter881;
-    for (_iter881 = this->part_vals.begin(); _iter881 != this->part_vals.end(); ++_iter881)
+    std::map<std::string, std::string> ::const_iterator _iter874;
+    for (_iter874 = this->part_vals.begin(); _iter874 != this->part_vals.end(); ++_iter874)
     {
-      xfer += oprot->writeString(_iter881->first);
-      xfer += oprot->writeString(_iter881->second);
+      xfer += oprot->writeString(_iter874->first);
+      xfer += oprot->writeString(_iter874->second);
     }
     xfer += oprot->writeMapEnd();
   }
@@ -17351,11 +17093,11 @@ uint32_t ThriftHiveMetastore_markPartitionForEvent_pargs::write(::apache::thrift
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_MAP, 3);
   {
     xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->part_vals)).size()));
-    std::map<std::string, std::string> ::const_iterator _iter882;
-    for (_iter882 = (*(this->part_vals)).begin(); _iter882 != (*(this->part_vals)).end(); ++_iter882)
+    std::map<std::string, std::string> ::const_iterator _iter875;
+    for (_iter875 = (*(this->part_vals)).begin(); _iter875 != (*(this->part_vals)).end(); ++_iter875)
     {
-      xfer += oprot->writeString(_iter882->first);
-      xfer += oprot->writeString(_iter882->second);
+      xfer += oprot->writeString(_iter875->first);
+      xfer += oprot->writeString(_iter875->second);
     }
     xfer += oprot->writeMapEnd();
   }
@@ -17606,17 +17348,17 @@ uint32_t ThriftHiveMetastore_isPartitionMarkedForEvent_args::read(::apache::thri
         if (ftype == ::apache::thrift::protocol::T_MAP) {
           {
             this->part_vals.clear();
-            uint32_t _size883;
-            ::apache::thrift::protocol::TType _ktype884;
-            ::apache::thrift::protocol::TType _vtype885;
-            xfer += iprot->readMapBegin(_ktype884, _vtype885, _size883);
-            uint32_t _i887;
-            for (_i887 = 0; _i887 < _size883; ++_i887)
+            uint32_t _size876;
+            ::apache::thrift::protocol::TType _ktype877;
+            ::apache::thrift::protocol::TType _vtype878;
+            xfer += iprot->readMapBegin(_ktype877, _vtype878, _size876);
+            uint32_t _i880;
+            for (_i880 = 0; _i880 < _size876; ++_i880)
             {
-              std::string _key888;
-              xfer += iprot->readString(_key888);
-              std::string& _val889 = this->part_vals[_key888];
-              xfer += iprot->readString(_val889);
+              std::string _key881;
+              xfer += iprot->readString(_key881);
+              std::string& _val882 = this->part_vals[_key881];
+              xfer += iprot->readString(_val882);
             }
             xfer += iprot->readMapEnd();
           }
@@ -17627,9 +17369,9 @@ uint32_t ThriftHiveMetastore_isPartitionMarkedForEvent_args::read(::apache::thri
         break;
       case 4:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast890;
-          xfer += iprot->readI32(ecast890);
-          this->eventType = (PartitionEventType::type)ecast890;
+          int32_t ecast883;
+          xfer += iprot->readI32(ecast883);
+          this->eventType = (PartitionEventType::type)ecast883;
           this->__isset.eventType = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -17662,11 +17404,11 @@ uint32_t ThriftHiveMetastore_isPartitionMarkedForEvent_args::write(::apache::thr
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_MAP, 3);
   {
     xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->part_vals.size()));
-    std::map<std::string, std::string> ::const_iterator _iter891;
-    for (_iter891 = this->part_vals.begin(); _iter891 != this->part_vals.end(); ++_iter891)
+    std::map<std::string, std::string> ::const_iterator _iter884;
+    for (_iter884 = this->part_vals.begin(); _iter884 != this->part_vals.end(); ++_iter884)
     {
-      xfer += oprot->writeString(_iter891->first);
-      xfer += oprot->writeString(_iter891->second);
+      xfer += oprot->writeString(_iter884->first);
+      xfer += oprot->writeString(_iter884->second);
     }
     xfer += oprot->writeMapEnd();
   }
@@ -17696,11 +17438,11 @@ uint32_t ThriftHiveMetastore_isPartitionMarkedForEvent_pargs::write(::apache::th
   xfer += oprot->writeFieldBegin("part_vals", ::apache::thrift::protocol::T_MAP, 3);
   {
     xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->part_vals)).size()));
-    std::map<std::string, std::string> ::const_iterator _iter892;
-    for (_iter892 = (*(this->part_vals)).begin(); _iter892 != (*(this->part_vals)).end(); ++_iter892)
+    std::map<std::string, std::string> ::const_iterator _iter885;
+    for (_iter885 = (*(this->part_vals)).begin(); _iter885 != (*(this->part_vals)).end(); ++_iter885)
     {
-      xfer += oprot->writeString(_iter892->first);
-      xfer += oprot->writeString(_iter892->second);
+      xfer += oprot->writeString(_iter885->first);
+      xfer += oprot->writeString(_iter885->second);
     }
     xfer += oprot->writeMapEnd();
   }
@@ -19005,14 +18747,14 @@ uint32_t ThriftHiveMetastore_get_indexes_result::read(::apache::thrift::protocol
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size893;
-            ::apache::thrift::protocol::TType _etype896;
-            xfer += iprot->readListBegin(_etype896, _size893);
-            this->success.resize(_size893);
-            uint32_t _i897;
-            for (_i897 = 0; _i897 < _size893; ++_i897)
+            uint32_t _size886;
+            ::apache::thrift::protocol::TType _etype889;
+            xfer += iprot->readListBegin(_etype889, _size886);
+            this->success.resize(_size886);
+            uint32_t _i890;
+            for (_i890 = 0; _i890 < _size886; ++_i890)
             {
-              xfer += this->success[_i897].read(iprot);
+              xfer += this->success[_i890].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -19059,10 +18801,10 @@ uint32_t ThriftHiveMetastore_get_indexes_result::write(::apache::thrift::protoco
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(this->success.size()));
-      std::vector<Index> ::const_iterator _iter898;
-      for (_iter898 = this->success.begin(); _iter898 != this->success.end(); ++_iter898)
+      std::vector<Index> ::const_iterator _iter891;
+      for (_iter891 = this->success.begin(); _iter891 != this->success.end(); ++_iter891)
       {
-        xfer += (*_iter898).write(oprot);
+        xfer += (*_iter891).write(oprot);
       }
       xfer += oprot->writeListEnd();
     }
@@ -19105,14 +18847,14 @@ uint32_t ThriftHiveMetastore_get_indexes_presult::read(::apache::thrift::protoco
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size899;
-            ::apache::thrift::protocol::TType _etype902;
-            xfer += iprot->readListBegin(_etype902, _size899);
-            (*(this->success)).resize(_size899);
-            uint32_t _i903;
-            for (_i903 = 0; _i903 < _size899; ++_i903)
+            uint32_t _size892;
+            ::apache::thrift::protocol::TType _etype895;
+            xfer += iprot->readListBegin(_etype895, _size892);
+            (*(this->success)).resize(_size892);
+            uint32_t _i896;
+            for (_i896 = 0; _i896 < _size892; ++_i896)
             {
-              xfer += (*(this->success))[_i903].read(iprot);
+              xfer += (*(this->success))[_i896].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -19271,14 +19013,14 @@ uint32_t ThriftHiveMetastore_get_index_names_result::read(::apache::thrift::prot
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size904;
-            ::apache::thrift::protocol::TType _etype907;
-            xfer += iprot->readListBegin(_etype907, _size904);
-            this->success.resize(_size904);
-            uint32_t _i908;
-            for (_i908 = 0; _i908 < _size904; ++_i908)
+            uint32_t _size897;
+            ::apache::thrift::protocol::TType _etype900;
+            xfer += iprot->readListBegin(_etype900, _size897);
+            this->success.resize(_size897);
+            uint32_t _i901;
+            for (_i901 = 0; _i901 < _size897; ++_i901)
             {
-              xfer += iprot->readString(this->success[_i908]);
+              xfer += iprot->readString(this->success[_i901]);
             }
             xfer += iprot->readListEnd();
           }
@@ -19317,10 +19059,10 @@ uint32_t ThriftHiveMetastore_get_index_names_result::write(::apache::thrift::pro
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter909;
-      for (_iter909 = this->success.begin(); _iter909 != this->success.end(); ++_iter909)
+      std::vector<std::string> ::const_iterator _iter902;
+      for (_iter902 = this->success.begin(); _iter902 != this->success.end(); ++_iter902)
       {
-        xfer += oprot->writeString((*_iter909));
+        xfer += oprot->writeString((*_iter902));
       }
       xfer += oprot->writeListEnd();
     }
@@ -19359,14 +19101,14 @@ uint32_t ThriftHiveMetastore_get_index_names_presult::read(::apache::thrift::pro
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size910;
-            ::apache::thrift::protocol::TType _etype913;
-            xfer += iprot->readListBegin(_etype913, _size910);
-            (*(this->success)).resize(_size910);
-            uint32_t _i914;
-            for (_i914 = 0; _i914 < _size910; ++_i914)
+            uint32_t _size903;
+            ::apache::thrift::protocol::TType _etype906;
+            xfer += iprot->readListBegin(_etype906, _size903);
+            (*(this->success)).resize(_size903);
+            uint32_t _i907;
+            for (_i907 = 0; _i907 < _size903; ++_i907)
             {
-              xfer += iprot->readString((*(this->success))[_i914]);
+              xfer += iprot->readString((*(this->success))[_i907]);
             }
             xfer += iprot->readListEnd();
           }
@@ -22595,14 +22337,14 @@ uint32_t ThriftHiveMetastore_get_functions_result::read(::apache::thrift::protoc
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size915;
-            ::apache::thrift::protocol::TType _etype918;
-            xfer += iprot->readListBegin(_etype918, _size915);
-            this->success.resize(_size915);
-            uint32_t _i919;
-            for (_i919 = 0; _i919 < _size915; ++_i919)
+            uint32_t _size908;
+            ::apache::thrift::protocol::TType _etype911;
+            xfer += iprot->readListBegin(_etype911, _size908);
+            this->success.resize(_size908);
+            uint32_t _i912;
+            for (_i912 = 0; _i912 < _size908; ++_i912)
             {
-              xfer += iprot->readString(this->success[_i919]);
+              xfer += iprot->readString(this->success[_i912]);
             }
             xfer += iprot->readListEnd();
           }
@@ -22641,10 +22383,10 @@ uint32_t ThriftHiveMetastore_get_functions_result::write(::apache::thrift::proto
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter920;
-      for (_iter920 = this->success.begin(); _iter920 != this->success.end(); ++_iter920)
+      std::vector<std::string> ::const_iterator _iter913;
+      for (_iter913 = this->success.begin(); _iter913 != this->success.end(); ++_iter913)
       {
-        xfer += oprot->writeString((*_iter920));
+        xfer += oprot->writeString((*_iter913));
       }
       xfer += oprot->writeListEnd();
     }
@@ -22683,14 +22425,14 @@ uint32_t ThriftHiveMetastore_get_functions_presult::read(::apache::thrift::proto
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size921;
-            ::apache::thrift::protocol::TType _etype924;
-            xfer += iprot->readListBegin(_etype924, _size921);
-            (*(this->success)).resize(_size921);
-            uint32_t _i925;
-            for (_i925 = 0; _i925 < _size921; ++_i925)
+            uint32_t _size914;
+            ::apache::thrift::protocol::TType _etype917;
+            xfer += iprot->readListBegin(_etype917, _size914);
+            (*(this->success)).resize(_size914);
+            uint32_t _i918;
+            for (_i918 = 0; _i918 < _size914; ++_i918)
             {
-              xfer += iprot->readString((*(this->success))[_i925]);
+              xfer += iprot->readString((*(this->success))[_i918]);
             }
             xfer += iprot->readListEnd();
           }
@@ -23531,14 +23273,14 @@ uint32_t ThriftHiveMetastore_get_role_names_result::read(::apache::thrift::proto
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size926;
-            ::apache::thrift::protocol::TType _etype929;
-            xfer += iprot->readListBegin(_etype929, _size926);
-            this->success.resize(_size926);
-            uint32_t _i930;
-            for (_i930 = 0; _i930 < _size926; ++_i930)
+            uint32_t _size919;
+            ::apache::thrift::protocol::TType _etype922;
+            xfer += iprot->readListBegin(_etype922, _size919);
+            this->success.resize(_size919);
+            uint32_t _i923;
+            for (_i923 = 0; _i923 < _size919; ++_i923)
             {
-              xfer += iprot->readString(this->success[_i930]);
+              xfer += iprot->readString(this->success[_i923]);
             }
             xfer += iprot->readListEnd();
           }
@@ -23577,10 +23319,10 @@ uint32_t ThriftHiveMetastore_get_role_names_result::write(::apache::thrift::prot
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter931;
-      for (_iter931 = this->success.begin(); _iter931 != this->success.end(); ++_iter931)
+      std::vector<std::string> ::const_iterator _iter924;
+      for (_iter924 = this->success.begin(); _iter924 != this->success.end(); ++_iter924)
       {
-        xfer += oprot->writeString((*_iter931));
+        xfer += oprot->writeString((*_iter924));
       }
       xfer += oprot->writeListEnd();
     }
@@ -23619,14 +23361,14 @@ uint32_t ThriftHiveMetastore_get_role_names_presult::read(::apache::thrift::prot
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size932;
-            ::apache::thrift::protocol::TType _etype935;
-            xfer += iprot->readListBegin(_etype935, _size932);
-            (*(this->success)).resize(_size932);
-            uint32_t _i936;
-            for (_i936 = 0; _i936 < _size932; ++_i936)
+            uint32_t _size925;
+            ::apache::thrift::protocol::TType _etype928;
+            xfer += iprot->readListBegin(_etype928, _size925);
+            (*(this->success)).resize(_size925);
+            uint32_t _i929;
+            for (_i929 = 0; _i929 < _size925; ++_i929)
             {
-              xfer += iprot->readString((*(this->success))[_i936]);
+              xfer += iprot->readString((*(this->success))[_i929]);
             }
             xfer += iprot->readListEnd();
           }
@@ -23693,9 +23435,9 @@ uint32_t ThriftHiveMetastore_grant_role_args::read(::apache::thrift::protocol::T
         break;
       case 3:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast937;
-          xfer += iprot->readI32(ecast937);
-          this->principal_type = (PrincipalType::type)ecast937;
+          int32_t ecast930;
+          xfer += iprot->readI32(ecast930);
+          this->principal_type = (PrincipalType::type)ecast930;
           this->__isset.principal_type = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -23711,9 +23453,9 @@ uint32_t ThriftHiveMetastore_grant_role_args::read(::apache::thrift::protocol::T
         break;
       case 5:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast938;
-          xfer += iprot->readI32(ecast938);
-          this->grantorType = (PrincipalType::type)ecast938;
+          int32_t ecast931;
+          xfer += iprot->readI32(ecast931);
+          this->grantorType = (PrincipalType::type)ecast931;
           this->__isset.grantorType = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -23959,9 +23701,9 @@ uint32_t ThriftHiveMetastore_revoke_role_args::read(::apache::thrift::protocol::
         break;
       case 3:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast939;
-          xfer += iprot->readI32(ecast939);
-          this->principal_type = (PrincipalType::type)ecast939;
+          int32_t ecast932;
+          xfer += iprot->readI32(ecast932);
+          this->principal_type = (PrincipalType::type)ecast932;
           this->__isset.principal_type = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -24167,9 +23909,9 @@ uint32_t ThriftHiveMetastore_list_roles_args::read(::apache::thrift::protocol::T
         break;
       case 2:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast940;
-          xfer += iprot->readI32(ecast940);
-          this->principal_type = (PrincipalType::type)ecast940;
+          int32_t ecast933;
+          xfer += iprot->readI32(ecast933);
+          this->principal_type = (PrincipalType::type)ecast933;
           this->__isset.principal_type = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -24245,14 +23987,14 @@ uint32_t ThriftHiveMetastore_list_roles_result::read(::apache::thrift::protocol:
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size941;
-            ::apache::thrift::protocol::TType _etype944;
-            xfer += iprot->readListBegin(_etype944, _size941);
-            this->success.resize(_size941);
-            uint32_t _i945;
-            for (_i945 = 0; _i945 < _size941; ++_i945)
+            uint32_t _size934;
+            ::apache::thrift::protocol::TType _etype937;
+            xfer += iprot->readListBegin(_etype937, _size934);
+            this->success.resize(_size934);
+            uint32_t _i938;
+            for (_i938 = 0; _i938 < _size934; ++_i938)
             {
-              xfer += this->success[_i945].read(iprot);
+              xfer += this->success[_i938].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -24291,10 +24033,10 @@ uint32_t ThriftHiveMetastore_list_roles_result::write(::apache::thrift::protocol
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(this->success.size()));
-      std::vector<Role> ::const_iterator _iter946;
-      for (_iter946 = this->success.begin(); _iter946 != this->success.end(); ++_iter946)
+      std::vector<Role> ::const_iterator _iter939;
+      for (_iter939 = this->success.begin(); _iter939 != this->success.end(); ++_iter939)
       {
-        xfer += (*_iter946).write(oprot);
+        xfer += (*_iter939).write(oprot);
       }
       xfer += oprot->writeListEnd();
     }
@@ -24333,14 +24075,14 @@ uint32_t ThriftHiveMetastore_list_roles_presult::read(::apache::thrift::protocol
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size947;
-            ::apache::thrift::protocol::TType _etype950;
-            xfer += iprot->readListBegin(_etype950, _size947);
-            (*(this->success)).resize(_size947);
-            uint32_t _i951;
-            for (_i951 = 0; _i951 < _size947; ++_i951)
+            uint32_t _size940;
+            ::apache::thrift::protocol::TType _etype943;
+            xfer += iprot->readListBegin(_etype943, _size940);
+            (*(this->success)).resize(_size940);
+            uint32_t _i944;
+            for (_i944 = 0; _i944 < _size940; ++_i944)
             {
-              xfer += (*(this->success))[_i951].read(iprot);
+              xfer += (*(this->success))[_i944].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -24955,14 +24697,14 @@ uint32_t ThriftHiveMetastore_get_privilege_set_args::read(::apache::thrift::prot
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->group_names.clear();
-            uint32_t _size952;
-            ::apache::thrift::protocol::TType _etype955;
-            xfer += iprot->readListBegin(_etype955, _size952);
-            this->group_names.resize(_size952);
-            uint32_t _i956;
-            for (_i956 = 0; _i956 < _size952; ++_i956)
+            uint32_t _size945;
+            ::apache::thrift::protocol::TType _etype948;
+            xfer += iprot->readListBegin(_etype948, _size945);
+            this->group_names.resize(_size945);
+            uint32_t _i949;
+            for (_i949 = 0; _i949 < _size945; ++_i949)
             {
-              xfer += iprot->readString(this->group_names[_i956]);
+              xfer += iprot->readString(this->group_names[_i949]);
             }
             xfer += iprot->readListEnd();
           }
@@ -24998,10 +24740,10 @@ uint32_t ThriftHiveMetastore_get_privilege_set_args::write(::apache::thrift::pro
   xfer += oprot->writeFieldBegin("group_names", ::apache::thrift::protocol::T_LIST, 3);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->group_names.size()));
-    std::vector<std::string> ::const_iterator _iter957;
-    for (_iter957 = this->group_names.begin(); _iter957 != this->group_names.end(); ++_iter957)
+    std::vector<std::string> ::const_iterator _iter950;
+    for (_iter950 = this->group_names.begin(); _iter950 != this->group_names.end(); ++_iter950)
     {
-      xfer += oprot->writeString((*_iter957));
+      xfer += oprot->writeString((*_iter950));
     }
     xfer += oprot->writeListEnd();
   }
@@ -25027,10 +24769,10 @@ uint32_t ThriftHiveMetastore_get_privilege_set_pargs::write(::apache::thrift::pr
   xfer += oprot->writeFieldBegin("group_names", ::apache::thrift::protocol::T_LIST, 3);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->group_names)).size()));
-    std::vector<std::string> ::const_iterator _iter958;
-    for (_iter958 = (*(this->group_names)).begin(); _iter958 != (*(this->group_names)).end(); ++_iter958)
+    std::vector<std::string> ::const_iterator _iter951;
+    for (_iter951 = (*(this->group_names)).begin(); _iter951 != (*(this->group_names)).end(); ++_iter951)
     {
-      xfer += oprot->writeString((*_iter958));
+      xfer += oprot->writeString((*_iter951));
     }
     xfer += oprot->writeListEnd();
   }
@@ -25187,9 +24929,9 @@ uint32_t ThriftHiveMetastore_list_privileges_args::read(::apache::thrift::protoc
         break;
       case 2:
         if (ftype == ::apache::thrift::protocol::T_I32) {
-          int32_t ecast959;
-          xfer += iprot->readI32(ecast959);
-          this->principal_type = (PrincipalType::type)ecast959;
+          int32_t ecast952;
+          xfer += iprot->readI32(ecast952);
+          this->principal_type = (PrincipalType::type)ecast952;
           this->__isset.principal_type = true;
         } else {
           xfer += iprot->skip(ftype);
@@ -25281,14 +25023,14 @@ uint32_t ThriftHiveMetastore_list_privileges_result::read(::apache::thrift::prot
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size960;
-            ::apache::thrift::protocol::TType _etype963;
-            xfer += iprot->readListBegin(_etype963, _size960);
-            this->success.resize(_size960);
-            uint32_t _i964;
-            for (_i964 = 0; _i964 < _size960; ++_i964)
+            uint32_t _size953;
+            ::apache::thrift::protocol::TType _etype956;
+            xfer += iprot->readListBegin(_etype956, _size953);
+            this->success.resize(_size953);
+            uint32_t _i957;
+            for (_i957 = 0; _i957 < _size953; ++_i957)
             {
-              xfer += this->success[_i964].read(iprot);
+              xfer += this->success[_i957].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -25327,10 +25069,10 @@ uint32_t ThriftHiveMetastore_list_privileges_result::write(::apache::thrift::pro
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(this->success.size()));
-      std::vector<HiveObjectPrivilege> ::const_iterator _iter965;
-      for (_iter965 = this->success.begin(); _iter965 != this->success.end(); ++_iter965)
+      std::vector<HiveObjectPrivilege> ::const_iterator _iter958;
+      for (_iter958 = this->success.begin(); _iter958 != this->success.end(); ++_iter958)
       {
-        xfer += (*_iter965).write(oprot);
+        xfer += (*_iter958).write(oprot);
       }
       xfer += oprot->writeListEnd();
     }
@@ -25369,14 +25111,14 @@ uint32_t ThriftHiveMetastore_list_privileges_presult::read(::apache::thrift::pro
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size966;
-            ::apache::thrift::protocol::TType _etype969;
-            xfer += iprot->readListBegin(_etype969, _size966);
-            (*(this->success)).resize(_size966);
-            uint32_t _i970;
-            for (_i970 = 0; _i970 < _size966; ++_i970)
+            uint32_t _size959;
+            ::apache::thrift::protocol::TType _etype962;
+            xfer += iprot->readListBegin(_etype962, _size959);
+            (*(this->success)).resize(_size959);
+            uint32_t _i963;
+            for (_i963 = 0; _i963 < _size959; ++_i963)
             {
-              xfer += (*(this->success))[_i970].read(iprot);
+              xfer += (*(this->success))[_i963].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -25983,14 +25725,14 @@ uint32_t ThriftHiveMetastore_set_ugi_args::read(::apache::thrift::protocol::TPro
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->group_names.clear();
-            uint32_t _size971;
-            ::apache::thrift::protocol::TType _etype974;
-            xfer += iprot->readListBegin(_etype974, _size971);
-            this->group_names.resize(_size971);
-            uint32_t _i975;
-            for (_i975 = 0; _i975 < _size971; ++_i975)
+            uint32_t _size964;
+            ::apache::thrift::protocol::TType _etype967;
+            xfer += iprot->readListBegin(_etype967, _size964);
+            this->group_names.resize(_size964);
+            uint32_t _i968;
+            for (_i968 = 0; _i968 < _size964; ++_i968)
             {
-              xfer += iprot->readString(this->group_names[_i975]);
+              xfer += iprot->readString(this->group_names[_i968]);
             }
             xfer += iprot->readListEnd();
           }
@@ -26022,10 +25764,10 @@ uint32_t ThriftHiveMetastore_set_ugi_args::write(::apache::thrift::protocol::TPr
   xfer += oprot->writeFieldBegin("group_names", ::apache::thrift::protocol::T_LIST, 2);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->group_names.size()));
-    std::vector<std::string> ::const_iterator _iter976;
-    for (_iter976 = this->group_names.begin(); _iter976 != this->group_names.end(); ++_iter976)
+    std::vector<std::string> ::const_iterator _iter969;
+    for (_iter969 = this->group_names.begin(); _iter969 != this->group_names.end(); ++_iter969)
     {
-      xfer += oprot->writeString((*_iter976));
+      xfer += oprot->writeString((*_iter969));
     }
     xfer += oprot->writeListEnd();
   }
@@ -26047,10 +25789,10 @@ uint32_t ThriftHiveMetastore_set_ugi_pargs::write(::apache::thrift::protocol::TP
   xfer += oprot->writeFieldBegin("group_names", ::apache::thrift::protocol::T_LIST, 2);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>((*(this->group_names)).size()));
-    std::vector<std::string> ::const_iterator _iter977;
-    for (_iter977 = (*(this->group_names)).begin(); _iter977 != (*(this->group_names)).end(); ++_iter977)
+    std::vector<std::string> ::const_iterator _iter970;
+    for (_iter970 = (*(this->group_names)).begin(); _iter970 != (*(this->group_names)).end(); ++_iter970)
     {
-      xfer += oprot->writeString((*_iter977));
+      xfer += oprot->writeString((*_iter970));
     }
     xfer += oprot->writeListEnd();
   }
@@ -26085,14 +25827,14 @@ uint32_t ThriftHiveMetastore_set_ugi_result::read(::apache::thrift::protocol::TP
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size978;
-            ::apache::thrift::protocol::TType _etype981;
-            xfer += iprot->readListBegin(_etype981, _size978);
-            this->success.resize(_size978);
-            uint32_t _i982;
-            for (_i982 = 0; _i982 < _size978; ++_i982)
+            uint32_t _size971;
+            ::apache::thrift::protocol::TType _etype974;
+            xfer += iprot->readListBegin(_etype974, _size971);
+            this->success.resize(_size971);
+            uint32_t _i975;
+            for (_i975 = 0; _i975 < _size971; ++_i975)
             {
-              xfer += iprot->readString(this->success[_i982]);
+              xfer += iprot->readString(this->success[_i975]);
             }
             xfer += iprot->readListEnd();
           }
@@ -26131,10 +25873,10 @@ uint32_t ThriftHiveMetastore_set_ugi_result::write(::apache::thrift::protocol::T
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter983;
-      for (_iter983 = this->success.begin(); _iter983 != this->success.end(); ++_iter983)
+      std::vector<std::string> ::const_iterator _iter976;
+      for (_iter976 = this->success.begin(); _iter976 != this->success.end(); ++_iter976)
       {
-        xfer += oprot->writeString((*_iter983));
+        xfer += oprot->writeString((*_iter976));
       }
       xfer += oprot->writeListEnd();
     }
@@ -26173,14 +25915,14 @@ uint32_t ThriftHiveMetastore_set_ugi_presult::read(::apache::thrift::protocol::T
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size984;
-            ::apache::thrift::protocol::TType _etype987;
-            xfer += iprot->readListBegin(_etype987, _size984);
-            (*(this->success)).resize(_size984);
-            uint32_t _i988;
-            for (_i988 = 0; _i988 < _size984; ++_i988)
+            uint32_t _size977;
+            ::apache::thrift::protocol::TType _etype980;
+            xfer += iprot->readListBegin(_etype980, _size977);
+            (*(this->success)).resize(_size977);
+            uint32_t _i981;
+            for (_i981 = 0; _i981 < _size977; ++_i981)
             {
-              xfer += iprot->readString((*(this->success))[_i988]);
+              xfer += iprot->readString((*(this->success))[_i981]);
             }
             xfer += iprot->readListEnd();
           }
@@ -27322,14 +27064,14 @@ uint32_t ThriftHiveMetastore_get_all_token_identifiers_result::read(::apache::th
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size989;
-            ::apache::thrift::protocol::TType _etype992;
-            xfer += iprot->readListBegin(_etype992, _size989);
-            this->success.resize(_size989);
-            uint32_t _i993;
-            for (_i993 = 0; _i993 < _size989; ++_i993)
+            uint32_t _size982;
+            ::apache::thrift::protocol::TType _etype985;
+            xfer += iprot->readListBegin(_etype985, _size982);
+            this->success.resize(_size982);
+            uint32_t _i986;
+            for (_i986 = 0; _i986 < _size982; ++_i986)
             {
-              xfer += iprot->readString(this->success[_i993]);
+              xfer += iprot->readString(this->success[_i986]);
             }
             xfer += iprot->readListEnd();
           }
@@ -27360,10 +27102,10 @@ uint32_t ThriftHiveMetastore_get_all_token_identifiers_result::write(::apache::t
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter994;
-      for (_iter994 = this->success.begin(); _iter994 != this->success.end(); ++_iter994)
+      std::vector<std::string> ::const_iterator _iter987;
+      for (_iter987 = this->success.begin(); _iter987 != this->success.end(); ++_iter987)
       {
-        xfer += oprot->writeString((*_iter994));
+        xfer += oprot->writeString((*_iter987));
       }
       xfer += oprot->writeListEnd();
     }
@@ -27398,14 +27140,14 @@ uint32_t ThriftHiveMetastore_get_all_token_identifiers_presult::read(::apache::t
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size995;
-            ::apache::thrift::protocol::TType _etype998;
-            xfer += iprot->readListBegin(_etype998, _size995);
-            (*(this->success)).resize(_size995);
-            uint32_t _i999;
-            for (_i999 = 0; _i999 < _size995; ++_i999)
+            uint32_t _size988;
+            ::apache::thrift::protocol::TType _etype991;
+            xfer += iprot->readListBegin(_etype991, _size988);
+            (*(this->success)).resize(_size988);
+            uint32_t _i992;
+            for (_i992 = 0; _i992 < _size988; ++_i992)
             {
-              xfer += iprot->readString((*(this->success))[_i999]);
+              xfer += iprot->readString((*(this->success))[_i992]);
             }
             xfer += iprot->readListEnd();
           }
@@ -28037,14 +27779,14 @@ uint32_t ThriftHiveMetastore_get_master_keys_result::read(::apache::thrift::prot
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->success.clear();
-            uint32_t _size1000;
-            ::apache::thrift::protocol::TType _etype1003;
-            xfer += iprot->readListBegin(_etype1003, _size1000);
-            this->success.resize(_size1000);
-            uint32_t _i1004;
-            for (_i1004 = 0; _i1004 < _size1000; ++_i1004)
+            uint32_t _size993;
+            ::apache::thrift::protocol::TType _etype996;
+            xfer += iprot->readListBegin(_etype996, _size993);
+            this->success.resize(_size993);
+            uint32_t _i997;
+            for (_i997 = 0; _i997 < _size993; ++_i997)
             {
-              xfer += iprot->readString(this->success[_i1004]);
+              xfer += iprot->readString(this->success[_i997]);
             }
             xfer += iprot->readListEnd();
           }
@@ -28075,10 +27817,10 @@ uint32_t ThriftHiveMetastore_get_master_keys_result::write(::apache::thrift::pro
     xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_LIST, 0);
     {
       xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->success.size()));
-      std::vector<std::string> ::const_iterator _iter1005;
-      for (_iter1005 = this->success.begin(); _iter1005 != this->success.end(); ++_iter1005)
+      std::vector<std::string> ::const_iterator _iter998;
+      for (_iter998 = this->success.begin(); _iter998 != this->success.end(); ++_iter998)
       {
-        xfer += oprot->writeString((*_iter1005));
+        xfer += oprot->writeString((*_iter998));
       }
       xfer += oprot->writeListEnd();
     }
@@ -28113,14 +27855,14 @@ uint32_t ThriftHiveMetastore_get_master_keys_presult::read(::apache::thrift::pro
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             (*(this->success)).clear();
-            uint32_t _size1006;
-            ::apache::thrift::protocol::TType _etype1009;
-            xfer += iprot->readListBegin(_etype1009, _size1006);
-            (*(this->success)).resize(_size1006);
-            uint32_t _i1010;
-            for (_i1010 = 0; _i1010 < _size1006; ++_i1010)
+            uint32_t _size999;
+            ::apache::thrift::protocol::TType _etype1002;
+            xfer += iprot->readListBegin(_etype1002, _size999);
+            (*(this->success)).resize(_size999);
+            uint32_t _i1003;
+            for (_i1003 = 0; _i1003 < _size999; ++_i1003)
             {
-              xfer += iprot->readString((*(this->success))[_i1010]);
+              xfer += iprot->readString((*(this->success))[_i1003]);
             }
             xfer += iprot->readListEnd();
           }
@@ -35040,68 +34782,6 @@ void ThriftHiveMetastoreClient::recv_alter_partitions()
   return;
 }
 
-void ThriftHiveMetastoreClient::alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context)
-{
-  send_alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context);
-  recv_alter_partitions_with_environment_context();
-}
-
-void ThriftHiveMetastoreClient::send_alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context)
-{
-  int32_t cseqid = 0;
-  oprot_->writeMessageBegin("alter_partitions_with_environment_context", ::apache::thrift::protocol::T_CALL, cseqid);
-
-  ThriftHiveMetastore_alter_partitions_with_environment_context_pargs args;
-  args.db_name = &db_name;
-  args.tbl_name = &tbl_name;
-  args.new_parts = &new_parts;
-  args.environment_context = &environment_context;
-  args.write(oprot_);
-
-  oprot_->writeMessageEnd();
-  oprot_->getTransport()->writeEnd();
-  oprot_->getTransport()->flush();
-}
-
-void ThriftHiveMetastoreClient::recv_alter_partitions_with_environment_context()
-{
-
-  int32_t rseqid = 0;
-  std::string fname;
-  ::apache::thrift::protocol::TMessageType mtype;
-
-  iprot_->readMessageBegin(fname, mtype, rseqid);
-  if (mtype == ::apache::thrift::protocol::T_EXCEPTION) {
-    ::apache::thrift::TApplicationException x;
-    x.read(iprot_);
-    iprot_->readMessageEnd();
-    iprot_->getTransport()->readEnd();
-    throw x;
-  }
-  if (mtype != ::apache::thrift::protocol::T_REPLY) {
-    iprot_->skip(::apache::thrift::protocol::T_STRUCT);
-    iprot_->readMessageEnd();
-    iprot_->getTransport()->readEnd();
-  }
-  if (fname.compare("alter_partitions_with_environment_context") != 0) {
-    iprot_->skip(::apache::thrift::protocol::T_STRUCT);
-    iprot_->readMessageEnd();
-    iprot_->getTransport()->readEnd();
-  }
-  ThriftHiveMetastore_alter_partitions_with_environment_context_presult result;
-  result.read(iprot_);
-  iprot_->readMessageEnd();
-  iprot_->getTransport()->readEnd();
-
-  if (result.__isset.o1) {
-    throw result.o1;
-  }
-  if (result.__isset.o2) {
-    throw result.o2;
-  }
-  return;
-}
-
 void ThriftHiveMetastoreClient::alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context)
 {
   send_alter_partition_with_environment_context(db_name, tbl_name, new_part, environment_context);
@@ -43423,65 +43103,6 @@ void ThriftHiveMetastoreProcessor::process_alter_partitions(int32_t seqid, ::apa
   }
 }
 
-void ThriftHiveMetastoreProcessor::process_alter_partitions_with_environment_context(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext)
-{
-  void* ctx = NULL;
-  if (this->eventHandler_.get() != NULL) {
-    ctx = this->eventHandler_->getContext("ThriftHiveMetastore.alter_partitions_with_environment_context", callContext);
-  }
-  ::apache::thrift::TProcessorContextFreer freer(this->eventHandler_.get(), ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context");
-
-  if (this->eventHandler_.get() != NULL) {
-    this->eventHandler_->preRead(ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context");
-  }
-
-  ThriftHiveMetastore_alter_partitions_with_environment_context_args args;
-  args.read(iprot);
-  iprot->readMessageEnd();
-  uint32_t bytes = iprot->getTransport()->readEnd();
-
-  if (this->eventHandler_.get() != NULL) {
-    this->eventHandler_->postRead(ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context", bytes);
-  }
-
-  ThriftHiveMetastore_alter_partitions_with_environment_context_result result;
-  try {
-    iface_->alter_partitions_with_environment_context(args.db_name, args.tbl_name, args.new_parts, args.environment_context);
-  } catch (InvalidOperationException &o1) {
-    result.o1 = o1;
-    result.__isset.o1 = true;
-  } catch (MetaException &o2) {
-    result.o2 = o2;
-    result.__isset.o2 = true;
-  } catch (const std::exception& e) {
-    if (this->eventHandler_.get() != NULL) {
-      this->eventHandler_->handlerError(ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context");
-    }
-
-    ::apache::thrift::TApplicationException x(e.what());
-    oprot->writeMessageBegin("alter_partitions_with_environment_context", ::apache::thrift::protocol::T_EXCEPTION, seqid);
-    x.write(oprot);
-    oprot->writeMessageEnd();
-    oprot->getTransport()->writeEnd();
-    oprot->getTransport()->flush();
-    return;
-  }
-
-  if (this->eventHandler_.get() != NULL) {
-    this->eventHandler_->preWrite(ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context");
-  }
-
-  oprot->writeMessageBegin("alter_partitions_with_environment_context", ::apache::thrift::protocol::T_REPLY, seqid);
-  result.write(oprot);
-  oprot->writeMessageEnd();
-  bytes = oprot->getTransport()->writeEnd();
-  oprot->getTransport()->flush();
-
-  if (this->eventHandler_.get() != NULL) {
-    this->eventHandler_->postWrite(ctx, "ThriftHiveMetastore.alter_partitions_with_environment_context", bytes);
-  }
-}
-
 void ThriftHiveMetastoreProcessor::process_alter_partition_with_environment_context(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext)
 {
   void* ctx = NULL;
diff --git a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h
index 6468a7e..2bd79d3 100644
--- a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h
+++ b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h
@@ -78,7 +78,6 @@ class ThriftHiveMetastoreIf : virtual public  ::facebook::fb303::FacebookService
   virtual void get_partitions_by_names(std::vector<Partition> & _return, const std::string& db_name, const std::string& tbl_name, const std::vector<std::string> & names) = 0;
   virtual void alter_partition(const std::string& db_name, const std::string& tbl_name, const Partition& new_part) = 0;
   virtual void alter_partitions(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts) = 0;
-  virtual void alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context) = 0;
   virtual void alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context) = 0;
   virtual void rename_partition(const std::string& db_name, const std::string& tbl_name, const std::vector<std::string> & part_vals, const Partition& new_part) = 0;
   virtual bool partition_name_has_valid_characters(const std::vector<std::string> & part_vals, const bool throw_exception) = 0;
@@ -376,9 +375,6 @@ class ThriftHiveMetastoreNull : virtual public ThriftHiveMetastoreIf , virtual p
   void alter_partitions(const std::string& /* db_name */, const std::string& /* tbl_name */, const std::vector<Partition> & /* new_parts */) {
     return;
   }
-  void alter_partitions_with_environment_context(const std::string& /* db_name */, const std::string& /* tbl_name */, const std::vector<Partition> & /* new_parts */, const EnvironmentContext& /* environment_context */) {
-    return;
-  }
   void alter_partition_with_environment_context(const std::string& /* db_name */, const std::string& /* tbl_name */, const Partition& /* new_part */, const EnvironmentContext& /* environment_context */) {
     return;
   }
@@ -9544,151 +9540,6 @@ class ThriftHiveMetastore_alter_partitions_presult {
 
 };
 
-typedef struct _ThriftHiveMetastore_alter_partitions_with_environment_context_args__isset {
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_args__isset() : db_name(false), tbl_name(false), new_parts(false), environment_context(false) {}
-  bool db_name;
-  bool tbl_name;
-  bool new_parts;
-  bool environment_context;
-} _ThriftHiveMetastore_alter_partitions_with_environment_context_args__isset;
-
-class ThriftHiveMetastore_alter_partitions_with_environment_context_args {
- public:
-
-  ThriftHiveMetastore_alter_partitions_with_environment_context_args() : db_name(), tbl_name() {
-  }
-
-  virtual ~ThriftHiveMetastore_alter_partitions_with_environment_context_args() throw() {}
-
-  std::string db_name;
-  std::string tbl_name;
-  std::vector<Partition>  new_parts;
-  EnvironmentContext environment_context;
-
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_args__isset __isset;
-
-  void __set_db_name(const std::string& val) {
-    db_name = val;
-  }
-
-  void __set_tbl_name(const std::string& val) {
-    tbl_name = val;
-  }
-
-  void __set_new_parts(const std::vector<Partition> & val) {
-    new_parts = val;
-  }
-
-  void __set_environment_context(const EnvironmentContext& val) {
-    environment_context = val;
-  }
-
-  bool operator == (const ThriftHiveMetastore_alter_partitions_with_environment_context_args & rhs) const
-  {
-    if (!(db_name == rhs.db_name))
-      return false;
-    if (!(tbl_name == rhs.tbl_name))
-      return false;
-    if (!(new_parts == rhs.new_parts))
-      return false;
-    if (!(environment_context == rhs.environment_context))
-      return false;
-    return true;
-  }
-  bool operator != (const ThriftHiveMetastore_alter_partitions_with_environment_context_args &rhs) const {
-    return !(*this == rhs);
-  }
-
-  bool operator < (const ThriftHiveMetastore_alter_partitions_with_environment_context_args & ) const;
-
-  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
-  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
-
-};
-
-
-class ThriftHiveMetastore_alter_partitions_with_environment_context_pargs {
- public:
-
-
-  virtual ~ThriftHiveMetastore_alter_partitions_with_environment_context_pargs() throw() {}
-
-  const std::string* db_name;
-  const std::string* tbl_name;
-  const std::vector<Partition> * new_parts;
-  const EnvironmentContext* environment_context;
-
-  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
-
-};
-
-typedef struct _ThriftHiveMetastore_alter_partitions_with_environment_context_result__isset {
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_result__isset() : o1(false), o2(false) {}
-  bool o1;
-  bool o2;
-} _ThriftHiveMetastore_alter_partitions_with_environment_context_result__isset;
-
-class ThriftHiveMetastore_alter_partitions_with_environment_context_result {
- public:
-
-  ThriftHiveMetastore_alter_partitions_with_environment_context_result() {
-  }
-
-  virtual ~ThriftHiveMetastore_alter_partitions_with_environment_context_result() throw() {}
-
-  InvalidOperationException o1;
-  MetaException o2;
-
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_result__isset __isset;
-
-  void __set_o1(const InvalidOperationException& val) {
-    o1 = val;
-  }
-
-  void __set_o2(const MetaException& val) {
-    o2 = val;
-  }
-
-  bool operator == (const ThriftHiveMetastore_alter_partitions_with_environment_context_result & rhs) const
-  {
-    if (!(o1 == rhs.o1))
-      return false;
-    if (!(o2 == rhs.o2))
-      return false;
-    return true;
-  }
-  bool operator != (const ThriftHiveMetastore_alter_partitions_with_environment_context_result &rhs) const {
-    return !(*this == rhs);
-  }
-
-  bool operator < (const ThriftHiveMetastore_alter_partitions_with_environment_context_result & ) const;
-
-  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
-  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
-
-};
-
-typedef struct _ThriftHiveMetastore_alter_partitions_with_environment_context_presult__isset {
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_presult__isset() : o1(false), o2(false) {}
-  bool o1;
-  bool o2;
-} _ThriftHiveMetastore_alter_partitions_with_environment_context_presult__isset;
-
-class ThriftHiveMetastore_alter_partitions_with_environment_context_presult {
- public:
-
-
-  virtual ~ThriftHiveMetastore_alter_partitions_with_environment_context_presult() throw() {}
-
-  InvalidOperationException o1;
-  MetaException o2;
-
-  _ThriftHiveMetastore_alter_partitions_with_environment_context_presult__isset __isset;
-
-  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
-
-};
-
 typedef struct _ThriftHiveMetastore_alter_partition_with_environment_context_args__isset {
   _ThriftHiveMetastore_alter_partition_with_environment_context_args__isset() : db_name(false), tbl_name(false), new_part(false), environment_context(false) {}
   bool db_name;
@@ -19161,9 +19012,6 @@ class ThriftHiveMetastoreClient : virtual public ThriftHiveMetastoreIf, public
   void alter_partitions(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts);
   void send_alter_partitions(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts);
   void recv_alter_partitions();
-  void alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context);
-  void send_alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context);
-  void recv_alter_partitions_with_environment_context();
   void alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context);
   void send_alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context);
   void recv_alter_partition_with_environment_context();
@@ -19455,7 +19303,6 @@ class ThriftHiveMetastoreProcessor : public  ::facebook::fb303::FacebookServiceP
   void process_get_partitions_by_names(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_alter_partition(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_alter_partitions(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
-  void process_alter_partitions_with_environment_context(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_alter_partition_with_environment_context(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_rename_partition(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_partition_name_has_valid_characters(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
@@ -19595,7 +19442,6 @@ class ThriftHiveMetastoreProcessor : public  ::facebook::fb303::FacebookServiceP
     processMap_["get_partitions_by_names"] = &ThriftHiveMetastoreProcessor::process_get_partitions_by_names;
     processMap_["alter_partition"] = &ThriftHiveMetastoreProcessor::process_alter_partition;
     processMap_["alter_partitions"] = &ThriftHiveMetastoreProcessor::process_alter_partitions;
-    processMap_["alter_partitions_with_environment_context"] = &ThriftHiveMetastoreProcessor::process_alter_partitions_with_environment_context;
     processMap_["alter_partition_with_environment_context"] = &ThriftHiveMetastoreProcessor::process_alter_partition_with_environment_context;
     processMap_["rename_partition"] = &ThriftHiveMetastoreProcessor::process_rename_partition;
     processMap_["partition_name_has_valid_characters"] = &ThriftHiveMetastoreProcessor::process_partition_name_has_valid_characters;
@@ -20300,15 +20146,6 @@ class ThriftHiveMetastoreMultiface : virtual public ThriftHiveMetastoreIf, publi
     ifaces_[i]->alter_partitions(db_name, tbl_name, new_parts);
   }
 
-  void alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context) {
-    size_t sz = ifaces_.size();
-    size_t i = 0;
-    for (; i < (sz - 1); ++i) {
-      ifaces_[i]->alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context);
-    }
-    ifaces_[i]->alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context);
-  }
-
   void alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context) {
     size_t sz = ifaces_.size();
     size_t i = 0;
diff --git a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp
index 6077b6e..c1772af 100644
--- a/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp
+++ b/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp
@@ -332,11 +332,6 @@ class ThriftHiveMetastoreHandler : virtual public ThriftHiveMetastoreIf {
     printf("alter_partitions\n");
   }
 
-  void alter_partitions_with_environment_context(const std::string& db_name, const std::string& tbl_name, const std::vector<Partition> & new_parts, const EnvironmentContext& environment_context) {
-    // Your implementation goes here
-    printf("alter_partitions_with_environment_context\n");
-  }
-
   void alter_partition_with_environment_context(const std::string& db_name, const std::string& tbl_name, const Partition& new_part, const EnvironmentContext& environment_context) {
     // Your implementation goes here
     printf("alter_partition_with_environment_context\n");
diff --git a/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java b/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java
index 2da03cd..f1f3bea 100644
--- a/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java
+++ b/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java
@@ -162,8 +162,6 @@
 
     public void alter_partitions(String db_name, String tbl_name, List<Partition> new_parts) throws InvalidOperationException, MetaException, org.apache.thrift.TException;
 
-    public void alter_partitions_with_environment_context(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context) throws InvalidOperationException, MetaException, org.apache.thrift.TException;
-
     public void alter_partition_with_environment_context(String db_name, String tbl_name, Partition new_part, EnvironmentContext environment_context) throws InvalidOperationException, MetaException, org.apache.thrift.TException;
 
     public void rename_partition(String db_name, String tbl_name, List<String> part_vals, Partition new_part) throws InvalidOperationException, MetaException, org.apache.thrift.TException;
@@ -438,8 +436,6 @@
 
     public void alter_partitions(String db_name, String tbl_name, List<Partition> new_parts, org.apache.thrift.async.AsyncMethodCallback<AsyncClient.alter_partitions_call> resultHandler) throws org.apache.thrift.TException;
 
-    public void alter_partitions_with_environment_context(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context, org.apache.thrift.async.AsyncMethodCallback<AsyncClient.alter_partitions_with_environment_context_call> resultHandler) throws org.apache.thrift.TException;
-
     public void alter_partition_with_environment_context(String db_name, String tbl_name, Partition new_part, EnvironmentContext environment_context, org.apache.thrift.async.AsyncMethodCallback<AsyncClient.alter_partition_with_environment_context_call> resultHandler) throws org.apache.thrift.TException;
 
     public void rename_partition(String db_name, String tbl_name, List<String> part_vals, Partition new_part, org.apache.thrift.async.AsyncMethodCallback<AsyncClient.rename_partition_call> resultHandler) throws org.apache.thrift.TException;
@@ -2524,35 +2520,6 @@ public void recv_alter_partitions() throws InvalidOperationException, MetaExcept
       return;
     }
 
-    public void alter_partitions_with_environment_context(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context) throws InvalidOperationException, MetaException, org.apache.thrift.TException
-    {
-      send_alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context);
-      recv_alter_partitions_with_environment_context();
-    }
-
-    public void send_alter_partitions_with_environment_context(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context) throws org.apache.thrift.TException
-    {
-      alter_partitions_with_environment_context_args args = new alter_partitions_with_environment_context_args();
-      args.setDb_name(db_name);
-      args.setTbl_name(tbl_name);
-      args.setNew_parts(new_parts);
-      args.setEnvironment_context(environment_context);
-      sendBase("alter_partitions_with_environment_context", args);
-    }
-
-    public void recv_alter_partitions_with_environment_context() throws InvalidOperationException, MetaException, org.apache.thrift.TException
-    {
-      alter_partitions_with_environment_context_result result = new alter_partitions_with_environment_context_result();
-      receiveBase(result, "alter_partitions_with_environment_context");
-      if (result.o1 != null) {
-        throw result.o1;
-      }
-      if (result.o2 != null) {
-        throw result.o2;
-      }
-      return;
-    }
-
     public void alter_partition_with_environment_context(String db_name, String tbl_name, Partition new_part, EnvironmentContext environment_context) throws InvalidOperationException, MetaException, org.apache.thrift.TException
     {
       send_alter_partition_with_environment_context(db_name, tbl_name, new_part, environment_context);
@@ -6899,47 +6866,6 @@ public void getResult() throws InvalidOperationException, MetaException, org.apa
       }
     }
 
-    public void alter_partitions_with_environment_context(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context, org.apache.thrift.async.AsyncMethodCallback<alter_partitions_with_environment_context_call> resultHandler) throws org.apache.thrift.TException {
-      checkReady();
-      alter_partitions_with_environment_context_call method_call = new alter_partitions_with_environment_context_call(db_name, tbl_name, new_parts, environment_context, resultHandler, this, ___protocolFactory, ___transport);
-      this.___currentMethod = method_call;
-      ___manager.call(method_call);
-    }
-
-    public static class alter_partitions_with_environment_context_call extends org.apache.thrift.async.TAsyncMethodCall {
-      private String db_name;
-      private String tbl_name;
-      private List<Partition> new_parts;
-      private EnvironmentContext environment_context;
-      public alter_partitions_with_environment_context_call(String db_name, String tbl_name, List<Partition> new_parts, EnvironmentContext environment_context, org.apache.thrift.async.AsyncMethodCallback<alter_partitions_with_environment_context_call> resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
-        super(client, protocolFactory, transport, resultHandler, false);
-        this.db_name = db_name;
-        this.tbl_name = tbl_name;
-        this.new_parts = new_parts;
-        this.environment_context = environment_context;
-      }
-
-      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
-        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("alter_partitions_with_environment_context", org.apache.thrift.protocol.TMessageType.CALL, 0));
-        alter_partitions_with_environment_context_args args = new alter_partitions_with_environment_context_args();
-        args.setDb_name(db_name);
-        args.setTbl_name(tbl_name);
-        args.setNew_parts(new_parts);
-        args.setEnvironment_context(environment_context);
-        args.write(prot);
-        prot.writeMessageEnd();
-      }
-
-      public void getResult() throws InvalidOperationException, MetaException, org.apache.thrift.TException {
-        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
-          throw new IllegalStateException("Method call not finished!");
-        }
-        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
-        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
-        (new Client(prot)).recv_alter_partitions_with_environment_context();
-      }
-    }
-
     public void alter_partition_with_environment_context(String db_name, String tbl_name, Partition new_part, EnvironmentContext environment_context, org.apache.thrift.async.AsyncMethodCallback<alter_partition_with_environment_context_call> resultHandler) throws org.apache.thrift.TException {
       checkReady();
       alter_partition_with_environment_context_call method_call = new alter_partition_with_environment_context_call(db_name, tbl_name, new_part, environment_context, resultHandler, this, ___protocolFactory, ___transport);
@@ -9501,7 +9427,6 @@ protected Processor(I iface, Map<String,  org.apache.thrift.ProcessFunction<I, ?
       processMap.put("get_partitions_by_names", new get_partitions_by_names());
       processMap.put("alter_partition", new alter_partition());
       processMap.put("alter_partitions", new alter_partitions());
-      processMap.put("alter_partitions_with_environment_context", new alter_partitions_with_environment_context());
       processMap.put("alter_partition_with_environment_context", new alter_partition_with_environment_context());
       processMap.put("rename_partition", new rename_partition());
       processMap.put("partition_name_has_valid_characters", new partition_name_has_valid_characters());
@@ -11233,32 +11158,6 @@ public alter_partitions_result getResult(I iface, alter_partitions_args args) th
       }
     }
 
-    public static class alter_partitions_with_environment_context<I extends Iface> extends org.apache.thrift.ProcessFunction<I, alter_partitions_with_environment_context_args> {
-      public alter_partitions_with_environment_context() {
-        super("alter_partitions_with_environment_context");
-      }
-
-      public alter_partitions_with_environment_context_args getEmptyArgsInstance() {
-        return new alter_partitions_with_environment_context_args();
-      }
-
-      protected boolean isOneway() {
-        return false;
-      }
-
-      public alter_partitions_with_environment_context_result getResult(I iface, alter_partitions_with_environment_context_args args) throws org.apache.thrift.TException {
-        alter_partitions_with_environment_context_result result = new alter_partitions_with_environment_context_result();
-        try {
-          iface.alter_partitions_with_environment_context(args.db_name, args.tbl_name, args.new_parts, args.environment_context);
-        } catch (InvalidOperationException o1) {
-          result.o1 = o1;
-        } catch (MetaException o2) {
-          result.o2 = o2;
-        }
-        return result;
-      }
-    }
-
     public static class alter_partition_with_environment_context<I extends Iface> extends org.apache.thrift.ProcessFunction<I, alter_partition_with_environment_context_args> {
       public alter_partition_with_environment_context() {
         super("alter_partition_with_environment_context");
@@ -79726,1007 +79625,21 @@ public String getFieldName() {
     static {
       Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
       tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
-              new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionSpec.class))));
-      tmpMap.put(_Fields.O1, new org.apache.thrift.meta_data.FieldMetaData("o1", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
-      tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
-      metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_part_specs_by_filter_result.class, metaDataMap);
-    }
-
-    public get_part_specs_by_filter_result() {
-    }
-
-    public get_part_specs_by_filter_result(
-      List<PartitionSpec> success,
-      MetaException o1,
-      NoSuchObjectException o2)
-    {
-      this();
-      this.success = success;
-      this.o1 = o1;
-      this.o2 = o2;
-    }
-
-    /**
-     * Performs a deep copy on <i>other</i>.
-     */
-    public get_part_specs_by_filter_result(get_part_specs_by_filter_result other) {
-      if (other.isSetSuccess()) {
-        List<PartitionSpec> __this__success = new ArrayList<PartitionSpec>();
-        for (PartitionSpec other_element : other.success) {
-          __this__success.add(new PartitionSpec(other_element));
-        }
-        this.success = __this__success;
-      }
-      if (other.isSetO1()) {
-        this.o1 = new MetaException(other.o1);
-      }
-      if (other.isSetO2()) {
-        this.o2 = new NoSuchObjectException(other.o2);
-      }
-    }
-
-    public get_part_specs_by_filter_result deepCopy() {
-      return new get_part_specs_by_filter_result(this);
-    }
-
-    @Override
-    public void clear() {
-      this.success = null;
-      this.o1 = null;
-      this.o2 = null;
-    }
-
-    public int getSuccessSize() {
-      return (this.success == null) ? 0 : this.success.size();
-    }
-
-    public java.util.Iterator<PartitionSpec> getSuccessIterator() {
-      return (this.success == null) ? null : this.success.iterator();
-    }
-
-    public void addToSuccess(PartitionSpec elem) {
-      if (this.success == null) {
-        this.success = new ArrayList<PartitionSpec>();
-      }
-      this.success.add(elem);
-    }
-
-    public List<PartitionSpec> getSuccess() {
-      return this.success;
-    }
-
-    public void setSuccess(List<PartitionSpec> success) {
-      this.success = success;
-    }
-
-    public void unsetSuccess() {
-      this.success = null;
-    }
-
-    /** Returns true if field success is set (has been assigned a value) and false otherwise */
-    public boolean isSetSuccess() {
-      return this.success != null;
-    }
-
-    public void setSuccessIsSet(boolean value) {
-      if (!value) {
-        this.success = null;
-      }
-    }
-
-    public MetaException getO1() {
-      return this.o1;
-    }
-
-    public void setO1(MetaException o1) {
-      this.o1 = o1;
-    }
-
-    public void unsetO1() {
-      this.o1 = null;
-    }
-
-    /** Returns true if field o1 is set (has been assigned a value) and false otherwise */
-    public boolean isSetO1() {
-      return this.o1 != null;
-    }
-
-    public void setO1IsSet(boolean value) {
-      if (!value) {
-        this.o1 = null;
-      }
-    }
-
-    public NoSuchObjectException getO2() {
-      return this.o2;
-    }
-
-    public void setO2(NoSuchObjectException o2) {
-      this.o2 = o2;
-    }
-
-    public void unsetO2() {
-      this.o2 = null;
-    }
-
-    /** Returns true if field o2 is set (has been assigned a value) and false otherwise */
-    public boolean isSetO2() {
-      return this.o2 != null;
-    }
-
-    public void setO2IsSet(boolean value) {
-      if (!value) {
-        this.o2 = null;
-      }
-    }
-
-    public void setFieldValue(_Fields field, Object value) {
-      switch (field) {
-      case SUCCESS:
-        if (value == null) {
-          unsetSuccess();
-        } else {
-          setSuccess((List<PartitionSpec>)value);
-        }
-        break;
-
-      case O1:
-        if (value == null) {
-          unsetO1();
-        } else {
-          setO1((MetaException)value);
-        }
-        break;
-
-      case O2:
-        if (value == null) {
-          unsetO2();
-        } else {
-          setO2((NoSuchObjectException)value);
-        }
-        break;
-
-      }
-    }
-
-    public Object getFieldValue(_Fields field) {
-      switch (field) {
-      case SUCCESS:
-        return getSuccess();
-
-      case O1:
-        return getO1();
-
-      case O2:
-        return getO2();
-
-      }
-      throw new IllegalStateException();
-    }
-
-    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
-    public boolean isSet(_Fields field) {
-      if (field == null) {
-        throw new IllegalArgumentException();
-      }
-
-      switch (field) {
-      case SUCCESS:
-        return isSetSuccess();
-      case O1:
-        return isSetO1();
-      case O2:
-        return isSetO2();
-      }
-      throw new IllegalStateException();
-    }
-
-    @Override
-    public boolean equals(Object that) {
-      if (that == null)
-        return false;
-      if (that instanceof get_part_specs_by_filter_result)
-        return this.equals((get_part_specs_by_filter_result)that);
-      return false;
-    }
-
-    public boolean equals(get_part_specs_by_filter_result that) {
-      if (that == null)
-        return false;
-
-      boolean this_present_success = true && this.isSetSuccess();
-      boolean that_present_success = true && that.isSetSuccess();
-      if (this_present_success || that_present_success) {
-        if (!(this_present_success && that_present_success))
-          return false;
-        if (!this.success.equals(that.success))
-          return false;
-      }
-
-      boolean this_present_o1 = true && this.isSetO1();
-      boolean that_present_o1 = true && that.isSetO1();
-      if (this_present_o1 || that_present_o1) {
-        if (!(this_present_o1 && that_present_o1))
-          return false;
-        if (!this.o1.equals(that.o1))
-          return false;
-      }
-
-      boolean this_present_o2 = true && this.isSetO2();
-      boolean that_present_o2 = true && that.isSetO2();
-      if (this_present_o2 || that_present_o2) {
-        if (!(this_present_o2 && that_present_o2))
-          return false;
-        if (!this.o2.equals(that.o2))
-          return false;
-      }
-
-      return true;
-    }
-
-    @Override
-    public int hashCode() {
-      HashCodeBuilder builder = new HashCodeBuilder();
-
-      boolean present_success = true && (isSetSuccess());
-      builder.append(present_success);
-      if (present_success)
-        builder.append(success);
-
-      boolean present_o1 = true && (isSetO1());
-      builder.append(present_o1);
-      if (present_o1)
-        builder.append(o1);
-
-      boolean present_o2 = true && (isSetO2());
-      builder.append(present_o2);
-      if (present_o2)
-        builder.append(o2);
-
-      return builder.toHashCode();
-    }
-
-    public int compareTo(get_part_specs_by_filter_result other) {
-      if (!getClass().equals(other.getClass())) {
-        return getClass().getName().compareTo(other.getClass().getName());
-      }
-
-      int lastComparison = 0;
-      get_part_specs_by_filter_result typedOther = (get_part_specs_by_filter_result)other;
-
-      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(typedOther.isSetSuccess());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetSuccess()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, typedOther.success);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      lastComparison = Boolean.valueOf(isSetO1()).compareTo(typedOther.isSetO1());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetO1()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.o1, typedOther.o1);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      lastComparison = Boolean.valueOf(isSetO2()).compareTo(typedOther.isSetO2());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetO2()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.o2, typedOther.o2);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      return 0;
-    }
-
-    public _Fields fieldForId(int fieldId) {
-      return _Fields.findByThriftId(fieldId);
-    }
-
-    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
-      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
-    }
-
-    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
-      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
-      }
-
-    @Override
-    public String toString() {
-      StringBuilder sb = new StringBuilder("get_part_specs_by_filter_result(");
-      boolean first = true;
-
-      sb.append("success:");
-      if (this.success == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.success);
-      }
-      first = false;
-      if (!first) sb.append(", ");
-      sb.append("o1:");
-      if (this.o1 == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.o1);
-      }
-      first = false;
-      if (!first) sb.append(", ");
-      sb.append("o2:");
-      if (this.o2 == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.o2);
-      }
-      first = false;
-      sb.append(")");
-      return sb.toString();
-    }
-
-    public void validate() throws org.apache.thrift.TException {
-      // check for required fields
-      // check for sub-struct validity
-    }
-
-    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
-      try {
-        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
-      } catch (org.apache.thrift.TException te) {
-        throw new java.io.IOException(te);
-      }
-    }
-
-    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
-      try {
-        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
-      } catch (org.apache.thrift.TException te) {
-        throw new java.io.IOException(te);
-      }
-    }
-
-    private static class get_part_specs_by_filter_resultStandardSchemeFactory implements SchemeFactory {
-      public get_part_specs_by_filter_resultStandardScheme getScheme() {
-        return new get_part_specs_by_filter_resultStandardScheme();
-      }
-    }
-
-    private static class get_part_specs_by_filter_resultStandardScheme extends StandardScheme<get_part_specs_by_filter_result> {
-
-      public void read(org.apache.thrift.protocol.TProtocol iprot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
-        org.apache.thrift.protocol.TField schemeField;
-        iprot.readStructBegin();
-        while (true)
-        {
-          schemeField = iprot.readFieldBegin();
-          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
-            break;
-          }
-          switch (schemeField.id) {
-            case 0: // SUCCESS
-              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
-                {
-                  org.apache.thrift.protocol.TList _list842 = iprot.readListBegin();
-                  struct.success = new ArrayList<PartitionSpec>(_list842.size);
-                  for (int _i843 = 0; _i843 < _list842.size; ++_i843)
-                  {
-                    PartitionSpec _elem844; // required
-                    _elem844 = new PartitionSpec();
-                    _elem844.read(iprot);
-                    struct.success.add(_elem844);
-                  }
-                  iprot.readListEnd();
-                }
-                struct.setSuccessIsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            case 1: // O1
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.o1 = new MetaException();
-                struct.o1.read(iprot);
-                struct.setO1IsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            case 2: // O2
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.o2 = new NoSuchObjectException();
-                struct.o2.read(iprot);
-                struct.setO2IsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            default:
-              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-          }
-          iprot.readFieldEnd();
-        }
-        iprot.readStructEnd();
-        struct.validate();
-      }
-
-      public void write(org.apache.thrift.protocol.TProtocol oprot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
-        struct.validate();
-
-        oprot.writeStructBegin(STRUCT_DESC);
-        if (struct.success != null) {
-          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
-          {
-            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
-            for (PartitionSpec _iter845 : struct.success)
-            {
-              _iter845.write(oprot);
-            }
-            oprot.writeListEnd();
-          }
-          oprot.writeFieldEnd();
-        }
-        if (struct.o1 != null) {
-          oprot.writeFieldBegin(O1_FIELD_DESC);
-          struct.o1.write(oprot);
-          oprot.writeFieldEnd();
-        }
-        if (struct.o2 != null) {
-          oprot.writeFieldBegin(O2_FIELD_DESC);
-          struct.o2.write(oprot);
-          oprot.writeFieldEnd();
-        }
-        oprot.writeFieldStop();
-        oprot.writeStructEnd();
-      }
-
-    }
-
-    private static class get_part_specs_by_filter_resultTupleSchemeFactory implements SchemeFactory {
-      public get_part_specs_by_filter_resultTupleScheme getScheme() {
-        return new get_part_specs_by_filter_resultTupleScheme();
-      }
-    }
-
-    private static class get_part_specs_by_filter_resultTupleScheme extends TupleScheme<get_part_specs_by_filter_result> {
-
-      @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
-        TTupleProtocol oprot = (TTupleProtocol) prot;
-        BitSet optionals = new BitSet();
-        if (struct.isSetSuccess()) {
-          optionals.set(0);
-        }
-        if (struct.isSetO1()) {
-          optionals.set(1);
-        }
-        if (struct.isSetO2()) {
-          optionals.set(2);
-        }
-        oprot.writeBitSet(optionals, 3);
-        if (struct.isSetSuccess()) {
-          {
-            oprot.writeI32(struct.success.size());
-            for (PartitionSpec _iter846 : struct.success)
-            {
-              _iter846.write(oprot);
-            }
-          }
-        }
-        if (struct.isSetO1()) {
-          struct.o1.write(oprot);
-        }
-        if (struct.isSetO2()) {
-          struct.o2.write(oprot);
-        }
-      }
-
-      @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
-        TTupleProtocol iprot = (TTupleProtocol) prot;
-        BitSet incoming = iprot.readBitSet(3);
-        if (incoming.get(0)) {
-          {
-            org.apache.thrift.protocol.TList _list847 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.success = new ArrayList<PartitionSpec>(_list847.size);
-            for (int _i848 = 0; _i848 < _list847.size; ++_i848)
-            {
-              PartitionSpec _elem849; // required
-              _elem849 = new PartitionSpec();
-              _elem849.read(iprot);
-              struct.success.add(_elem849);
-            }
-          }
-          struct.setSuccessIsSet(true);
-        }
-        if (incoming.get(1)) {
-          struct.o1 = new MetaException();
-          struct.o1.read(iprot);
-          struct.setO1IsSet(true);
-        }
-        if (incoming.get(2)) {
-          struct.o2 = new NoSuchObjectException();
-          struct.o2.read(iprot);
-          struct.setO2IsSet(true);
-        }
-      }
-    }
-
-  }
-
-  public static class get_partitions_by_expr_args implements org.apache.thrift.TBase<get_partitions_by_expr_args, get_partitions_by_expr_args._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_expr_args");
-
-    private static final org.apache.thrift.protocol.TField REQ_FIELD_DESC = new org.apache.thrift.protocol.TField("req", org.apache.thrift.protocol.TType.STRUCT, (short)1);
-
-    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
-    static {
-      schemes.put(StandardScheme.class, new get_partitions_by_expr_argsStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new get_partitions_by_expr_argsTupleSchemeFactory());
-    }
-
-    private PartitionsByExprRequest req; // required
-
-    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
-    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
-      REQ((short)1, "req");
-
-      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
-
-      static {
-        for (_Fields field : EnumSet.allOf(_Fields.class)) {
-          byName.put(field.getFieldName(), field);
-        }
-      }
-
-      /**
-       * Find the _Fields constant that matches fieldId, or null if its not found.
-       */
-      public static _Fields findByThriftId(int fieldId) {
-        switch(fieldId) {
-          case 1: // REQ
-            return REQ;
-          default:
-            return null;
-        }
-      }
-
-      /**
-       * Find the _Fields constant that matches fieldId, throwing an exception
-       * if it is not found.
-       */
-      public static _Fields findByThriftIdOrThrow(int fieldId) {
-        _Fields fields = findByThriftId(fieldId);
-        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
-        return fields;
-      }
-
-      /**
-       * Find the _Fields constant that matches name, or null if its not found.
-       */
-      public static _Fields findByName(String name) {
-        return byName.get(name);
-      }
-
-      private final short _thriftId;
-      private final String _fieldName;
-
-      _Fields(short thriftId, String fieldName) {
-        _thriftId = thriftId;
-        _fieldName = fieldName;
-      }
-
-      public short getThriftFieldId() {
-        return _thriftId;
-      }
-
-      public String getFieldName() {
-        return _fieldName;
-      }
-    }
-
-    // isset id assignments
-    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
-    static {
-      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
-      tmpMap.put(_Fields.REQ, new org.apache.thrift.meta_data.FieldMetaData("req", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionsByExprRequest.class)));
-      metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_expr_args.class, metaDataMap);
-    }
-
-    public get_partitions_by_expr_args() {
-    }
-
-    public get_partitions_by_expr_args(
-      PartitionsByExprRequest req)
-    {
-      this();
-      this.req = req;
-    }
-
-    /**
-     * Performs a deep copy on <i>other</i>.
-     */
-    public get_partitions_by_expr_args(get_partitions_by_expr_args other) {
-      if (other.isSetReq()) {
-        this.req = new PartitionsByExprRequest(other.req);
-      }
-    }
-
-    public get_partitions_by_expr_args deepCopy() {
-      return new get_partitions_by_expr_args(this);
-    }
-
-    @Override
-    public void clear() {
-      this.req = null;
-    }
-
-    public PartitionsByExprRequest getReq() {
-      return this.req;
-    }
-
-    public void setReq(PartitionsByExprRequest req) {
-      this.req = req;
-    }
-
-    public void unsetReq() {
-      this.req = null;
-    }
-
-    /** Returns true if field req is set (has been assigned a value) and false otherwise */
-    public boolean isSetReq() {
-      return this.req != null;
-    }
-
-    public void setReqIsSet(boolean value) {
-      if (!value) {
-        this.req = null;
-      }
-    }
-
-    public void setFieldValue(_Fields field, Object value) {
-      switch (field) {
-      case REQ:
-        if (value == null) {
-          unsetReq();
-        } else {
-          setReq((PartitionsByExprRequest)value);
-        }
-        break;
-
-      }
-    }
-
-    public Object getFieldValue(_Fields field) {
-      switch (field) {
-      case REQ:
-        return getReq();
-
-      }
-      throw new IllegalStateException();
-    }
-
-    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
-    public boolean isSet(_Fields field) {
-      if (field == null) {
-        throw new IllegalArgumentException();
-      }
-
-      switch (field) {
-      case REQ:
-        return isSetReq();
-      }
-      throw new IllegalStateException();
-    }
-
-    @Override
-    public boolean equals(Object that) {
-      if (that == null)
-        return false;
-      if (that instanceof get_partitions_by_expr_args)
-        return this.equals((get_partitions_by_expr_args)that);
-      return false;
-    }
-
-    public boolean equals(get_partitions_by_expr_args that) {
-      if (that == null)
-        return false;
-
-      boolean this_present_req = true && this.isSetReq();
-      boolean that_present_req = true && that.isSetReq();
-      if (this_present_req || that_present_req) {
-        if (!(this_present_req && that_present_req))
-          return false;
-        if (!this.req.equals(that.req))
-          return false;
-      }
-
-      return true;
-    }
-
-    @Override
-    public int hashCode() {
-      HashCodeBuilder builder = new HashCodeBuilder();
-
-      boolean present_req = true && (isSetReq());
-      builder.append(present_req);
-      if (present_req)
-        builder.append(req);
-
-      return builder.toHashCode();
-    }
-
-    public int compareTo(get_partitions_by_expr_args other) {
-      if (!getClass().equals(other.getClass())) {
-        return getClass().getName().compareTo(other.getClass().getName());
-      }
-
-      int lastComparison = 0;
-      get_partitions_by_expr_args typedOther = (get_partitions_by_expr_args)other;
-
-      lastComparison = Boolean.valueOf(isSetReq()).compareTo(typedOther.isSetReq());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetReq()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.req, typedOther.req);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      return 0;
-    }
-
-    public _Fields fieldForId(int fieldId) {
-      return _Fields.findByThriftId(fieldId);
-    }
-
-    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
-      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
-    }
-
-    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
-      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
-    }
-
-    @Override
-    public String toString() {
-      StringBuilder sb = new StringBuilder("get_partitions_by_expr_args(");
-      boolean first = true;
-
-      sb.append("req:");
-      if (this.req == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.req);
-      }
-      first = false;
-      sb.append(")");
-      return sb.toString();
-    }
-
-    public void validate() throws org.apache.thrift.TException {
-      // check for required fields
-      // check for sub-struct validity
-      if (req != null) {
-        req.validate();
-      }
-    }
-
-    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
-      try {
-        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
-      } catch (org.apache.thrift.TException te) {
-        throw new java.io.IOException(te);
-      }
-    }
-
-    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
-      try {
-        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
-      } catch (org.apache.thrift.TException te) {
-        throw new java.io.IOException(te);
-      }
-    }
-
-    private static class get_partitions_by_expr_argsStandardSchemeFactory implements SchemeFactory {
-      public get_partitions_by_expr_argsStandardScheme getScheme() {
-        return new get_partitions_by_expr_argsStandardScheme();
-      }
-    }
-
-    private static class get_partitions_by_expr_argsStandardScheme extends StandardScheme<get_partitions_by_expr_args> {
-
-      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
-        org.apache.thrift.protocol.TField schemeField;
-        iprot.readStructBegin();
-        while (true)
-        {
-          schemeField = iprot.readFieldBegin();
-          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
-            break;
-          }
-          switch (schemeField.id) {
-            case 1: // REQ
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.req = new PartitionsByExprRequest();
-                struct.req.read(iprot);
-                struct.setReqIsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            default:
-              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-          }
-          iprot.readFieldEnd();
-        }
-        iprot.readStructEnd();
-        struct.validate();
-      }
-
-      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
-        struct.validate();
-
-        oprot.writeStructBegin(STRUCT_DESC);
-        if (struct.req != null) {
-          oprot.writeFieldBegin(REQ_FIELD_DESC);
-          struct.req.write(oprot);
-          oprot.writeFieldEnd();
-        }
-        oprot.writeFieldStop();
-        oprot.writeStructEnd();
-      }
-
-    }
-
-    private static class get_partitions_by_expr_argsTupleSchemeFactory implements SchemeFactory {
-      public get_partitions_by_expr_argsTupleScheme getScheme() {
-        return new get_partitions_by_expr_argsTupleScheme();
-      }
-    }
-
-    private static class get_partitions_by_expr_argsTupleScheme extends TupleScheme<get_partitions_by_expr_args> {
-
-      @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
-        TTupleProtocol oprot = (TTupleProtocol) prot;
-        BitSet optionals = new BitSet();
-        if (struct.isSetReq()) {
-          optionals.set(0);
-        }
-        oprot.writeBitSet(optionals, 1);
-        if (struct.isSetReq()) {
-          struct.req.write(oprot);
-        }
-      }
-
-      @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
-        TTupleProtocol iprot = (TTupleProtocol) prot;
-        BitSet incoming = iprot.readBitSet(1);
-        if (incoming.get(0)) {
-          struct.req = new PartitionsByExprRequest();
-          struct.req.read(iprot);
-          struct.setReqIsSet(true);
-        }
-      }
-    }
-
-  }
-
-  public static class get_partitions_by_expr_result implements org.apache.thrift.TBase<get_partitions_by_expr_result, get_partitions_by_expr_result._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_expr_result");
-
-    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);
-    private static final org.apache.thrift.protocol.TField O1_FIELD_DESC = new org.apache.thrift.protocol.TField("o1", org.apache.thrift.protocol.TType.STRUCT, (short)1);
-    private static final org.apache.thrift.protocol.TField O2_FIELD_DESC = new org.apache.thrift.protocol.TField("o2", org.apache.thrift.protocol.TType.STRUCT, (short)2);
-
-    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
-    static {
-      schemes.put(StandardScheme.class, new get_partitions_by_expr_resultStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new get_partitions_by_expr_resultTupleSchemeFactory());
-    }
-
-    private PartitionsByExprResult success; // required
-    private MetaException o1; // required
-    private NoSuchObjectException o2; // required
-
-    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
-    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
-      SUCCESS((short)0, "success"),
-      O1((short)1, "o1"),
-      O2((short)2, "o2");
-
-      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
-
-      static {
-        for (_Fields field : EnumSet.allOf(_Fields.class)) {
-          byName.put(field.getFieldName(), field);
-        }
-      }
-
-      /**
-       * Find the _Fields constant that matches fieldId, or null if its not found.
-       */
-      public static _Fields findByThriftId(int fieldId) {
-        switch(fieldId) {
-          case 0: // SUCCESS
-            return SUCCESS;
-          case 1: // O1
-            return O1;
-          case 2: // O2
-            return O2;
-          default:
-            return null;
-        }
-      }
-
-      /**
-       * Find the _Fields constant that matches fieldId, throwing an exception
-       * if it is not found.
-       */
-      public static _Fields findByThriftIdOrThrow(int fieldId) {
-        _Fields fields = findByThriftId(fieldId);
-        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
-        return fields;
-      }
-
-      /**
-       * Find the _Fields constant that matches name, or null if its not found.
-       */
-      public static _Fields findByName(String name) {
-        return byName.get(name);
-      }
-
-      private final short _thriftId;
-      private final String _fieldName;
-
-      _Fields(short thriftId, String fieldName) {
-        _thriftId = thriftId;
-        _fieldName = fieldName;
-      }
-
-      public short getThriftFieldId() {
-        return _thriftId;
-      }
-
-      public String getFieldName() {
-        return _fieldName;
-      }
-    }
-
-    // isset id assignments
-    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
-    static {
-      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
-      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionsByExprResult.class)));
+          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
+              new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionSpec.class))));
       tmpMap.put(_Fields.O1, new org.apache.thrift.meta_data.FieldMetaData("o1", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_expr_result.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_part_specs_by_filter_result.class, metaDataMap);
     }
 
-    public get_partitions_by_expr_result() {
+    public get_part_specs_by_filter_result() {
     }
 
-    public get_partitions_by_expr_result(
-      PartitionsByExprResult success,
+    public get_part_specs_by_filter_result(
+      List<PartitionSpec> success,
       MetaException o1,
       NoSuchObjectException o2)
     {
@@ -80739,9 +79652,13 @@ public get_partitions_by_expr_result(
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public get_partitions_by_expr_result(get_partitions_by_expr_result other) {
+    public get_part_specs_by_filter_result(get_part_specs_by_filter_result other) {
       if (other.isSetSuccess()) {
-        this.success = new PartitionsByExprResult(other.success);
+        List<PartitionSpec> __this__success = new ArrayList<PartitionSpec>();
+        for (PartitionSpec other_element : other.success) {
+          __this__success.add(new PartitionSpec(other_element));
+        }
+        this.success = __this__success;
       }
       if (other.isSetO1()) {
         this.o1 = new MetaException(other.o1);
@@ -80751,8 +79668,8 @@ public get_partitions_by_expr_result(get_partitions_by_expr_result other) {
       }
     }
 
-    public get_partitions_by_expr_result deepCopy() {
-      return new get_partitions_by_expr_result(this);
+    public get_part_specs_by_filter_result deepCopy() {
+      return new get_part_specs_by_filter_result(this);
     }
 
     @Override
@@ -80762,11 +79679,26 @@ public void clear() {
       this.o2 = null;
     }
 
-    public PartitionsByExprResult getSuccess() {
+    public int getSuccessSize() {
+      return (this.success == null) ? 0 : this.success.size();
+    }
+
+    public java.util.Iterator<PartitionSpec> getSuccessIterator() {
+      return (this.success == null) ? null : this.success.iterator();
+    }
+
+    public void addToSuccess(PartitionSpec elem) {
+      if (this.success == null) {
+        this.success = new ArrayList<PartitionSpec>();
+      }
+      this.success.add(elem);
+    }
+
+    public List<PartitionSpec> getSuccess() {
       return this.success;
     }
 
-    public void setSuccess(PartitionsByExprResult success) {
+    public void setSuccess(List<PartitionSpec> success) {
       this.success = success;
     }
 
@@ -80837,7 +79769,7 @@ public void setFieldValue(_Fields field, Object value) {
         if (value == null) {
           unsetSuccess();
         } else {
-          setSuccess((PartitionsByExprResult)value);
+          setSuccess((List<PartitionSpec>)value);
         }
         break;
 
@@ -80896,12 +79828,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof get_partitions_by_expr_result)
-        return this.equals((get_partitions_by_expr_result)that);
+      if (that instanceof get_part_specs_by_filter_result)
+        return this.equals((get_part_specs_by_filter_result)that);
       return false;
     }
 
-    public boolean equals(get_partitions_by_expr_result that) {
+    public boolean equals(get_part_specs_by_filter_result that) {
       if (that == null)
         return false;
 
@@ -80957,13 +79889,13 @@ public int hashCode() {
       return builder.toHashCode();
     }
 
-    public int compareTo(get_partitions_by_expr_result other) {
+    public int compareTo(get_part_specs_by_filter_result other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      get_partitions_by_expr_result typedOther = (get_partitions_by_expr_result)other;
+      get_part_specs_by_filter_result typedOther = (get_part_specs_by_filter_result)other;
 
       lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(typedOther.isSetSuccess());
       if (lastComparison != 0) {
@@ -81012,7 +79944,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("get_partitions_by_expr_result(");
+      StringBuilder sb = new StringBuilder("get_part_specs_by_filter_result(");
       boolean first = true;
 
       sb.append("success:");
@@ -81045,9 +79977,6 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
-      if (success != null) {
-        success.validate();
-      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -81066,15 +79995,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class get_partitions_by_expr_resultStandardSchemeFactory implements SchemeFactory {
-      public get_partitions_by_expr_resultStandardScheme getScheme() {
-        return new get_partitions_by_expr_resultStandardScheme();
+    private static class get_part_specs_by_filter_resultStandardSchemeFactory implements SchemeFactory {
+      public get_part_specs_by_filter_resultStandardScheme getScheme() {
+        return new get_part_specs_by_filter_resultStandardScheme();
       }
     }
 
-    private static class get_partitions_by_expr_resultStandardScheme extends StandardScheme<get_partitions_by_expr_result> {
+    private static class get_part_specs_by_filter_resultStandardScheme extends StandardScheme<get_part_specs_by_filter_result> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -81085,9 +80014,19 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_e
           }
           switch (schemeField.id) {
             case 0: // SUCCESS
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.success = new PartitionsByExprResult();
-                struct.success.read(iprot);
+              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
+                {
+                  org.apache.thrift.protocol.TList _list842 = iprot.readListBegin();
+                  struct.success = new ArrayList<PartitionSpec>(_list842.size);
+                  for (int _i843 = 0; _i843 < _list842.size; ++_i843)
+                  {
+                    PartitionSpec _elem844; // required
+                    _elem844 = new PartitionSpec();
+                    _elem844.read(iprot);
+                    struct.success.add(_elem844);
+                  }
+                  iprot.readListEnd();
+                }
                 struct.setSuccessIsSet(true);
               } else { 
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
@@ -81120,13 +80059,20 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_e
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
         if (struct.success != null) {
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
-          struct.success.write(oprot);
+          {
+            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
+            for (PartitionSpec _iter845 : struct.success)
+            {
+              _iter845.write(oprot);
+            }
+            oprot.writeListEnd();
+          }
           oprot.writeFieldEnd();
         }
         if (struct.o1 != null) {
@@ -81145,16 +80091,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_
 
     }
 
-    private static class get_partitions_by_expr_resultTupleSchemeFactory implements SchemeFactory {
-      public get_partitions_by_expr_resultTupleScheme getScheme() {
-        return new get_partitions_by_expr_resultTupleScheme();
+    private static class get_part_specs_by_filter_resultTupleSchemeFactory implements SchemeFactory {
+      public get_part_specs_by_filter_resultTupleScheme getScheme() {
+        return new get_part_specs_by_filter_resultTupleScheme();
       }
     }
 
-    private static class get_partitions_by_expr_resultTupleScheme extends TupleScheme<get_partitions_by_expr_result> {
+    private static class get_part_specs_by_filter_resultTupleScheme extends TupleScheme<get_part_specs_by_filter_result> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetSuccess()) {
@@ -81168,7 +80114,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_e
         }
         oprot.writeBitSet(optionals, 3);
         if (struct.isSetSuccess()) {
-          struct.success.write(oprot);
+          {
+            oprot.writeI32(struct.success.size());
+            for (PartitionSpec _iter846 : struct.success)
+            {
+              _iter846.write(oprot);
+            }
+          }
         }
         if (struct.isSetO1()) {
           struct.o1.write(oprot);
@@ -81179,12 +80131,21 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_e
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, get_part_specs_by_filter_result struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
-          struct.success = new PartitionsByExprResult();
-          struct.success.read(iprot);
+          {
+            org.apache.thrift.protocol.TList _list847 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.success = new ArrayList<PartitionSpec>(_list847.size);
+            for (int _i848 = 0; _i848 < _list847.size; ++_i848)
+            {
+              PartitionSpec _elem849; // required
+              _elem849 = new PartitionSpec();
+              _elem849.read(iprot);
+              struct.success.add(_elem849);
+            }
+          }
           struct.setSuccessIsSet(true);
         }
         if (incoming.get(1)) {
@@ -81202,28 +80163,22 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_ex
 
   }
 
-  public static class get_partitions_by_names_args implements org.apache.thrift.TBase<get_partitions_by_names_args, get_partitions_by_names_args._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_names_args");
+  public static class get_partitions_by_expr_args implements org.apache.thrift.TBase<get_partitions_by_expr_args, get_partitions_by_expr_args._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_expr_args");
 
-    private static final org.apache.thrift.protocol.TField DB_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("db_name", org.apache.thrift.protocol.TType.STRING, (short)1);
-    private static final org.apache.thrift.protocol.TField TBL_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("tbl_name", org.apache.thrift.protocol.TType.STRING, (short)2);
-    private static final org.apache.thrift.protocol.TField NAMES_FIELD_DESC = new org.apache.thrift.protocol.TField("names", org.apache.thrift.protocol.TType.LIST, (short)3);
+    private static final org.apache.thrift.protocol.TField REQ_FIELD_DESC = new org.apache.thrift.protocol.TField("req", org.apache.thrift.protocol.TType.STRUCT, (short)1);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new get_partitions_by_names_argsStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new get_partitions_by_names_argsTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new get_partitions_by_expr_argsStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new get_partitions_by_expr_argsTupleSchemeFactory());
     }
 
-    private String db_name; // required
-    private String tbl_name; // required
-    private List<String> names; // required
+    private PartitionsByExprRequest req; // required
 
     /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
     public enum _Fields implements org.apache.thrift.TFieldIdEnum {
-      DB_NAME((short)1, "db_name"),
-      TBL_NAME((short)2, "tbl_name"),
-      NAMES((short)3, "names");
+      REQ((short)1, "req");
 
       private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
 
@@ -81238,12 +80193,8 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_ex
        */
       public static _Fields findByThriftId(int fieldId) {
         switch(fieldId) {
-          case 1: // DB_NAME
-            return DB_NAME;
-          case 2: // TBL_NAME
-            return TBL_NAME;
-          case 3: // NAMES
-            return NAMES;
+          case 1: // REQ
+            return REQ;
           default:
             return null;
         }
@@ -81287,168 +80238,70 @@ public String getFieldName() {
     public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
     static {
       Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
-      tmpMap.put(_Fields.DB_NAME, new org.apache.thrift.meta_data.FieldMetaData("db_name", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
-      tmpMap.put(_Fields.TBL_NAME, new org.apache.thrift.meta_data.FieldMetaData("tbl_name", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
-      tmpMap.put(_Fields.NAMES, new org.apache.thrift.meta_data.FieldMetaData("names", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
-              new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
+      tmpMap.put(_Fields.REQ, new org.apache.thrift.meta_data.FieldMetaData("req", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionsByExprRequest.class)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_names_args.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_expr_args.class, metaDataMap);
     }
 
-    public get_partitions_by_names_args() {
+    public get_partitions_by_expr_args() {
     }
 
-    public get_partitions_by_names_args(
-      String db_name,
-      String tbl_name,
-      List<String> names)
+    public get_partitions_by_expr_args(
+      PartitionsByExprRequest req)
     {
       this();
-      this.db_name = db_name;
-      this.tbl_name = tbl_name;
-      this.names = names;
+      this.req = req;
     }
 
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public get_partitions_by_names_args(get_partitions_by_names_args other) {
-      if (other.isSetDb_name()) {
-        this.db_name = other.db_name;
-      }
-      if (other.isSetTbl_name()) {
-        this.tbl_name = other.tbl_name;
-      }
-      if (other.isSetNames()) {
-        List<String> __this__names = new ArrayList<String>();
-        for (String other_element : other.names) {
-          __this__names.add(other_element);
-        }
-        this.names = __this__names;
+    public get_partitions_by_expr_args(get_partitions_by_expr_args other) {
+      if (other.isSetReq()) {
+        this.req = new PartitionsByExprRequest(other.req);
       }
     }
 
-    public get_partitions_by_names_args deepCopy() {
-      return new get_partitions_by_names_args(this);
+    public get_partitions_by_expr_args deepCopy() {
+      return new get_partitions_by_expr_args(this);
     }
 
     @Override
     public void clear() {
-      this.db_name = null;
-      this.tbl_name = null;
-      this.names = null;
-    }
-
-    public String getDb_name() {
-      return this.db_name;
-    }
-
-    public void setDb_name(String db_name) {
-      this.db_name = db_name;
-    }
-
-    public void unsetDb_name() {
-      this.db_name = null;
-    }
-
-    /** Returns true if field db_name is set (has been assigned a value) and false otherwise */
-    public boolean isSetDb_name() {
-      return this.db_name != null;
-    }
-
-    public void setDb_nameIsSet(boolean value) {
-      if (!value) {
-        this.db_name = null;
-      }
-    }
-
-    public String getTbl_name() {
-      return this.tbl_name;
-    }
-
-    public void setTbl_name(String tbl_name) {
-      this.tbl_name = tbl_name;
-    }
-
-    public void unsetTbl_name() {
-      this.tbl_name = null;
-    }
-
-    /** Returns true if field tbl_name is set (has been assigned a value) and false otherwise */
-    public boolean isSetTbl_name() {
-      return this.tbl_name != null;
-    }
-
-    public void setTbl_nameIsSet(boolean value) {
-      if (!value) {
-        this.tbl_name = null;
-      }
-    }
-
-    public int getNamesSize() {
-      return (this.names == null) ? 0 : this.names.size();
-    }
-
-    public java.util.Iterator<String> getNamesIterator() {
-      return (this.names == null) ? null : this.names.iterator();
-    }
-
-    public void addToNames(String elem) {
-      if (this.names == null) {
-        this.names = new ArrayList<String>();
-      }
-      this.names.add(elem);
+      this.req = null;
     }
 
-    public List<String> getNames() {
-      return this.names;
+    public PartitionsByExprRequest getReq() {
+      return this.req;
     }
 
-    public void setNames(List<String> names) {
-      this.names = names;
+    public void setReq(PartitionsByExprRequest req) {
+      this.req = req;
     }
 
-    public void unsetNames() {
-      this.names = null;
+    public void unsetReq() {
+      this.req = null;
     }
 
-    /** Returns true if field names is set (has been assigned a value) and false otherwise */
-    public boolean isSetNames() {
-      return this.names != null;
+    /** Returns true if field req is set (has been assigned a value) and false otherwise */
+    public boolean isSetReq() {
+      return this.req != null;
     }
 
-    public void setNamesIsSet(boolean value) {
+    public void setReqIsSet(boolean value) {
       if (!value) {
-        this.names = null;
+        this.req = null;
       }
     }
 
     public void setFieldValue(_Fields field, Object value) {
       switch (field) {
-      case DB_NAME:
-        if (value == null) {
-          unsetDb_name();
-        } else {
-          setDb_name((String)value);
-        }
-        break;
-
-      case TBL_NAME:
-        if (value == null) {
-          unsetTbl_name();
-        } else {
-          setTbl_name((String)value);
-        }
-        break;
-
-      case NAMES:
+      case REQ:
         if (value == null) {
-          unsetNames();
+          unsetReq();
         } else {
-          setNames((List<String>)value);
+          setReq((PartitionsByExprRequest)value);
         }
         break;
 
@@ -81457,14 +80310,8 @@ public void setFieldValue(_Fields field, Object value) {
 
     public Object getFieldValue(_Fields field) {
       switch (field) {
-      case DB_NAME:
-        return getDb_name();
-
-      case TBL_NAME:
-        return getTbl_name();
-
-      case NAMES:
-        return getNames();
+      case REQ:
+        return getReq();
 
       }
       throw new IllegalStateException();
@@ -81477,12 +80324,8 @@ public boolean isSet(_Fields field) {
       }
 
       switch (field) {
-      case DB_NAME:
-        return isSetDb_name();
-      case TBL_NAME:
-        return isSetTbl_name();
-      case NAMES:
-        return isSetNames();
+      case REQ:
+        return isSetReq();
       }
       throw new IllegalStateException();
     }
@@ -81491,39 +80334,21 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof get_partitions_by_names_args)
-        return this.equals((get_partitions_by_names_args)that);
+      if (that instanceof get_partitions_by_expr_args)
+        return this.equals((get_partitions_by_expr_args)that);
       return false;
     }
 
-    public boolean equals(get_partitions_by_names_args that) {
+    public boolean equals(get_partitions_by_expr_args that) {
       if (that == null)
         return false;
 
-      boolean this_present_db_name = true && this.isSetDb_name();
-      boolean that_present_db_name = true && that.isSetDb_name();
-      if (this_present_db_name || that_present_db_name) {
-        if (!(this_present_db_name && that_present_db_name))
-          return false;
-        if (!this.db_name.equals(that.db_name))
-          return false;
-      }
-
-      boolean this_present_tbl_name = true && this.isSetTbl_name();
-      boolean that_present_tbl_name = true && that.isSetTbl_name();
-      if (this_present_tbl_name || that_present_tbl_name) {
-        if (!(this_present_tbl_name && that_present_tbl_name))
-          return false;
-        if (!this.tbl_name.equals(that.tbl_name))
-          return false;
-      }
-
-      boolean this_present_names = true && this.isSetNames();
-      boolean that_present_names = true && that.isSetNames();
-      if (this_present_names || that_present_names) {
-        if (!(this_present_names && that_present_names))
+      boolean this_present_req = true && this.isSetReq();
+      boolean that_present_req = true && that.isSetReq();
+      if (this_present_req || that_present_req) {
+        if (!(this_present_req && that_present_req))
           return false;
-        if (!this.names.equals(that.names))
+        if (!this.req.equals(that.req))
           return false;
       }
 
@@ -81534,58 +80359,28 @@ public boolean equals(get_partitions_by_names_args that) {
     public int hashCode() {
       HashCodeBuilder builder = new HashCodeBuilder();
 
-      boolean present_db_name = true && (isSetDb_name());
-      builder.append(present_db_name);
-      if (present_db_name)
-        builder.append(db_name);
-
-      boolean present_tbl_name = true && (isSetTbl_name());
-      builder.append(present_tbl_name);
-      if (present_tbl_name)
-        builder.append(tbl_name);
-
-      boolean present_names = true && (isSetNames());
-      builder.append(present_names);
-      if (present_names)
-        builder.append(names);
+      boolean present_req = true && (isSetReq());
+      builder.append(present_req);
+      if (present_req)
+        builder.append(req);
 
       return builder.toHashCode();
     }
 
-    public int compareTo(get_partitions_by_names_args other) {
+    public int compareTo(get_partitions_by_expr_args other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      get_partitions_by_names_args typedOther = (get_partitions_by_names_args)other;
+      get_partitions_by_expr_args typedOther = (get_partitions_by_expr_args)other;
 
-      lastComparison = Boolean.valueOf(isSetDb_name()).compareTo(typedOther.isSetDb_name());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetDb_name()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.db_name, typedOther.db_name);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      lastComparison = Boolean.valueOf(isSetTbl_name()).compareTo(typedOther.isSetTbl_name());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetTbl_name()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.tbl_name, typedOther.tbl_name);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
-      lastComparison = Boolean.valueOf(isSetNames()).compareTo(typedOther.isSetNames());
+      lastComparison = Boolean.valueOf(isSetReq()).compareTo(typedOther.isSetReq());
       if (lastComparison != 0) {
         return lastComparison;
       }
-      if (isSetNames()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.names, typedOther.names);
+      if (isSetReq()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.req, typedOther.req);
         if (lastComparison != 0) {
           return lastComparison;
         }
@@ -81607,30 +80402,14 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("get_partitions_by_names_args(");
+      StringBuilder sb = new StringBuilder("get_partitions_by_expr_args(");
       boolean first = true;
 
-      sb.append("db_name:");
-      if (this.db_name == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.db_name);
-      }
-      first = false;
-      if (!first) sb.append(", ");
-      sb.append("tbl_name:");
-      if (this.tbl_name == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.tbl_name);
-      }
-      first = false;
-      if (!first) sb.append(", ");
-      sb.append("names:");
-      if (this.names == null) {
+      sb.append("req:");
+      if (this.req == null) {
         sb.append("null");
       } else {
-        sb.append(this.names);
+        sb.append(this.req);
       }
       first = false;
       sb.append(")");
@@ -81640,6 +80419,9 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
+      if (req != null) {
+        req.validate();
+      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -81658,15 +80440,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class get_partitions_by_names_argsStandardSchemeFactory implements SchemeFactory {
-      public get_partitions_by_names_argsStandardScheme getScheme() {
-        return new get_partitions_by_names_argsStandardScheme();
+    private static class get_partitions_by_expr_argsStandardSchemeFactory implements SchemeFactory {
+      public get_partitions_by_expr_argsStandardScheme getScheme() {
+        return new get_partitions_by_expr_argsStandardScheme();
       }
     }
 
-    private static class get_partitions_by_names_argsStandardScheme extends StandardScheme<get_partitions_by_names_args> {
+    private static class get_partitions_by_expr_argsStandardScheme extends StandardScheme<get_partitions_by_expr_args> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -81676,36 +80458,11 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_n
             break;
           }
           switch (schemeField.id) {
-            case 1: // DB_NAME
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
-                struct.db_name = iprot.readString();
-                struct.setDb_nameIsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            case 2: // TBL_NAME
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
-                struct.tbl_name = iprot.readString();
-                struct.setTbl_nameIsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
-            case 3: // NAMES
-              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
-                {
-                  org.apache.thrift.protocol.TList _list850 = iprot.readListBegin();
-                  struct.names = new ArrayList<String>(_list850.size);
-                  for (int _i851 = 0; _i851 < _list850.size; ++_i851)
-                  {
-                    String _elem852; // required
-                    _elem852 = iprot.readString();
-                    struct.names.add(_elem852);
-                  }
-                  iprot.readListEnd();
-                }
-                struct.setNamesIsSet(true);
+            case 1: // REQ
+              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+                struct.req = new PartitionsByExprRequest();
+                struct.req.read(iprot);
+                struct.setReqIsSet(true);
               } else { 
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
@@ -81719,30 +80476,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_n
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
-        if (struct.db_name != null) {
-          oprot.writeFieldBegin(DB_NAME_FIELD_DESC);
-          oprot.writeString(struct.db_name);
-          oprot.writeFieldEnd();
-        }
-        if (struct.tbl_name != null) {
-          oprot.writeFieldBegin(TBL_NAME_FIELD_DESC);
-          oprot.writeString(struct.tbl_name);
-          oprot.writeFieldEnd();
-        }
-        if (struct.names != null) {
-          oprot.writeFieldBegin(NAMES_FIELD_DESC);
-          {
-            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.names.size()));
-            for (String _iter853 : struct.names)
-            {
-              oprot.writeString(_iter853);
-            }
-            oprot.writeListEnd();
-          }
+        if (struct.req != null) {
+          oprot.writeFieldBegin(REQ_FIELD_DESC);
+          struct.req.write(oprot);
           oprot.writeFieldEnd();
         }
         oprot.writeFieldStop();
@@ -81751,89 +80491,55 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_
 
     }
 
-    private static class get_partitions_by_names_argsTupleSchemeFactory implements SchemeFactory {
-      public get_partitions_by_names_argsTupleScheme getScheme() {
-        return new get_partitions_by_names_argsTupleScheme();
+    private static class get_partitions_by_expr_argsTupleSchemeFactory implements SchemeFactory {
+      public get_partitions_by_expr_argsTupleScheme getScheme() {
+        return new get_partitions_by_expr_argsTupleScheme();
       }
     }
 
-    private static class get_partitions_by_names_argsTupleScheme extends TupleScheme<get_partitions_by_names_args> {
+    private static class get_partitions_by_expr_argsTupleScheme extends TupleScheme<get_partitions_by_expr_args> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
-        if (struct.isSetDb_name()) {
+        if (struct.isSetReq()) {
           optionals.set(0);
         }
-        if (struct.isSetTbl_name()) {
-          optionals.set(1);
-        }
-        if (struct.isSetNames()) {
-          optionals.set(2);
-        }
-        oprot.writeBitSet(optionals, 3);
-        if (struct.isSetDb_name()) {
-          oprot.writeString(struct.db_name);
-        }
-        if (struct.isSetTbl_name()) {
-          oprot.writeString(struct.tbl_name);
-        }
-        if (struct.isSetNames()) {
-          {
-            oprot.writeI32(struct.names.size());
-            for (String _iter854 : struct.names)
-            {
-              oprot.writeString(_iter854);
-            }
-          }
+        oprot.writeBitSet(optionals, 1);
+        if (struct.isSetReq()) {
+          struct.req.write(oprot);
         }
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_args struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
-        BitSet incoming = iprot.readBitSet(3);
+        BitSet incoming = iprot.readBitSet(1);
         if (incoming.get(0)) {
-          struct.db_name = iprot.readString();
-          struct.setDb_nameIsSet(true);
-        }
-        if (incoming.get(1)) {
-          struct.tbl_name = iprot.readString();
-          struct.setTbl_nameIsSet(true);
-        }
-        if (incoming.get(2)) {
-          {
-            org.apache.thrift.protocol.TList _list855 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.names = new ArrayList<String>(_list855.size);
-            for (int _i856 = 0; _i856 < _list855.size; ++_i856)
-            {
-              String _elem857; // required
-              _elem857 = iprot.readString();
-              struct.names.add(_elem857);
-            }
-          }
-          struct.setNamesIsSet(true);
+          struct.req = new PartitionsByExprRequest();
+          struct.req.read(iprot);
+          struct.setReqIsSet(true);
         }
       }
     }
 
   }
 
-  public static class get_partitions_by_names_result implements org.apache.thrift.TBase<get_partitions_by_names_result, get_partitions_by_names_result._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_names_result");
+  public static class get_partitions_by_expr_result implements org.apache.thrift.TBase<get_partitions_by_expr_result, get_partitions_by_expr_result._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_expr_result");
 
-    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.LIST, (short)0);
+    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);
     private static final org.apache.thrift.protocol.TField O1_FIELD_DESC = new org.apache.thrift.protocol.TField("o1", org.apache.thrift.protocol.TType.STRUCT, (short)1);
     private static final org.apache.thrift.protocol.TField O2_FIELD_DESC = new org.apache.thrift.protocol.TField("o2", org.apache.thrift.protocol.TType.STRUCT, (short)2);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new get_partitions_by_names_resultStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new get_partitions_by_names_resultTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new get_partitions_by_expr_resultStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new get_partitions_by_expr_resultTupleSchemeFactory());
     }
 
-    private List<Partition> success; // required
+    private PartitionsByExprResult success; // required
     private MetaException o1; // required
     private NoSuchObjectException o2; // required
 
@@ -81906,21 +80612,20 @@ public String getFieldName() {
     static {
       Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
       tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
-              new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class))));
+          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PartitionsByExprResult.class)));
       tmpMap.put(_Fields.O1, new org.apache.thrift.meta_data.FieldMetaData("o1", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_names_result.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_expr_result.class, metaDataMap);
     }
 
-    public get_partitions_by_names_result() {
+    public get_partitions_by_expr_result() {
     }
 
-    public get_partitions_by_names_result(
-      List<Partition> success,
+    public get_partitions_by_expr_result(
+      PartitionsByExprResult success,
       MetaException o1,
       NoSuchObjectException o2)
     {
@@ -81933,13 +80638,9 @@ public get_partitions_by_names_result(
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public get_partitions_by_names_result(get_partitions_by_names_result other) {
+    public get_partitions_by_expr_result(get_partitions_by_expr_result other) {
       if (other.isSetSuccess()) {
-        List<Partition> __this__success = new ArrayList<Partition>();
-        for (Partition other_element : other.success) {
-          __this__success.add(new Partition(other_element));
-        }
-        this.success = __this__success;
+        this.success = new PartitionsByExprResult(other.success);
       }
       if (other.isSetO1()) {
         this.o1 = new MetaException(other.o1);
@@ -81949,8 +80650,8 @@ public get_partitions_by_names_result(get_partitions_by_names_result other) {
       }
     }
 
-    public get_partitions_by_names_result deepCopy() {
-      return new get_partitions_by_names_result(this);
+    public get_partitions_by_expr_result deepCopy() {
+      return new get_partitions_by_expr_result(this);
     }
 
     @Override
@@ -81960,26 +80661,11 @@ public void clear() {
       this.o2 = null;
     }
 
-    public int getSuccessSize() {
-      return (this.success == null) ? 0 : this.success.size();
-    }
-
-    public java.util.Iterator<Partition> getSuccessIterator() {
-      return (this.success == null) ? null : this.success.iterator();
-    }
-
-    public void addToSuccess(Partition elem) {
-      if (this.success == null) {
-        this.success = new ArrayList<Partition>();
-      }
-      this.success.add(elem);
-    }
-
-    public List<Partition> getSuccess() {
+    public PartitionsByExprResult getSuccess() {
       return this.success;
     }
 
-    public void setSuccess(List<Partition> success) {
+    public void setSuccess(PartitionsByExprResult success) {
       this.success = success;
     }
 
@@ -82050,7 +80736,7 @@ public void setFieldValue(_Fields field, Object value) {
         if (value == null) {
           unsetSuccess();
         } else {
-          setSuccess((List<Partition>)value);
+          setSuccess((PartitionsByExprResult)value);
         }
         break;
 
@@ -82109,12 +80795,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof get_partitions_by_names_result)
-        return this.equals((get_partitions_by_names_result)that);
+      if (that instanceof get_partitions_by_expr_result)
+        return this.equals((get_partitions_by_expr_result)that);
       return false;
     }
 
-    public boolean equals(get_partitions_by_names_result that) {
+    public boolean equals(get_partitions_by_expr_result that) {
       if (that == null)
         return false;
 
@@ -82170,13 +80856,13 @@ public int hashCode() {
       return builder.toHashCode();
     }
 
-    public int compareTo(get_partitions_by_names_result other) {
+    public int compareTo(get_partitions_by_expr_result other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      get_partitions_by_names_result typedOther = (get_partitions_by_names_result)other;
+      get_partitions_by_expr_result typedOther = (get_partitions_by_expr_result)other;
 
       lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(typedOther.isSetSuccess());
       if (lastComparison != 0) {
@@ -82225,7 +80911,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("get_partitions_by_names_result(");
+      StringBuilder sb = new StringBuilder("get_partitions_by_expr_result(");
       boolean first = true;
 
       sb.append("success:");
@@ -82258,6 +80944,9 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
+      if (success != null) {
+        success.validate();
+      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -82276,15 +80965,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class get_partitions_by_names_resultStandardSchemeFactory implements SchemeFactory {
-      public get_partitions_by_names_resultStandardScheme getScheme() {
-        return new get_partitions_by_names_resultStandardScheme();
+    private static class get_partitions_by_expr_resultStandardSchemeFactory implements SchemeFactory {
+      public get_partitions_by_expr_resultStandardScheme getScheme() {
+        return new get_partitions_by_expr_resultStandardScheme();
       }
     }
 
-    private static class get_partitions_by_names_resultStandardScheme extends StandardScheme<get_partitions_by_names_result> {
+    private static class get_partitions_by_expr_resultStandardScheme extends StandardScheme<get_partitions_by_expr_result> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -82295,19 +80984,9 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_n
           }
           switch (schemeField.id) {
             case 0: // SUCCESS
-              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
-                {
-                  org.apache.thrift.protocol.TList _list858 = iprot.readListBegin();
-                  struct.success = new ArrayList<Partition>(_list858.size);
-                  for (int _i859 = 0; _i859 < _list858.size; ++_i859)
-                  {
-                    Partition _elem860; // required
-                    _elem860 = new Partition();
-                    _elem860.read(iprot);
-                    struct.success.add(_elem860);
-                  }
-                  iprot.readListEnd();
-                }
+              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+                struct.success = new PartitionsByExprResult();
+                struct.success.read(iprot);
                 struct.setSuccessIsSet(true);
               } else { 
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
@@ -82340,20 +81019,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_n
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
         if (struct.success != null) {
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
-          {
-            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
-            for (Partition _iter861 : struct.success)
-            {
-              _iter861.write(oprot);
-            }
-            oprot.writeListEnd();
-          }
+          struct.success.write(oprot);
           oprot.writeFieldEnd();
         }
         if (struct.o1 != null) {
@@ -82372,16 +81044,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_
 
     }
 
-    private static class get_partitions_by_names_resultTupleSchemeFactory implements SchemeFactory {
-      public get_partitions_by_names_resultTupleScheme getScheme() {
-        return new get_partitions_by_names_resultTupleScheme();
+    private static class get_partitions_by_expr_resultTupleSchemeFactory implements SchemeFactory {
+      public get_partitions_by_expr_resultTupleScheme getScheme() {
+        return new get_partitions_by_expr_resultTupleScheme();
       }
     }
 
-    private static class get_partitions_by_names_resultTupleScheme extends TupleScheme<get_partitions_by_names_result> {
+    private static class get_partitions_by_expr_resultTupleScheme extends TupleScheme<get_partitions_by_expr_result> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetSuccess()) {
@@ -82395,13 +81067,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_n
         }
         oprot.writeBitSet(optionals, 3);
         if (struct.isSetSuccess()) {
-          {
-            oprot.writeI32(struct.success.size());
-            for (Partition _iter862 : struct.success)
-            {
-              _iter862.write(oprot);
-            }
-          }
+          struct.success.write(oprot);
         }
         if (struct.isSetO1()) {
           struct.o1.write(oprot);
@@ -82412,21 +81078,12 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_n
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_expr_result struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
-          {
-            org.apache.thrift.protocol.TList _list863 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.success = new ArrayList<Partition>(_list863.size);
-            for (int _i864 = 0; _i864 < _list863.size; ++_i864)
-            {
-              Partition _elem865; // required
-              _elem865 = new Partition();
-              _elem865.read(iprot);
-              struct.success.add(_elem865);
-            }
-          }
+          struct.success = new PartitionsByExprResult();
+          struct.success.read(iprot);
           struct.setSuccessIsSet(true);
         }
         if (incoming.get(1)) {
@@ -82444,28 +81101,28 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_na
 
   }
 
-  public static class alter_partition_args implements org.apache.thrift.TBase<alter_partition_args, alter_partition_args._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partition_args");
+  public static class get_partitions_by_names_args implements org.apache.thrift.TBase<get_partitions_by_names_args, get_partitions_by_names_args._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_names_args");
 
     private static final org.apache.thrift.protocol.TField DB_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("db_name", org.apache.thrift.protocol.TType.STRING, (short)1);
     private static final org.apache.thrift.protocol.TField TBL_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("tbl_name", org.apache.thrift.protocol.TType.STRING, (short)2);
-    private static final org.apache.thrift.protocol.TField NEW_PART_FIELD_DESC = new org.apache.thrift.protocol.TField("new_part", org.apache.thrift.protocol.TType.STRUCT, (short)3);
+    private static final org.apache.thrift.protocol.TField NAMES_FIELD_DESC = new org.apache.thrift.protocol.TField("names", org.apache.thrift.protocol.TType.LIST, (short)3);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partition_argsStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partition_argsTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new get_partitions_by_names_argsStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new get_partitions_by_names_argsTupleSchemeFactory());
     }
 
     private String db_name; // required
     private String tbl_name; // required
-    private Partition new_part; // required
+    private List<String> names; // required
 
     /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
     public enum _Fields implements org.apache.thrift.TFieldIdEnum {
       DB_NAME((short)1, "db_name"),
       TBL_NAME((short)2, "tbl_name"),
-      NEW_PART((short)3, "new_part");
+      NAMES((short)3, "names");
 
       private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
 
@@ -82484,8 +81141,8 @@ public static _Fields findByThriftId(int fieldId) {
             return DB_NAME;
           case 2: // TBL_NAME
             return TBL_NAME;
-          case 3: // NEW_PART
-            return NEW_PART;
+          case 3: // NAMES
+            return NAMES;
           default:
             return null;
         }
@@ -82533,50 +81190,55 @@ public String getFieldName() {
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
       tmpMap.put(_Fields.TBL_NAME, new org.apache.thrift.meta_data.FieldMetaData("tbl_name", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
-      tmpMap.put(_Fields.NEW_PART, new org.apache.thrift.meta_data.FieldMetaData("new_part", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class)));
+      tmpMap.put(_Fields.NAMES, new org.apache.thrift.meta_data.FieldMetaData("names", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
+              new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partition_args.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_names_args.class, metaDataMap);
     }
 
-    public alter_partition_args() {
+    public get_partitions_by_names_args() {
     }
 
-    public alter_partition_args(
+    public get_partitions_by_names_args(
       String db_name,
       String tbl_name,
-      Partition new_part)
+      List<String> names)
     {
       this();
       this.db_name = db_name;
       this.tbl_name = tbl_name;
-      this.new_part = new_part;
+      this.names = names;
     }
 
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partition_args(alter_partition_args other) {
+    public get_partitions_by_names_args(get_partitions_by_names_args other) {
       if (other.isSetDb_name()) {
         this.db_name = other.db_name;
       }
       if (other.isSetTbl_name()) {
         this.tbl_name = other.tbl_name;
       }
-      if (other.isSetNew_part()) {
-        this.new_part = new Partition(other.new_part);
+      if (other.isSetNames()) {
+        List<String> __this__names = new ArrayList<String>();
+        for (String other_element : other.names) {
+          __this__names.add(other_element);
+        }
+        this.names = __this__names;
       }
     }
 
-    public alter_partition_args deepCopy() {
-      return new alter_partition_args(this);
+    public get_partitions_by_names_args deepCopy() {
+      return new get_partitions_by_names_args(this);
     }
 
     @Override
     public void clear() {
       this.db_name = null;
       this.tbl_name = null;
-      this.new_part = null;
+      this.names = null;
     }
 
     public String getDb_name() {
@@ -82625,26 +81287,41 @@ public void setTbl_nameIsSet(boolean value) {
       }
     }
 
-    public Partition getNew_part() {
-      return this.new_part;
+    public int getNamesSize() {
+      return (this.names == null) ? 0 : this.names.size();
     }
 
-    public void setNew_part(Partition new_part) {
-      this.new_part = new_part;
+    public java.util.Iterator<String> getNamesIterator() {
+      return (this.names == null) ? null : this.names.iterator();
     }
 
-    public void unsetNew_part() {
-      this.new_part = null;
+    public void addToNames(String elem) {
+      if (this.names == null) {
+        this.names = new ArrayList<String>();
+      }
+      this.names.add(elem);
     }
 
-    /** Returns true if field new_part is set (has been assigned a value) and false otherwise */
-    public boolean isSetNew_part() {
-      return this.new_part != null;
+    public List<String> getNames() {
+      return this.names;
     }
 
-    public void setNew_partIsSet(boolean value) {
+    public void setNames(List<String> names) {
+      this.names = names;
+    }
+
+    public void unsetNames() {
+      this.names = null;
+    }
+
+    /** Returns true if field names is set (has been assigned a value) and false otherwise */
+    public boolean isSetNames() {
+      return this.names != null;
+    }
+
+    public void setNamesIsSet(boolean value) {
       if (!value) {
-        this.new_part = null;
+        this.names = null;
       }
     }
 
@@ -82666,11 +81343,11 @@ public void setFieldValue(_Fields field, Object value) {
         }
         break;
 
-      case NEW_PART:
+      case NAMES:
         if (value == null) {
-          unsetNew_part();
+          unsetNames();
         } else {
-          setNew_part((Partition)value);
+          setNames((List<String>)value);
         }
         break;
 
@@ -82685,8 +81362,8 @@ public Object getFieldValue(_Fields field) {
       case TBL_NAME:
         return getTbl_name();
 
-      case NEW_PART:
-        return getNew_part();
+      case NAMES:
+        return getNames();
 
       }
       throw new IllegalStateException();
@@ -82703,8 +81380,8 @@ public boolean isSet(_Fields field) {
         return isSetDb_name();
       case TBL_NAME:
         return isSetTbl_name();
-      case NEW_PART:
-        return isSetNew_part();
+      case NAMES:
+        return isSetNames();
       }
       throw new IllegalStateException();
     }
@@ -82713,12 +81390,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partition_args)
-        return this.equals((alter_partition_args)that);
+      if (that instanceof get_partitions_by_names_args)
+        return this.equals((get_partitions_by_names_args)that);
       return false;
     }
 
-    public boolean equals(alter_partition_args that) {
+    public boolean equals(get_partitions_by_names_args that) {
       if (that == null)
         return false;
 
@@ -82740,12 +81417,12 @@ public boolean equals(alter_partition_args that) {
           return false;
       }
 
-      boolean this_present_new_part = true && this.isSetNew_part();
-      boolean that_present_new_part = true && that.isSetNew_part();
-      if (this_present_new_part || that_present_new_part) {
-        if (!(this_present_new_part && that_present_new_part))
+      boolean this_present_names = true && this.isSetNames();
+      boolean that_present_names = true && that.isSetNames();
+      if (this_present_names || that_present_names) {
+        if (!(this_present_names && that_present_names))
           return false;
-        if (!this.new_part.equals(that.new_part))
+        if (!this.names.equals(that.names))
           return false;
       }
 
@@ -82766,21 +81443,21 @@ public int hashCode() {
       if (present_tbl_name)
         builder.append(tbl_name);
 
-      boolean present_new_part = true && (isSetNew_part());
-      builder.append(present_new_part);
-      if (present_new_part)
-        builder.append(new_part);
+      boolean present_names = true && (isSetNames());
+      builder.append(present_names);
+      if (present_names)
+        builder.append(names);
 
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partition_args other) {
+    public int compareTo(get_partitions_by_names_args other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partition_args typedOther = (alter_partition_args)other;
+      get_partitions_by_names_args typedOther = (get_partitions_by_names_args)other;
 
       lastComparison = Boolean.valueOf(isSetDb_name()).compareTo(typedOther.isSetDb_name());
       if (lastComparison != 0) {
@@ -82802,12 +81479,12 @@ public int compareTo(alter_partition_args other) {
           return lastComparison;
         }
       }
-      lastComparison = Boolean.valueOf(isSetNew_part()).compareTo(typedOther.isSetNew_part());
+      lastComparison = Boolean.valueOf(isSetNames()).compareTo(typedOther.isSetNames());
       if (lastComparison != 0) {
         return lastComparison;
       }
-      if (isSetNew_part()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.new_part, typedOther.new_part);
+      if (isSetNames()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.names, typedOther.names);
         if (lastComparison != 0) {
           return lastComparison;
         }
@@ -82829,7 +81506,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partition_args(");
+      StringBuilder sb = new StringBuilder("get_partitions_by_names_args(");
       boolean first = true;
 
       sb.append("db_name:");
@@ -82848,11 +81525,11 @@ public String toString() {
       }
       first = false;
       if (!first) sb.append(", ");
-      sb.append("new_part:");
-      if (this.new_part == null) {
+      sb.append("names:");
+      if (this.names == null) {
         sb.append("null");
       } else {
-        sb.append(this.new_part);
+        sb.append(this.names);
       }
       first = false;
       sb.append(")");
@@ -82862,9 +81539,6 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
-      if (new_part != null) {
-        new_part.validate();
-      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -82883,15 +81557,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partition_argsStandardSchemeFactory implements SchemeFactory {
-      public alter_partition_argsStandardScheme getScheme() {
-        return new alter_partition_argsStandardScheme();
+    private static class get_partitions_by_names_argsStandardSchemeFactory implements SchemeFactory {
+      public get_partitions_by_names_argsStandardScheme getScheme() {
+        return new get_partitions_by_names_argsStandardScheme();
       }
     }
 
-    private static class alter_partition_argsStandardScheme extends StandardScheme<alter_partition_args> {
+    private static class get_partitions_by_names_argsStandardScheme extends StandardScheme<get_partitions_by_names_args> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -82917,11 +81591,20 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_arg
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
               break;
-            case 3: // NEW_PART
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.new_part = new Partition();
-                struct.new_part.read(iprot);
-                struct.setNew_partIsSet(true);
+            case 3: // NAMES
+              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
+                {
+                  org.apache.thrift.protocol.TList _list850 = iprot.readListBegin();
+                  struct.names = new ArrayList<String>(_list850.size);
+                  for (int _i851 = 0; _i851 < _list850.size; ++_i851)
+                  {
+                    String _elem852; // required
+                    _elem852 = iprot.readString();
+                    struct.names.add(_elem852);
+                  }
+                  iprot.readListEnd();
+                }
+                struct.setNamesIsSet(true);
               } else { 
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
@@ -82935,7 +81618,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_arg
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
@@ -82949,9 +81632,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_ar
           oprot.writeString(struct.tbl_name);
           oprot.writeFieldEnd();
         }
-        if (struct.new_part != null) {
-          oprot.writeFieldBegin(NEW_PART_FIELD_DESC);
-          struct.new_part.write(oprot);
+        if (struct.names != null) {
+          oprot.writeFieldBegin(NAMES_FIELD_DESC);
+          {
+            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.names.size()));
+            for (String _iter853 : struct.names)
+            {
+              oprot.writeString(_iter853);
+            }
+            oprot.writeListEnd();
+          }
           oprot.writeFieldEnd();
         }
         oprot.writeFieldStop();
@@ -82960,16 +81650,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_ar
 
     }
 
-    private static class alter_partition_argsTupleSchemeFactory implements SchemeFactory {
-      public alter_partition_argsTupleScheme getScheme() {
-        return new alter_partition_argsTupleScheme();
+    private static class get_partitions_by_names_argsTupleSchemeFactory implements SchemeFactory {
+      public get_partitions_by_names_argsTupleScheme getScheme() {
+        return new get_partitions_by_names_argsTupleScheme();
       }
     }
 
-    private static class alter_partition_argsTupleScheme extends TupleScheme<alter_partition_args> {
+    private static class get_partitions_by_names_argsTupleScheme extends TupleScheme<get_partitions_by_names_args> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetDb_name()) {
@@ -82978,7 +81668,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_arg
         if (struct.isSetTbl_name()) {
           optionals.set(1);
         }
-        if (struct.isSetNew_part()) {
+        if (struct.isSetNames()) {
           optionals.set(2);
         }
         oprot.writeBitSet(optionals, 3);
@@ -82988,13 +81678,19 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_arg
         if (struct.isSetTbl_name()) {
           oprot.writeString(struct.tbl_name);
         }
-        if (struct.isSetNew_part()) {
-          struct.new_part.write(oprot);
+        if (struct.isSetNames()) {
+          {
+            oprot.writeI32(struct.names.size());
+            for (String _iter854 : struct.names)
+            {
+              oprot.writeString(_iter854);
+            }
+          }
         }
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_args struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
@@ -83006,32 +81702,43 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_args
           struct.setTbl_nameIsSet(true);
         }
         if (incoming.get(2)) {
-          struct.new_part = new Partition();
-          struct.new_part.read(iprot);
-          struct.setNew_partIsSet(true);
+          {
+            org.apache.thrift.protocol.TList _list855 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.names = new ArrayList<String>(_list855.size);
+            for (int _i856 = 0; _i856 < _list855.size; ++_i856)
+            {
+              String _elem857; // required
+              _elem857 = iprot.readString();
+              struct.names.add(_elem857);
+            }
+          }
+          struct.setNamesIsSet(true);
         }
       }
     }
 
   }
 
-  public static class alter_partition_result implements org.apache.thrift.TBase<alter_partition_result, alter_partition_result._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partition_result");
+  public static class get_partitions_by_names_result implements org.apache.thrift.TBase<get_partitions_by_names_result, get_partitions_by_names_result._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("get_partitions_by_names_result");
 
+    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.LIST, (short)0);
     private static final org.apache.thrift.protocol.TField O1_FIELD_DESC = new org.apache.thrift.protocol.TField("o1", org.apache.thrift.protocol.TType.STRUCT, (short)1);
     private static final org.apache.thrift.protocol.TField O2_FIELD_DESC = new org.apache.thrift.protocol.TField("o2", org.apache.thrift.protocol.TType.STRUCT, (short)2);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partition_resultStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partition_resultTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new get_partitions_by_names_resultStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new get_partitions_by_names_resultTupleSchemeFactory());
     }
 
-    private InvalidOperationException o1; // required
-    private MetaException o2; // required
+    private List<Partition> success; // required
+    private MetaException o1; // required
+    private NoSuchObjectException o2; // required
 
     /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
     public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+      SUCCESS((short)0, "success"),
       O1((short)1, "o1"),
       O2((short)2, "o2");
 
@@ -83048,6 +81755,8 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_args
        */
       public static _Fields findByThriftId(int fieldId) {
         switch(fieldId) {
+          case 0: // SUCCESS
+            return SUCCESS;
           case 1: // O1
             return O1;
           case 2: // O2
@@ -83095,22 +81804,27 @@ public String getFieldName() {
     public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
     static {
       Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
+              new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class))));
       tmpMap.put(_Fields.O1, new org.apache.thrift.meta_data.FieldMetaData("o1", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partition_result.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_partitions_by_names_result.class, metaDataMap);
     }
 
-    public alter_partition_result() {
+    public get_partitions_by_names_result() {
     }
 
-    public alter_partition_result(
-      InvalidOperationException o1,
-      MetaException o2)
+    public get_partitions_by_names_result(
+      List<Partition> success,
+      MetaException o1,
+      NoSuchObjectException o2)
     {
       this();
+      this.success = success;
       this.o1 = o1;
       this.o2 = o2;
     }
@@ -83118,30 +81832,76 @@ public alter_partition_result(
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partition_result(alter_partition_result other) {
+    public get_partitions_by_names_result(get_partitions_by_names_result other) {
+      if (other.isSetSuccess()) {
+        List<Partition> __this__success = new ArrayList<Partition>();
+        for (Partition other_element : other.success) {
+          __this__success.add(new Partition(other_element));
+        }
+        this.success = __this__success;
+      }
       if (other.isSetO1()) {
-        this.o1 = new InvalidOperationException(other.o1);
+        this.o1 = new MetaException(other.o1);
       }
       if (other.isSetO2()) {
-        this.o2 = new MetaException(other.o2);
+        this.o2 = new NoSuchObjectException(other.o2);
       }
     }
 
-    public alter_partition_result deepCopy() {
-      return new alter_partition_result(this);
+    public get_partitions_by_names_result deepCopy() {
+      return new get_partitions_by_names_result(this);
     }
 
     @Override
     public void clear() {
+      this.success = null;
       this.o1 = null;
       this.o2 = null;
     }
 
-    public InvalidOperationException getO1() {
+    public int getSuccessSize() {
+      return (this.success == null) ? 0 : this.success.size();
+    }
+
+    public java.util.Iterator<Partition> getSuccessIterator() {
+      return (this.success == null) ? null : this.success.iterator();
+    }
+
+    public void addToSuccess(Partition elem) {
+      if (this.success == null) {
+        this.success = new ArrayList<Partition>();
+      }
+      this.success.add(elem);
+    }
+
+    public List<Partition> getSuccess() {
+      return this.success;
+    }
+
+    public void setSuccess(List<Partition> success) {
+      this.success = success;
+    }
+
+    public void unsetSuccess() {
+      this.success = null;
+    }
+
+    /** Returns true if field success is set (has been assigned a value) and false otherwise */
+    public boolean isSetSuccess() {
+      return this.success != null;
+    }
+
+    public void setSuccessIsSet(boolean value) {
+      if (!value) {
+        this.success = null;
+      }
+    }
+
+    public MetaException getO1() {
       return this.o1;
     }
 
-    public void setO1(InvalidOperationException o1) {
+    public void setO1(MetaException o1) {
       this.o1 = o1;
     }
 
@@ -83160,11 +81920,11 @@ public void setO1IsSet(boolean value) {
       }
     }
 
-    public MetaException getO2() {
+    public NoSuchObjectException getO2() {
       return this.o2;
     }
 
-    public void setO2(MetaException o2) {
+    public void setO2(NoSuchObjectException o2) {
       this.o2 = o2;
     }
 
@@ -83185,11 +81945,19 @@ public void setO2IsSet(boolean value) {
 
     public void setFieldValue(_Fields field, Object value) {
       switch (field) {
+      case SUCCESS:
+        if (value == null) {
+          unsetSuccess();
+        } else {
+          setSuccess((List<Partition>)value);
+        }
+        break;
+
       case O1:
         if (value == null) {
           unsetO1();
         } else {
-          setO1((InvalidOperationException)value);
+          setO1((MetaException)value);
         }
         break;
 
@@ -83197,7 +81965,7 @@ public void setFieldValue(_Fields field, Object value) {
         if (value == null) {
           unsetO2();
         } else {
-          setO2((MetaException)value);
+          setO2((NoSuchObjectException)value);
         }
         break;
 
@@ -83206,6 +81974,9 @@ public void setFieldValue(_Fields field, Object value) {
 
     public Object getFieldValue(_Fields field) {
       switch (field) {
+      case SUCCESS:
+        return getSuccess();
+
       case O1:
         return getO1();
 
@@ -83223,6 +81994,8 @@ public boolean isSet(_Fields field) {
       }
 
       switch (field) {
+      case SUCCESS:
+        return isSetSuccess();
       case O1:
         return isSetO1();
       case O2:
@@ -83235,15 +82008,24 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partition_result)
-        return this.equals((alter_partition_result)that);
+      if (that instanceof get_partitions_by_names_result)
+        return this.equals((get_partitions_by_names_result)that);
       return false;
     }
 
-    public boolean equals(alter_partition_result that) {
+    public boolean equals(get_partitions_by_names_result that) {
       if (that == null)
         return false;
 
+      boolean this_present_success = true && this.isSetSuccess();
+      boolean that_present_success = true && that.isSetSuccess();
+      if (this_present_success || that_present_success) {
+        if (!(this_present_success && that_present_success))
+          return false;
+        if (!this.success.equals(that.success))
+          return false;
+      }
+
       boolean this_present_o1 = true && this.isSetO1();
       boolean that_present_o1 = true && that.isSetO1();
       if (this_present_o1 || that_present_o1) {
@@ -83269,6 +82051,11 @@ public boolean equals(alter_partition_result that) {
     public int hashCode() {
       HashCodeBuilder builder = new HashCodeBuilder();
 
+      boolean present_success = true && (isSetSuccess());
+      builder.append(present_success);
+      if (present_success)
+        builder.append(success);
+
       boolean present_o1 = true && (isSetO1());
       builder.append(present_o1);
       if (present_o1)
@@ -83282,14 +82069,24 @@ public int hashCode() {
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partition_result other) {
+    public int compareTo(get_partitions_by_names_result other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partition_result typedOther = (alter_partition_result)other;
+      get_partitions_by_names_result typedOther = (get_partitions_by_names_result)other;
 
+      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(typedOther.isSetSuccess());
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+      if (isSetSuccess()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, typedOther.success);
+        if (lastComparison != 0) {
+          return lastComparison;
+        }
+      }
       lastComparison = Boolean.valueOf(isSetO1()).compareTo(typedOther.isSetO1());
       if (lastComparison != 0) {
         return lastComparison;
@@ -83327,9 +82124,17 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partition_result(");
+      StringBuilder sb = new StringBuilder("get_partitions_by_names_result(");
       boolean first = true;
 
+      sb.append("success:");
+      if (this.success == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.success);
+      }
+      first = false;
+      if (!first) sb.append(", ");
       sb.append("o1:");
       if (this.o1 == null) {
         sb.append("null");
@@ -83370,15 +82175,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partition_resultStandardSchemeFactory implements SchemeFactory {
-      public alter_partition_resultStandardScheme getScheme() {
-        return new alter_partition_resultStandardScheme();
+    private static class get_partitions_by_names_resultStandardSchemeFactory implements SchemeFactory {
+      public get_partitions_by_names_resultStandardScheme getScheme() {
+        return new get_partitions_by_names_resultStandardScheme();
       }
     }
 
-    private static class alter_partition_resultStandardScheme extends StandardScheme<alter_partition_result> {
+    private static class get_partitions_by_names_resultStandardScheme extends StandardScheme<get_partitions_by_names_result> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -83388,9 +82193,28 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_res
             break;
           }
           switch (schemeField.id) {
+            case 0: // SUCCESS
+              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
+                {
+                  org.apache.thrift.protocol.TList _list858 = iprot.readListBegin();
+                  struct.success = new ArrayList<Partition>(_list858.size);
+                  for (int _i859 = 0; _i859 < _list858.size; ++_i859)
+                  {
+                    Partition _elem860; // required
+                    _elem860 = new Partition();
+                    _elem860.read(iprot);
+                    struct.success.add(_elem860);
+                  }
+                  iprot.readListEnd();
+                }
+                struct.setSuccessIsSet(true);
+              } else { 
+                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+              }
+              break;
             case 1: // O1
               if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.o1 = new InvalidOperationException();
+                struct.o1 = new MetaException();
                 struct.o1.read(iprot);
                 struct.setO1IsSet(true);
               } else { 
@@ -83399,7 +82223,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_res
               break;
             case 2: // O2
               if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.o2 = new MetaException();
+                struct.o2 = new NoSuchObjectException();
                 struct.o2.read(iprot);
                 struct.setO2IsSet(true);
               } else { 
@@ -83415,10 +82239,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_res
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
+        if (struct.success != null) {
+          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
+          {
+            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
+            for (Partition _iter861 : struct.success)
+            {
+              _iter861.write(oprot);
+            }
+            oprot.writeListEnd();
+          }
+          oprot.writeFieldEnd();
+        }
         if (struct.o1 != null) {
           oprot.writeFieldBegin(O1_FIELD_DESC);
           struct.o1.write(oprot);
@@ -83435,25 +82271,37 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_re
 
     }
 
-    private static class alter_partition_resultTupleSchemeFactory implements SchemeFactory {
-      public alter_partition_resultTupleScheme getScheme() {
-        return new alter_partition_resultTupleScheme();
+    private static class get_partitions_by_names_resultTupleSchemeFactory implements SchemeFactory {
+      public get_partitions_by_names_resultTupleScheme getScheme() {
+        return new get_partitions_by_names_resultTupleScheme();
       }
     }
 
-    private static class alter_partition_resultTupleScheme extends TupleScheme<alter_partition_result> {
+    private static class get_partitions_by_names_resultTupleScheme extends TupleScheme<get_partitions_by_names_result> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
-        if (struct.isSetO1()) {
+        if (struct.isSetSuccess()) {
           optionals.set(0);
         }
-        if (struct.isSetO2()) {
+        if (struct.isSetO1()) {
           optionals.set(1);
         }
-        oprot.writeBitSet(optionals, 2);
+        if (struct.isSetO2()) {
+          optionals.set(2);
+        }
+        oprot.writeBitSet(optionals, 3);
+        if (struct.isSetSuccess()) {
+          {
+            oprot.writeI32(struct.success.size());
+            for (Partition _iter862 : struct.success)
+            {
+              _iter862.write(oprot);
+            }
+          }
+        }
         if (struct.isSetO1()) {
           struct.o1.write(oprot);
         }
@@ -83463,16 +82311,30 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_res
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, get_partitions_by_names_result struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
-        BitSet incoming = iprot.readBitSet(2);
+        BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
-          struct.o1 = new InvalidOperationException();
+          {
+            org.apache.thrift.protocol.TList _list863 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.success = new ArrayList<Partition>(_list863.size);
+            for (int _i864 = 0; _i864 < _list863.size; ++_i864)
+            {
+              Partition _elem865; // required
+              _elem865 = new Partition();
+              _elem865.read(iprot);
+              struct.success.add(_elem865);
+            }
+          }
+          struct.setSuccessIsSet(true);
+        }
+        if (incoming.get(1)) {
+          struct.o1 = new MetaException();
           struct.o1.read(iprot);
           struct.setO1IsSet(true);
         }
-        if (incoming.get(1)) {
-          struct.o2 = new MetaException();
+        if (incoming.get(2)) {
+          struct.o2 = new NoSuchObjectException();
           struct.o2.read(iprot);
           struct.setO2IsSet(true);
         }
@@ -83481,28 +82343,28 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_resu
 
   }
 
-  public static class alter_partitions_args implements org.apache.thrift.TBase<alter_partitions_args, alter_partitions_args._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_args");
+  public static class alter_partition_args implements org.apache.thrift.TBase<alter_partition_args, alter_partition_args._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partition_args");
 
     private static final org.apache.thrift.protocol.TField DB_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("db_name", org.apache.thrift.protocol.TType.STRING, (short)1);
     private static final org.apache.thrift.protocol.TField TBL_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("tbl_name", org.apache.thrift.protocol.TType.STRING, (short)2);
-    private static final org.apache.thrift.protocol.TField NEW_PARTS_FIELD_DESC = new org.apache.thrift.protocol.TField("new_parts", org.apache.thrift.protocol.TType.LIST, (short)3);
+    private static final org.apache.thrift.protocol.TField NEW_PART_FIELD_DESC = new org.apache.thrift.protocol.TField("new_part", org.apache.thrift.protocol.TType.STRUCT, (short)3);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partitions_argsStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partitions_argsTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new alter_partition_argsStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new alter_partition_argsTupleSchemeFactory());
     }
 
     private String db_name; // required
     private String tbl_name; // required
-    private List<Partition> new_parts; // required
+    private Partition new_part; // required
 
     /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
     public enum _Fields implements org.apache.thrift.TFieldIdEnum {
       DB_NAME((short)1, "db_name"),
       TBL_NAME((short)2, "tbl_name"),
-      NEW_PARTS((short)3, "new_parts");
+      NEW_PART((short)3, "new_part");
 
       private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
 
@@ -83521,8 +82383,8 @@ public static _Fields findByThriftId(int fieldId) {
             return DB_NAME;
           case 2: // TBL_NAME
             return TBL_NAME;
-          case 3: // NEW_PARTS
-            return NEW_PARTS;
+          case 3: // NEW_PART
+            return NEW_PART;
           default:
             return null;
         }
@@ -83570,55 +82432,50 @@ public String getFieldName() {
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
       tmpMap.put(_Fields.TBL_NAME, new org.apache.thrift.meta_data.FieldMetaData("tbl_name", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
-      tmpMap.put(_Fields.NEW_PARTS, new org.apache.thrift.meta_data.FieldMetaData("new_parts", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
-              new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class))));
+      tmpMap.put(_Fields.NEW_PART, new org.apache.thrift.meta_data.FieldMetaData("new_part", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_args.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partition_args.class, metaDataMap);
     }
 
-    public alter_partitions_args() {
+    public alter_partition_args() {
     }
 
-    public alter_partitions_args(
+    public alter_partition_args(
       String db_name,
       String tbl_name,
-      List<Partition> new_parts)
+      Partition new_part)
     {
       this();
       this.db_name = db_name;
       this.tbl_name = tbl_name;
-      this.new_parts = new_parts;
+      this.new_part = new_part;
     }
 
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partitions_args(alter_partitions_args other) {
+    public alter_partition_args(alter_partition_args other) {
       if (other.isSetDb_name()) {
         this.db_name = other.db_name;
       }
       if (other.isSetTbl_name()) {
         this.tbl_name = other.tbl_name;
       }
-      if (other.isSetNew_parts()) {
-        List<Partition> __this__new_parts = new ArrayList<Partition>();
-        for (Partition other_element : other.new_parts) {
-          __this__new_parts.add(new Partition(other_element));
-        }
-        this.new_parts = __this__new_parts;
+      if (other.isSetNew_part()) {
+        this.new_part = new Partition(other.new_part);
       }
     }
 
-    public alter_partitions_args deepCopy() {
-      return new alter_partitions_args(this);
+    public alter_partition_args deepCopy() {
+      return new alter_partition_args(this);
     }
 
     @Override
     public void clear() {
       this.db_name = null;
       this.tbl_name = null;
-      this.new_parts = null;
+      this.new_part = null;
     }
 
     public String getDb_name() {
@@ -83667,41 +82524,26 @@ public void setTbl_nameIsSet(boolean value) {
       }
     }
 
-    public int getNew_partsSize() {
-      return (this.new_parts == null) ? 0 : this.new_parts.size();
-    }
-
-    public java.util.Iterator<Partition> getNew_partsIterator() {
-      return (this.new_parts == null) ? null : this.new_parts.iterator();
-    }
-
-    public void addToNew_parts(Partition elem) {
-      if (this.new_parts == null) {
-        this.new_parts = new ArrayList<Partition>();
-      }
-      this.new_parts.add(elem);
-    }
-
-    public List<Partition> getNew_parts() {
-      return this.new_parts;
+    public Partition getNew_part() {
+      return this.new_part;
     }
 
-    public void setNew_parts(List<Partition> new_parts) {
-      this.new_parts = new_parts;
+    public void setNew_part(Partition new_part) {
+      this.new_part = new_part;
     }
 
-    public void unsetNew_parts() {
-      this.new_parts = null;
+    public void unsetNew_part() {
+      this.new_part = null;
     }
 
-    /** Returns true if field new_parts is set (has been assigned a value) and false otherwise */
-    public boolean isSetNew_parts() {
-      return this.new_parts != null;
+    /** Returns true if field new_part is set (has been assigned a value) and false otherwise */
+    public boolean isSetNew_part() {
+      return this.new_part != null;
     }
 
-    public void setNew_partsIsSet(boolean value) {
+    public void setNew_partIsSet(boolean value) {
       if (!value) {
-        this.new_parts = null;
+        this.new_part = null;
       }
     }
 
@@ -83723,11 +82565,11 @@ public void setFieldValue(_Fields field, Object value) {
         }
         break;
 
-      case NEW_PARTS:
+      case NEW_PART:
         if (value == null) {
-          unsetNew_parts();
+          unsetNew_part();
         } else {
-          setNew_parts((List<Partition>)value);
+          setNew_part((Partition)value);
         }
         break;
 
@@ -83742,8 +82584,8 @@ public Object getFieldValue(_Fields field) {
       case TBL_NAME:
         return getTbl_name();
 
-      case NEW_PARTS:
-        return getNew_parts();
+      case NEW_PART:
+        return getNew_part();
 
       }
       throw new IllegalStateException();
@@ -83760,8 +82602,8 @@ public boolean isSet(_Fields field) {
         return isSetDb_name();
       case TBL_NAME:
         return isSetTbl_name();
-      case NEW_PARTS:
-        return isSetNew_parts();
+      case NEW_PART:
+        return isSetNew_part();
       }
       throw new IllegalStateException();
     }
@@ -83770,12 +82612,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partitions_args)
-        return this.equals((alter_partitions_args)that);
+      if (that instanceof alter_partition_args)
+        return this.equals((alter_partition_args)that);
       return false;
     }
 
-    public boolean equals(alter_partitions_args that) {
+    public boolean equals(alter_partition_args that) {
       if (that == null)
         return false;
 
@@ -83797,12 +82639,12 @@ public boolean equals(alter_partitions_args that) {
           return false;
       }
 
-      boolean this_present_new_parts = true && this.isSetNew_parts();
-      boolean that_present_new_parts = true && that.isSetNew_parts();
-      if (this_present_new_parts || that_present_new_parts) {
-        if (!(this_present_new_parts && that_present_new_parts))
+      boolean this_present_new_part = true && this.isSetNew_part();
+      boolean that_present_new_part = true && that.isSetNew_part();
+      if (this_present_new_part || that_present_new_part) {
+        if (!(this_present_new_part && that_present_new_part))
           return false;
-        if (!this.new_parts.equals(that.new_parts))
+        if (!this.new_part.equals(that.new_part))
           return false;
       }
 
@@ -83823,21 +82665,21 @@ public int hashCode() {
       if (present_tbl_name)
         builder.append(tbl_name);
 
-      boolean present_new_parts = true && (isSetNew_parts());
-      builder.append(present_new_parts);
-      if (present_new_parts)
-        builder.append(new_parts);
+      boolean present_new_part = true && (isSetNew_part());
+      builder.append(present_new_part);
+      if (present_new_part)
+        builder.append(new_part);
 
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partitions_args other) {
+    public int compareTo(alter_partition_args other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partitions_args typedOther = (alter_partitions_args)other;
+      alter_partition_args typedOther = (alter_partition_args)other;
 
       lastComparison = Boolean.valueOf(isSetDb_name()).compareTo(typedOther.isSetDb_name());
       if (lastComparison != 0) {
@@ -83859,12 +82701,12 @@ public int compareTo(alter_partitions_args other) {
           return lastComparison;
         }
       }
-      lastComparison = Boolean.valueOf(isSetNew_parts()).compareTo(typedOther.isSetNew_parts());
+      lastComparison = Boolean.valueOf(isSetNew_part()).compareTo(typedOther.isSetNew_part());
       if (lastComparison != 0) {
         return lastComparison;
       }
-      if (isSetNew_parts()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.new_parts, typedOther.new_parts);
+      if (isSetNew_part()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.new_part, typedOther.new_part);
         if (lastComparison != 0) {
           return lastComparison;
         }
@@ -83886,7 +82728,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partitions_args(");
+      StringBuilder sb = new StringBuilder("alter_partition_args(");
       boolean first = true;
 
       sb.append("db_name:");
@@ -83905,11 +82747,11 @@ public String toString() {
       }
       first = false;
       if (!first) sb.append(", ");
-      sb.append("new_parts:");
-      if (this.new_parts == null) {
+      sb.append("new_part:");
+      if (this.new_part == null) {
         sb.append("null");
       } else {
-        sb.append(this.new_parts);
+        sb.append(this.new_part);
       }
       first = false;
       sb.append(")");
@@ -83919,6 +82761,9 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
+      if (new_part != null) {
+        new_part.validate();
+      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -83937,15 +82782,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partitions_argsStandardSchemeFactory implements SchemeFactory {
-      public alter_partitions_argsStandardScheme getScheme() {
-        return new alter_partitions_argsStandardScheme();
+    private static class alter_partition_argsStandardSchemeFactory implements SchemeFactory {
+      public alter_partition_argsStandardScheme getScheme() {
+        return new alter_partition_argsStandardScheme();
       }
     }
 
-    private static class alter_partitions_argsStandardScheme extends StandardScheme<alter_partitions_args> {
+    private static class alter_partition_argsStandardScheme extends StandardScheme<alter_partition_args> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_args struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -83971,21 +82816,11 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_ar
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
               break;
-            case 3: // NEW_PARTS
-              if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
-                {
-                  org.apache.thrift.protocol.TList _list866 = iprot.readListBegin();
-                  struct.new_parts = new ArrayList<Partition>(_list866.size);
-                  for (int _i867 = 0; _i867 < _list866.size; ++_i867)
-                  {
-                    Partition _elem868; // required
-                    _elem868 = new Partition();
-                    _elem868.read(iprot);
-                    struct.new_parts.add(_elem868);
-                  }
-                  iprot.readListEnd();
-                }
-                struct.setNew_partsIsSet(true);
+            case 3: // NEW_PART
+              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+                struct.new_part = new Partition();
+                struct.new_part.read(iprot);
+                struct.setNew_partIsSet(true);
               } else { 
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
@@ -83999,7 +82834,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_ar
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_args struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
@@ -84013,16 +82848,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_a
           oprot.writeString(struct.tbl_name);
           oprot.writeFieldEnd();
         }
-        if (struct.new_parts != null) {
-          oprot.writeFieldBegin(NEW_PARTS_FIELD_DESC);
-          {
-            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.new_parts.size()));
-            for (Partition _iter869 : struct.new_parts)
-            {
-              _iter869.write(oprot);
-            }
-            oprot.writeListEnd();
-          }
+        if (struct.new_part != null) {
+          oprot.writeFieldBegin(NEW_PART_FIELD_DESC);
+          struct.new_part.write(oprot);
           oprot.writeFieldEnd();
         }
         oprot.writeFieldStop();
@@ -84031,16 +82859,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_a
 
     }
 
-    private static class alter_partitions_argsTupleSchemeFactory implements SchemeFactory {
-      public alter_partitions_argsTupleScheme getScheme() {
-        return new alter_partitions_argsTupleScheme();
+    private static class alter_partition_argsTupleSchemeFactory implements SchemeFactory {
+      public alter_partition_argsTupleScheme getScheme() {
+        return new alter_partition_argsTupleScheme();
       }
     }
 
-    private static class alter_partitions_argsTupleScheme extends TupleScheme<alter_partitions_args> {
+    private static class alter_partition_argsTupleScheme extends TupleScheme<alter_partition_args> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_args struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetDb_name()) {
@@ -84049,7 +82877,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_ar
         if (struct.isSetTbl_name()) {
           optionals.set(1);
         }
-        if (struct.isSetNew_parts()) {
+        if (struct.isSetNew_part()) {
           optionals.set(2);
         }
         oprot.writeBitSet(optionals, 3);
@@ -84059,19 +82887,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_ar
         if (struct.isSetTbl_name()) {
           oprot.writeString(struct.tbl_name);
         }
-        if (struct.isSetNew_parts()) {
-          {
-            oprot.writeI32(struct.new_parts.size());
-            for (Partition _iter870 : struct.new_parts)
-            {
-              _iter870.write(oprot);
-            }
-          }
+        if (struct.isSetNew_part()) {
+          struct.new_part.write(oprot);
         }
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_args struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
@@ -84083,34 +82905,25 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_arg
           struct.setTbl_nameIsSet(true);
         }
         if (incoming.get(2)) {
-          {
-            org.apache.thrift.protocol.TList _list871 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.new_parts = new ArrayList<Partition>(_list871.size);
-            for (int _i872 = 0; _i872 < _list871.size; ++_i872)
-            {
-              Partition _elem873; // required
-              _elem873 = new Partition();
-              _elem873.read(iprot);
-              struct.new_parts.add(_elem873);
-            }
-          }
-          struct.setNew_partsIsSet(true);
+          struct.new_part = new Partition();
+          struct.new_part.read(iprot);
+          struct.setNew_partIsSet(true);
         }
       }
     }
 
   }
 
-  public static class alter_partitions_result implements org.apache.thrift.TBase<alter_partitions_result, alter_partitions_result._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_result");
+  public static class alter_partition_result implements org.apache.thrift.TBase<alter_partition_result, alter_partition_result._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partition_result");
 
     private static final org.apache.thrift.protocol.TField O1_FIELD_DESC = new org.apache.thrift.protocol.TField("o1", org.apache.thrift.protocol.TType.STRUCT, (short)1);
     private static final org.apache.thrift.protocol.TField O2_FIELD_DESC = new org.apache.thrift.protocol.TField("o2", org.apache.thrift.protocol.TType.STRUCT, (short)2);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partitions_resultStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partitions_resultTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new alter_partition_resultStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new alter_partition_resultTupleSchemeFactory());
     }
 
     private InvalidOperationException o1; // required
@@ -84186,13 +82999,13 @@ public String getFieldName() {
       tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_result.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partition_result.class, metaDataMap);
     }
 
-    public alter_partitions_result() {
+    public alter_partition_result() {
     }
 
-    public alter_partitions_result(
+    public alter_partition_result(
       InvalidOperationException o1,
       MetaException o2)
     {
@@ -84204,7 +83017,7 @@ public alter_partitions_result(
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partitions_result(alter_partitions_result other) {
+    public alter_partition_result(alter_partition_result other) {
       if (other.isSetO1()) {
         this.o1 = new InvalidOperationException(other.o1);
       }
@@ -84213,8 +83026,8 @@ public alter_partitions_result(alter_partitions_result other) {
       }
     }
 
-    public alter_partitions_result deepCopy() {
-      return new alter_partitions_result(this);
+    public alter_partition_result deepCopy() {
+      return new alter_partition_result(this);
     }
 
     @Override
@@ -84321,12 +83134,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partitions_result)
-        return this.equals((alter_partitions_result)that);
+      if (that instanceof alter_partition_result)
+        return this.equals((alter_partition_result)that);
       return false;
     }
 
-    public boolean equals(alter_partitions_result that) {
+    public boolean equals(alter_partition_result that) {
       if (that == null)
         return false;
 
@@ -84368,13 +83181,13 @@ public int hashCode() {
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partitions_result other) {
+    public int compareTo(alter_partition_result other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partitions_result typedOther = (alter_partitions_result)other;
+      alter_partition_result typedOther = (alter_partition_result)other;
 
       lastComparison = Boolean.valueOf(isSetO1()).compareTo(typedOther.isSetO1());
       if (lastComparison != 0) {
@@ -84413,7 +83226,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partitions_result(");
+      StringBuilder sb = new StringBuilder("alter_partition_result(");
       boolean first = true;
 
       sb.append("o1:");
@@ -84456,15 +83269,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partitions_resultStandardSchemeFactory implements SchemeFactory {
-      public alter_partitions_resultStandardScheme getScheme() {
-        return new alter_partitions_resultStandardScheme();
+    private static class alter_partition_resultStandardSchemeFactory implements SchemeFactory {
+      public alter_partition_resultStandardScheme getScheme() {
+        return new alter_partition_resultStandardScheme();
       }
     }
 
-    private static class alter_partitions_resultStandardScheme extends StandardScheme<alter_partitions_result> {
+    private static class alter_partition_resultStandardScheme extends StandardScheme<alter_partition_result> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partition_result struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -84501,7 +83314,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_re
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partition_result struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
@@ -84521,16 +83334,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_r
 
     }
 
-    private static class alter_partitions_resultTupleSchemeFactory implements SchemeFactory {
-      public alter_partitions_resultTupleScheme getScheme() {
-        return new alter_partitions_resultTupleScheme();
+    private static class alter_partition_resultTupleSchemeFactory implements SchemeFactory {
+      public alter_partition_resultTupleScheme getScheme() {
+        return new alter_partition_resultTupleScheme();
       }
     }
 
-    private static class alter_partitions_resultTupleScheme extends TupleScheme<alter_partitions_result> {
+    private static class alter_partition_resultTupleScheme extends TupleScheme<alter_partition_result> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partition_result struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetO1()) {
@@ -84549,7 +83362,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_re
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partition_result struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
@@ -84567,31 +83380,28 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_res
 
   }
 
-  public static class alter_partitions_with_environment_context_args implements org.apache.thrift.TBase<alter_partitions_with_environment_context_args, alter_partitions_with_environment_context_args._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_with_environment_context_args");
+  public static class alter_partitions_args implements org.apache.thrift.TBase<alter_partitions_args, alter_partitions_args._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_args");
 
     private static final org.apache.thrift.protocol.TField DB_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("db_name", org.apache.thrift.protocol.TType.STRING, (short)1);
     private static final org.apache.thrift.protocol.TField TBL_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("tbl_name", org.apache.thrift.protocol.TType.STRING, (short)2);
     private static final org.apache.thrift.protocol.TField NEW_PARTS_FIELD_DESC = new org.apache.thrift.protocol.TField("new_parts", org.apache.thrift.protocol.TType.LIST, (short)3);
-    private static final org.apache.thrift.protocol.TField ENVIRONMENT_CONTEXT_FIELD_DESC = new org.apache.thrift.protocol.TField("environment_context", org.apache.thrift.protocol.TType.STRUCT, (short)4);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partitions_with_environment_context_argsStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partitions_with_environment_context_argsTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new alter_partitions_argsStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new alter_partitions_argsTupleSchemeFactory());
     }
 
     private String db_name; // required
     private String tbl_name; // required
     private List<Partition> new_parts; // required
-    private EnvironmentContext environment_context; // required
 
     /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
     public enum _Fields implements org.apache.thrift.TFieldIdEnum {
       DB_NAME((short)1, "db_name"),
       TBL_NAME((short)2, "tbl_name"),
-      NEW_PARTS((short)3, "new_parts"),
-      ENVIRONMENT_CONTEXT((short)4, "environment_context");
+      NEW_PARTS((short)3, "new_parts");
 
       private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
 
@@ -84612,8 +83422,6 @@ public static _Fields findByThriftId(int fieldId) {
             return TBL_NAME;
           case 3: // NEW_PARTS
             return NEW_PARTS;
-          case 4: // ENVIRONMENT_CONTEXT
-            return ENVIRONMENT_CONTEXT;
           default:
             return null;
         }
@@ -84664,32 +83472,28 @@ public String getFieldName() {
       tmpMap.put(_Fields.NEW_PARTS, new org.apache.thrift.meta_data.FieldMetaData("new_parts", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
               new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, Partition.class))));
-      tmpMap.put(_Fields.ENVIRONMENT_CONTEXT, new org.apache.thrift.meta_data.FieldMetaData("environment_context", org.apache.thrift.TFieldRequirementType.DEFAULT, 
-          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, EnvironmentContext.class)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_with_environment_context_args.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_args.class, metaDataMap);
     }
 
-    public alter_partitions_with_environment_context_args() {
+    public alter_partitions_args() {
     }
 
-    public alter_partitions_with_environment_context_args(
+    public alter_partitions_args(
       String db_name,
       String tbl_name,
-      List<Partition> new_parts,
-      EnvironmentContext environment_context)
+      List<Partition> new_parts)
     {
       this();
       this.db_name = db_name;
       this.tbl_name = tbl_name;
       this.new_parts = new_parts;
-      this.environment_context = environment_context;
     }
 
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partitions_with_environment_context_args(alter_partitions_with_environment_context_args other) {
+    public alter_partitions_args(alter_partitions_args other) {
       if (other.isSetDb_name()) {
         this.db_name = other.db_name;
       }
@@ -84703,13 +83507,10 @@ public alter_partitions_with_environment_context_args(alter_partitions_with_envi
         }
         this.new_parts = __this__new_parts;
       }
-      if (other.isSetEnvironment_context()) {
-        this.environment_context = new EnvironmentContext(other.environment_context);
-      }
     }
 
-    public alter_partitions_with_environment_context_args deepCopy() {
-      return new alter_partitions_with_environment_context_args(this);
+    public alter_partitions_args deepCopy() {
+      return new alter_partitions_args(this);
     }
 
     @Override
@@ -84717,7 +83518,6 @@ public void clear() {
       this.db_name = null;
       this.tbl_name = null;
       this.new_parts = null;
-      this.environment_context = null;
     }
 
     public String getDb_name() {
@@ -84804,29 +83604,6 @@ public void setNew_partsIsSet(boolean value) {
       }
     }
 
-    public EnvironmentContext getEnvironment_context() {
-      return this.environment_context;
-    }
-
-    public void setEnvironment_context(EnvironmentContext environment_context) {
-      this.environment_context = environment_context;
-    }
-
-    public void unsetEnvironment_context() {
-      this.environment_context = null;
-    }
-
-    /** Returns true if field environment_context is set (has been assigned a value) and false otherwise */
-    public boolean isSetEnvironment_context() {
-      return this.environment_context != null;
-    }
-
-    public void setEnvironment_contextIsSet(boolean value) {
-      if (!value) {
-        this.environment_context = null;
-      }
-    }
-
     public void setFieldValue(_Fields field, Object value) {
       switch (field) {
       case DB_NAME:
@@ -84853,14 +83630,6 @@ public void setFieldValue(_Fields field, Object value) {
         }
         break;
 
-      case ENVIRONMENT_CONTEXT:
-        if (value == null) {
-          unsetEnvironment_context();
-        } else {
-          setEnvironment_context((EnvironmentContext)value);
-        }
-        break;
-
       }
     }
 
@@ -84875,9 +83644,6 @@ public Object getFieldValue(_Fields field) {
       case NEW_PARTS:
         return getNew_parts();
 
-      case ENVIRONMENT_CONTEXT:
-        return getEnvironment_context();
-
       }
       throw new IllegalStateException();
     }
@@ -84895,8 +83661,6 @@ public boolean isSet(_Fields field) {
         return isSetTbl_name();
       case NEW_PARTS:
         return isSetNew_parts();
-      case ENVIRONMENT_CONTEXT:
-        return isSetEnvironment_context();
       }
       throw new IllegalStateException();
     }
@@ -84905,12 +83669,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partitions_with_environment_context_args)
-        return this.equals((alter_partitions_with_environment_context_args)that);
+      if (that instanceof alter_partitions_args)
+        return this.equals((alter_partitions_args)that);
       return false;
     }
 
-    public boolean equals(alter_partitions_with_environment_context_args that) {
+    public boolean equals(alter_partitions_args that) {
       if (that == null)
         return false;
 
@@ -84941,15 +83705,6 @@ public boolean equals(alter_partitions_with_environment_context_args that) {
           return false;
       }
 
-      boolean this_present_environment_context = true && this.isSetEnvironment_context();
-      boolean that_present_environment_context = true && that.isSetEnvironment_context();
-      if (this_present_environment_context || that_present_environment_context) {
-        if (!(this_present_environment_context && that_present_environment_context))
-          return false;
-        if (!this.environment_context.equals(that.environment_context))
-          return false;
-      }
-
       return true;
     }
 
@@ -84972,21 +83727,16 @@ public int hashCode() {
       if (present_new_parts)
         builder.append(new_parts);
 
-      boolean present_environment_context = true && (isSetEnvironment_context());
-      builder.append(present_environment_context);
-      if (present_environment_context)
-        builder.append(environment_context);
-
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partitions_with_environment_context_args other) {
+    public int compareTo(alter_partitions_args other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partitions_with_environment_context_args typedOther = (alter_partitions_with_environment_context_args)other;
+      alter_partitions_args typedOther = (alter_partitions_args)other;
 
       lastComparison = Boolean.valueOf(isSetDb_name()).compareTo(typedOther.isSetDb_name());
       if (lastComparison != 0) {
@@ -85018,16 +83768,6 @@ public int compareTo(alter_partitions_with_environment_context_args other) {
           return lastComparison;
         }
       }
-      lastComparison = Boolean.valueOf(isSetEnvironment_context()).compareTo(typedOther.isSetEnvironment_context());
-      if (lastComparison != 0) {
-        return lastComparison;
-      }
-      if (isSetEnvironment_context()) {
-        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.environment_context, typedOther.environment_context);
-        if (lastComparison != 0) {
-          return lastComparison;
-        }
-      }
       return 0;
     }
 
@@ -85045,7 +83785,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partitions_with_environment_context_args(");
+      StringBuilder sb = new StringBuilder("alter_partitions_args(");
       boolean first = true;
 
       sb.append("db_name:");
@@ -85071,14 +83811,6 @@ public String toString() {
         sb.append(this.new_parts);
       }
       first = false;
-      if (!first) sb.append(", ");
-      sb.append("environment_context:");
-      if (this.environment_context == null) {
-        sb.append("null");
-      } else {
-        sb.append(this.environment_context);
-      }
-      first = false;
       sb.append(")");
       return sb.toString();
     }
@@ -85086,9 +83818,6 @@ public String toString() {
     public void validate() throws org.apache.thrift.TException {
       // check for required fields
       // check for sub-struct validity
-      if (environment_context != null) {
-        environment_context.validate();
-      }
     }
 
     private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
@@ -85107,15 +83836,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partitions_with_environment_context_argsStandardSchemeFactory implements SchemeFactory {
-      public alter_partitions_with_environment_context_argsStandardScheme getScheme() {
-        return new alter_partitions_with_environment_context_argsStandardScheme();
+    private static class alter_partitions_argsStandardSchemeFactory implements SchemeFactory {
+      public alter_partitions_argsStandardScheme getScheme() {
+        return new alter_partitions_argsStandardScheme();
       }
     }
 
-    private static class alter_partitions_with_environment_context_argsStandardScheme extends StandardScheme<alter_partitions_with_environment_context_args> {
+    private static class alter_partitions_argsStandardScheme extends StandardScheme<alter_partitions_args> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_with_environment_context_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_args struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -85144,14 +83873,14 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_wi
             case 3: // NEW_PARTS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list874 = iprot.readListBegin();
-                  struct.new_parts = new ArrayList<Partition>(_list874.size);
-                  for (int _i875 = 0; _i875 < _list874.size; ++_i875)
+                  org.apache.thrift.protocol.TList _list866 = iprot.readListBegin();
+                  struct.new_parts = new ArrayList<Partition>(_list866.size);
+                  for (int _i867 = 0; _i867 < _list866.size; ++_i867)
                   {
-                    Partition _elem876; // required
-                    _elem876 = new Partition();
-                    _elem876.read(iprot);
-                    struct.new_parts.add(_elem876);
+                    Partition _elem868; // required
+                    _elem868 = new Partition();
+                    _elem868.read(iprot);
+                    struct.new_parts.add(_elem868);
                   }
                   iprot.readListEnd();
                 }
@@ -85160,15 +83889,6 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_wi
                 org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
               }
               break;
-            case 4: // ENVIRONMENT_CONTEXT
-              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
-                struct.environment_context = new EnvironmentContext();
-                struct.environment_context.read(iprot);
-                struct.setEnvironment_contextIsSet(true);
-              } else { 
-                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
-              }
-              break;
             default:
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
           }
@@ -85178,7 +83898,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_wi
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_with_environment_context_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_args struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
@@ -85196,35 +83916,30 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_w
           oprot.writeFieldBegin(NEW_PARTS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.new_parts.size()));
-            for (Partition _iter877 : struct.new_parts)
+            for (Partition _iter869 : struct.new_parts)
             {
-              _iter877.write(oprot);
+              _iter869.write(oprot);
             }
             oprot.writeListEnd();
           }
           oprot.writeFieldEnd();
         }
-        if (struct.environment_context != null) {
-          oprot.writeFieldBegin(ENVIRONMENT_CONTEXT_FIELD_DESC);
-          struct.environment_context.write(oprot);
-          oprot.writeFieldEnd();
-        }
         oprot.writeFieldStop();
         oprot.writeStructEnd();
       }
 
     }
 
-    private static class alter_partitions_with_environment_context_argsTupleSchemeFactory implements SchemeFactory {
-      public alter_partitions_with_environment_context_argsTupleScheme getScheme() {
-        return new alter_partitions_with_environment_context_argsTupleScheme();
+    private static class alter_partitions_argsTupleSchemeFactory implements SchemeFactory {
+      public alter_partitions_argsTupleScheme getScheme() {
+        return new alter_partitions_argsTupleScheme();
       }
     }
 
-    private static class alter_partitions_with_environment_context_argsTupleScheme extends TupleScheme<alter_partitions_with_environment_context_args> {
+    private static class alter_partitions_argsTupleScheme extends TupleScheme<alter_partitions_args> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_with_environment_context_args struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_args struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetDb_name()) {
@@ -85236,10 +83951,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_wi
         if (struct.isSetNew_parts()) {
           optionals.set(2);
         }
-        if (struct.isSetEnvironment_context()) {
-          optionals.set(3);
-        }
-        oprot.writeBitSet(optionals, 4);
+        oprot.writeBitSet(optionals, 3);
         if (struct.isSetDb_name()) {
           oprot.writeString(struct.db_name);
         }
@@ -85249,21 +83961,18 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_wi
         if (struct.isSetNew_parts()) {
           {
             oprot.writeI32(struct.new_parts.size());
-            for (Partition _iter878 : struct.new_parts)
+            for (Partition _iter870 : struct.new_parts)
             {
-              _iter878.write(oprot);
+              _iter870.write(oprot);
             }
           }
         }
-        if (struct.isSetEnvironment_context()) {
-          struct.environment_context.write(oprot);
-        }
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_with_environment_context_args struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_args struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
-        BitSet incoming = iprot.readBitSet(4);
+        BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
           struct.db_name = iprot.readString();
           struct.setDb_nameIsSet(true);
@@ -85274,38 +83983,33 @@ public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_wit
         }
         if (incoming.get(2)) {
           {
-            org.apache.thrift.protocol.TList _list879 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.new_parts = new ArrayList<Partition>(_list879.size);
-            for (int _i880 = 0; _i880 < _list879.size; ++_i880)
+            org.apache.thrift.protocol.TList _list871 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.new_parts = new ArrayList<Partition>(_list871.size);
+            for (int _i872 = 0; _i872 < _list871.size; ++_i872)
             {
-              Partition _elem881; // required
-              _elem881 = new Partition();
-              _elem881.read(iprot);
-              struct.new_parts.add(_elem881);
+              Partition _elem873; // required
+              _elem873 = new Partition();
+              _elem873.read(iprot);
+              struct.new_parts.add(_elem873);
             }
           }
           struct.setNew_partsIsSet(true);
         }
-        if (incoming.get(3)) {
-          struct.environment_context = new EnvironmentContext();
-          struct.environment_context.read(iprot);
-          struct.setEnvironment_contextIsSet(true);
-        }
       }
     }
 
   }
 
-  public static class alter_partitions_with_environment_context_result implements org.apache.thrift.TBase<alter_partitions_with_environment_context_result, alter_partitions_with_environment_context_result._Fields>, java.io.Serializable, Cloneable   {
-    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_with_environment_context_result");
+  public static class alter_partitions_result implements org.apache.thrift.TBase<alter_partitions_result, alter_partitions_result._Fields>, java.io.Serializable, Cloneable   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("alter_partitions_result");
 
     private static final org.apache.thrift.protocol.TField O1_FIELD_DESC = new org.apache.thrift.protocol.TField("o1", org.apache.thrift.protocol.TType.STRUCT, (short)1);
     private static final org.apache.thrift.protocol.TField O2_FIELD_DESC = new org.apache.thrift.protocol.TField("o2", org.apache.thrift.protocol.TType.STRUCT, (short)2);
 
     private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
     static {
-      schemes.put(StandardScheme.class, new alter_partitions_with_environment_context_resultStandardSchemeFactory());
-      schemes.put(TupleScheme.class, new alter_partitions_with_environment_context_resultTupleSchemeFactory());
+      schemes.put(StandardScheme.class, new alter_partitions_resultStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new alter_partitions_resultTupleSchemeFactory());
     }
 
     private InvalidOperationException o1; // required
@@ -85381,13 +84085,13 @@ public String getFieldName() {
       tmpMap.put(_Fields.O2, new org.apache.thrift.meta_data.FieldMetaData("o2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
           new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRUCT)));
       metaDataMap = Collections.unmodifiableMap(tmpMap);
-      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_with_environment_context_result.class, metaDataMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(alter_partitions_result.class, metaDataMap);
     }
 
-    public alter_partitions_with_environment_context_result() {
+    public alter_partitions_result() {
     }
 
-    public alter_partitions_with_environment_context_result(
+    public alter_partitions_result(
       InvalidOperationException o1,
       MetaException o2)
     {
@@ -85399,7 +84103,7 @@ public alter_partitions_with_environment_context_result(
     /**
      * Performs a deep copy on <i>other</i>.
      */
-    public alter_partitions_with_environment_context_result(alter_partitions_with_environment_context_result other) {
+    public alter_partitions_result(alter_partitions_result other) {
       if (other.isSetO1()) {
         this.o1 = new InvalidOperationException(other.o1);
       }
@@ -85408,8 +84112,8 @@ public alter_partitions_with_environment_context_result(alter_partitions_with_en
       }
     }
 
-    public alter_partitions_with_environment_context_result deepCopy() {
-      return new alter_partitions_with_environment_context_result(this);
+    public alter_partitions_result deepCopy() {
+      return new alter_partitions_result(this);
     }
 
     @Override
@@ -85516,12 +84220,12 @@ public boolean isSet(_Fields field) {
     public boolean equals(Object that) {
       if (that == null)
         return false;
-      if (that instanceof alter_partitions_with_environment_context_result)
-        return this.equals((alter_partitions_with_environment_context_result)that);
+      if (that instanceof alter_partitions_result)
+        return this.equals((alter_partitions_result)that);
       return false;
     }
 
-    public boolean equals(alter_partitions_with_environment_context_result that) {
+    public boolean equals(alter_partitions_result that) {
       if (that == null)
         return false;
 
@@ -85563,13 +84267,13 @@ public int hashCode() {
       return builder.toHashCode();
     }
 
-    public int compareTo(alter_partitions_with_environment_context_result other) {
+    public int compareTo(alter_partitions_result other) {
       if (!getClass().equals(other.getClass())) {
         return getClass().getName().compareTo(other.getClass().getName());
       }
 
       int lastComparison = 0;
-      alter_partitions_with_environment_context_result typedOther = (alter_partitions_with_environment_context_result)other;
+      alter_partitions_result typedOther = (alter_partitions_result)other;
 
       lastComparison = Boolean.valueOf(isSetO1()).compareTo(typedOther.isSetO1());
       if (lastComparison != 0) {
@@ -85608,7 +84312,7 @@ public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.
 
     @Override
     public String toString() {
-      StringBuilder sb = new StringBuilder("alter_partitions_with_environment_context_result(");
+      StringBuilder sb = new StringBuilder("alter_partitions_result(");
       boolean first = true;
 
       sb.append("o1:");
@@ -85651,15 +84355,15 @@ private void readObject(java.io.ObjectInputStream in) throws java.io.IOException
       }
     }
 
-    private static class alter_partitions_with_environment_context_resultStandardSchemeFactory implements SchemeFactory {
-      public alter_partitions_with_environment_context_resultStandardScheme getScheme() {
-        return new alter_partitions_with_environment_context_resultStandardScheme();
+    private static class alter_partitions_resultStandardSchemeFactory implements SchemeFactory {
+      public alter_partitions_resultStandardScheme getScheme() {
+        return new alter_partitions_resultStandardScheme();
       }
     }
 
-    private static class alter_partitions_with_environment_context_resultStandardScheme extends StandardScheme<alter_partitions_with_environment_context_result> {
+    private static class alter_partitions_resultStandardScheme extends StandardScheme<alter_partitions_result> {
 
-      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_with_environment_context_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_result struct) throws org.apache.thrift.TException {
         org.apache.thrift.protocol.TField schemeField;
         iprot.readStructBegin();
         while (true)
@@ -85696,7 +84400,7 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, alter_partitions_wi
         struct.validate();
       }
 
-      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_with_environment_context_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_result struct) throws org.apache.thrift.TException {
         struct.validate();
 
         oprot.writeStructBegin(STRUCT_DESC);
@@ -85716,16 +84420,16 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, alter_partitions_w
 
     }
 
-    private static class alter_partitions_with_environment_context_resultTupleSchemeFactory implements SchemeFactory {
-      public alter_partitions_with_environment_context_resultTupleScheme getScheme() {
-        return new alter_partitions_with_environment_context_resultTupleScheme();
+    private static class alter_partitions_resultTupleSchemeFactory implements SchemeFactory {
+      public alter_partitions_resultTupleScheme getScheme() {
+        return new alter_partitions_resultTupleScheme();
       }
     }
 
-    private static class alter_partitions_with_environment_context_resultTupleScheme extends TupleScheme<alter_partitions_with_environment_context_result> {
+    private static class alter_partitions_resultTupleScheme extends TupleScheme<alter_partitions_result> {
 
       @Override
-      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_with_environment_context_result struct) throws org.apache.thrift.TException {
+      public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_result struct) throws org.apache.thrift.TException {
         TTupleProtocol oprot = (TTupleProtocol) prot;
         BitSet optionals = new BitSet();
         if (struct.isSetO1()) {
@@ -85744,7 +84448,7 @@ public void write(org.apache.thrift.protocol.TProtocol prot, alter_partitions_wi
       }
 
       @Override
-      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_with_environment_context_result struct) throws org.apache.thrift.TException {
+      public void read(org.apache.thrift.protocol.TProtocol prot, alter_partitions_result struct) throws org.apache.thrift.TException {
         TTupleProtocol iprot = (TTupleProtocol) prot;
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
@@ -87485,13 +86189,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, rename_partition_ar
             case 3: // PART_VALS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list882 = iprot.readListBegin();
-                  struct.part_vals = new ArrayList<String>(_list882.size);
-                  for (int _i883 = 0; _i883 < _list882.size; ++_i883)
+                  org.apache.thrift.protocol.TList _list874 = iprot.readListBegin();
+                  struct.part_vals = new ArrayList<String>(_list874.size);
+                  for (int _i875 = 0; _i875 < _list874.size; ++_i875)
                   {
-                    String _elem884; // required
-                    _elem884 = iprot.readString();
-                    struct.part_vals.add(_elem884);
+                    String _elem876; // required
+                    _elem876 = iprot.readString();
+                    struct.part_vals.add(_elem876);
                   }
                   iprot.readListEnd();
                 }
@@ -87536,9 +86240,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, rename_partition_a
           oprot.writeFieldBegin(PART_VALS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.part_vals.size()));
-            for (String _iter885 : struct.part_vals)
+            for (String _iter877 : struct.part_vals)
             {
-              oprot.writeString(_iter885);
+              oprot.writeString(_iter877);
             }
             oprot.writeListEnd();
           }
@@ -87589,9 +86293,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, rename_partition_ar
         if (struct.isSetPart_vals()) {
           {
             oprot.writeI32(struct.part_vals.size());
-            for (String _iter886 : struct.part_vals)
+            for (String _iter878 : struct.part_vals)
             {
-              oprot.writeString(_iter886);
+              oprot.writeString(_iter878);
             }
           }
         }
@@ -87614,13 +86318,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, rename_partition_arg
         }
         if (incoming.get(2)) {
           {
-            org.apache.thrift.protocol.TList _list887 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.part_vals = new ArrayList<String>(_list887.size);
-            for (int _i888 = 0; _i888 < _list887.size; ++_i888)
+            org.apache.thrift.protocol.TList _list879 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.part_vals = new ArrayList<String>(_list879.size);
+            for (int _i880 = 0; _i880 < _list879.size; ++_i880)
             {
-              String _elem889; // required
-              _elem889 = iprot.readString();
-              struct.part_vals.add(_elem889);
+              String _elem881; // required
+              _elem881 = iprot.readString();
+              struct.part_vals.add(_elem881);
             }
           }
           struct.setPart_valsIsSet(true);
@@ -88497,13 +87201,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, partition_name_has_
             case 1: // PART_VALS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list890 = iprot.readListBegin();
-                  struct.part_vals = new ArrayList<String>(_list890.size);
-                  for (int _i891 = 0; _i891 < _list890.size; ++_i891)
+                  org.apache.thrift.protocol.TList _list882 = iprot.readListBegin();
+                  struct.part_vals = new ArrayList<String>(_list882.size);
+                  for (int _i883 = 0; _i883 < _list882.size; ++_i883)
                   {
-                    String _elem892; // required
-                    _elem892 = iprot.readString();
-                    struct.part_vals.add(_elem892);
+                    String _elem884; // required
+                    _elem884 = iprot.readString();
+                    struct.part_vals.add(_elem884);
                   }
                   iprot.readListEnd();
                 }
@@ -88537,9 +87241,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, partition_name_has
           oprot.writeFieldBegin(PART_VALS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.part_vals.size()));
-            for (String _iter893 : struct.part_vals)
+            for (String _iter885 : struct.part_vals)
             {
-              oprot.writeString(_iter893);
+              oprot.writeString(_iter885);
             }
             oprot.writeListEnd();
           }
@@ -88576,9 +87280,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, partition_name_has_
         if (struct.isSetPart_vals()) {
           {
             oprot.writeI32(struct.part_vals.size());
-            for (String _iter894 : struct.part_vals)
+            for (String _iter886 : struct.part_vals)
             {
-              oprot.writeString(_iter894);
+              oprot.writeString(_iter886);
             }
           }
         }
@@ -88593,13 +87297,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, partition_name_has_v
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list895 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.part_vals = new ArrayList<String>(_list895.size);
-            for (int _i896 = 0; _i896 < _list895.size; ++_i896)
+            org.apache.thrift.protocol.TList _list887 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.part_vals = new ArrayList<String>(_list887.size);
+            for (int _i888 = 0; _i888 < _list887.size; ++_i888)
             {
-              String _elem897; // required
-              _elem897 = iprot.readString();
-              struct.part_vals.add(_elem897);
+              String _elem889; // required
+              _elem889 = iprot.readString();
+              struct.part_vals.add(_elem889);
             }
           }
           struct.setPart_valsIsSet(true);
@@ -90757,13 +89461,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, partition_name_to_v
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list898 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list898.size);
-                  for (int _i899 = 0; _i899 < _list898.size; ++_i899)
+                  org.apache.thrift.protocol.TList _list890 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list890.size);
+                  for (int _i891 = 0; _i891 < _list890.size; ++_i891)
                   {
-                    String _elem900; // required
-                    _elem900 = iprot.readString();
-                    struct.success.add(_elem900);
+                    String _elem892; // required
+                    _elem892 = iprot.readString();
+                    struct.success.add(_elem892);
                   }
                   iprot.readListEnd();
                 }
@@ -90798,9 +89502,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, partition_name_to_
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter901 : struct.success)
+            for (String _iter893 : struct.success)
             {
-              oprot.writeString(_iter901);
+              oprot.writeString(_iter893);
             }
             oprot.writeListEnd();
           }
@@ -90839,9 +89543,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, partition_name_to_v
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter902 : struct.success)
+            for (String _iter894 : struct.success)
             {
-              oprot.writeString(_iter902);
+              oprot.writeString(_iter894);
             }
           }
         }
@@ -90856,13 +89560,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, partition_name_to_va
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list903 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list903.size);
-            for (int _i904 = 0; _i904 < _list903.size; ++_i904)
+            org.apache.thrift.protocol.TList _list895 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list895.size);
+            for (int _i896 = 0; _i896 < _list895.size; ++_i896)
             {
-              String _elem905; // required
-              _elem905 = iprot.readString();
-              struct.success.add(_elem905);
+              String _elem897; // required
+              _elem897 = iprot.readString();
+              struct.success.add(_elem897);
             }
           }
           struct.setSuccessIsSet(true);
@@ -91636,15 +90340,15 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, partition_name_to_s
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
                 {
-                  org.apache.thrift.protocol.TMap _map906 = iprot.readMapBegin();
-                  struct.success = new HashMap<String,String>(2*_map906.size);
-                  for (int _i907 = 0; _i907 < _map906.size; ++_i907)
+                  org.apache.thrift.protocol.TMap _map898 = iprot.readMapBegin();
+                  struct.success = new HashMap<String,String>(2*_map898.size);
+                  for (int _i899 = 0; _i899 < _map898.size; ++_i899)
                   {
-                    String _key908; // required
-                    String _val909; // required
-                    _key908 = iprot.readString();
-                    _val909 = iprot.readString();
-                    struct.success.put(_key908, _val909);
+                    String _key900; // required
+                    String _val901; // required
+                    _key900 = iprot.readString();
+                    _val901 = iprot.readString();
+                    struct.success.put(_key900, _val901);
                   }
                   iprot.readMapEnd();
                 }
@@ -91679,10 +90383,10 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, partition_name_to_
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (Map.Entry<String, String> _iter910 : struct.success.entrySet())
+            for (Map.Entry<String, String> _iter902 : struct.success.entrySet())
             {
-              oprot.writeString(_iter910.getKey());
-              oprot.writeString(_iter910.getValue());
+              oprot.writeString(_iter902.getKey());
+              oprot.writeString(_iter902.getValue());
             }
             oprot.writeMapEnd();
           }
@@ -91721,10 +90425,10 @@ public void write(org.apache.thrift.protocol.TProtocol prot, partition_name_to_s
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (Map.Entry<String, String> _iter911 : struct.success.entrySet())
+            for (Map.Entry<String, String> _iter903 : struct.success.entrySet())
             {
-              oprot.writeString(_iter911.getKey());
-              oprot.writeString(_iter911.getValue());
+              oprot.writeString(_iter903.getKey());
+              oprot.writeString(_iter903.getValue());
             }
           }
         }
@@ -91739,15 +90443,15 @@ public void read(org.apache.thrift.protocol.TProtocol prot, partition_name_to_sp
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TMap _map912 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new HashMap<String,String>(2*_map912.size);
-            for (int _i913 = 0; _i913 < _map912.size; ++_i913)
+            org.apache.thrift.protocol.TMap _map904 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new HashMap<String,String>(2*_map904.size);
+            for (int _i905 = 0; _i905 < _map904.size; ++_i905)
             {
-              String _key914; // required
-              String _val915; // required
-              _key914 = iprot.readString();
-              _val915 = iprot.readString();
-              struct.success.put(_key914, _val915);
+              String _key906; // required
+              String _val907; // required
+              _key906 = iprot.readString();
+              _val907 = iprot.readString();
+              struct.success.put(_key906, _val907);
             }
           }
           struct.setSuccessIsSet(true);
@@ -92353,15 +91057,15 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, markPartitionForEve
             case 3: // PART_VALS
               if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
                 {
-                  org.apache.thrift.protocol.TMap _map916 = iprot.readMapBegin();
-                  struct.part_vals = new HashMap<String,String>(2*_map916.size);
-                  for (int _i917 = 0; _i917 < _map916.size; ++_i917)
+                  org.apache.thrift.protocol.TMap _map908 = iprot.readMapBegin();
+                  struct.part_vals = new HashMap<String,String>(2*_map908.size);
+                  for (int _i909 = 0; _i909 < _map908.size; ++_i909)
                   {
-                    String _key918; // required
-                    String _val919; // required
-                    _key918 = iprot.readString();
-                    _val919 = iprot.readString();
-                    struct.part_vals.put(_key918, _val919);
+                    String _key910; // required
+                    String _val911; // required
+                    _key910 = iprot.readString();
+                    _val911 = iprot.readString();
+                    struct.part_vals.put(_key910, _val911);
                   }
                   iprot.readMapEnd();
                 }
@@ -92405,10 +91109,10 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, markPartitionForEv
           oprot.writeFieldBegin(PART_VALS_FIELD_DESC);
           {
             oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.part_vals.size()));
-            for (Map.Entry<String, String> _iter920 : struct.part_vals.entrySet())
+            for (Map.Entry<String, String> _iter912 : struct.part_vals.entrySet())
             {
-              oprot.writeString(_iter920.getKey());
-              oprot.writeString(_iter920.getValue());
+              oprot.writeString(_iter912.getKey());
+              oprot.writeString(_iter912.getValue());
             }
             oprot.writeMapEnd();
           }
@@ -92459,10 +91163,10 @@ public void write(org.apache.thrift.protocol.TProtocol prot, markPartitionForEve
         if (struct.isSetPart_vals()) {
           {
             oprot.writeI32(struct.part_vals.size());
-            for (Map.Entry<String, String> _iter921 : struct.part_vals.entrySet())
+            for (Map.Entry<String, String> _iter913 : struct.part_vals.entrySet())
             {
-              oprot.writeString(_iter921.getKey());
-              oprot.writeString(_iter921.getValue());
+              oprot.writeString(_iter913.getKey());
+              oprot.writeString(_iter913.getValue());
             }
           }
         }
@@ -92485,15 +91189,15 @@ public void read(org.apache.thrift.protocol.TProtocol prot, markPartitionForEven
         }
         if (incoming.get(2)) {
           {
-            org.apache.thrift.protocol.TMap _map922 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.part_vals = new HashMap<String,String>(2*_map922.size);
-            for (int _i923 = 0; _i923 < _map922.size; ++_i923)
+            org.apache.thrift.protocol.TMap _map914 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.part_vals = new HashMap<String,String>(2*_map914.size);
+            for (int _i915 = 0; _i915 < _map914.size; ++_i915)
             {
-              String _key924; // required
-              String _val925; // required
-              _key924 = iprot.readString();
-              _val925 = iprot.readString();
-              struct.part_vals.put(_key924, _val925);
+              String _key916; // required
+              String _val917; // required
+              _key916 = iprot.readString();
+              _val917 = iprot.readString();
+              struct.part_vals.put(_key916, _val917);
             }
           }
           struct.setPart_valsIsSet(true);
@@ -93988,15 +92692,15 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, isPartitionMarkedFo
             case 3: // PART_VALS
               if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
                 {
-                  org.apache.thrift.protocol.TMap _map926 = iprot.readMapBegin();
-                  struct.part_vals = new HashMap<String,String>(2*_map926.size);
-                  for (int _i927 = 0; _i927 < _map926.size; ++_i927)
+                  org.apache.thrift.protocol.TMap _map918 = iprot.readMapBegin();
+                  struct.part_vals = new HashMap<String,String>(2*_map918.size);
+                  for (int _i919 = 0; _i919 < _map918.size; ++_i919)
                   {
-                    String _key928; // required
-                    String _val929; // required
-                    _key928 = iprot.readString();
-                    _val929 = iprot.readString();
-                    struct.part_vals.put(_key928, _val929);
+                    String _key920; // required
+                    String _val921; // required
+                    _key920 = iprot.readString();
+                    _val921 = iprot.readString();
+                    struct.part_vals.put(_key920, _val921);
                   }
                   iprot.readMapEnd();
                 }
@@ -94040,10 +92744,10 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, isPartitionMarkedF
           oprot.writeFieldBegin(PART_VALS_FIELD_DESC);
           {
             oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.part_vals.size()));
-            for (Map.Entry<String, String> _iter930 : struct.part_vals.entrySet())
+            for (Map.Entry<String, String> _iter922 : struct.part_vals.entrySet())
             {
-              oprot.writeString(_iter930.getKey());
-              oprot.writeString(_iter930.getValue());
+              oprot.writeString(_iter922.getKey());
+              oprot.writeString(_iter922.getValue());
             }
             oprot.writeMapEnd();
           }
@@ -94094,10 +92798,10 @@ public void write(org.apache.thrift.protocol.TProtocol prot, isPartitionMarkedFo
         if (struct.isSetPart_vals()) {
           {
             oprot.writeI32(struct.part_vals.size());
-            for (Map.Entry<String, String> _iter931 : struct.part_vals.entrySet())
+            for (Map.Entry<String, String> _iter923 : struct.part_vals.entrySet())
             {
-              oprot.writeString(_iter931.getKey());
-              oprot.writeString(_iter931.getValue());
+              oprot.writeString(_iter923.getKey());
+              oprot.writeString(_iter923.getValue());
             }
           }
         }
@@ -94120,15 +92824,15 @@ public void read(org.apache.thrift.protocol.TProtocol prot, isPartitionMarkedFor
         }
         if (incoming.get(2)) {
           {
-            org.apache.thrift.protocol.TMap _map932 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.part_vals = new HashMap<String,String>(2*_map932.size);
-            for (int _i933 = 0; _i933 < _map932.size; ++_i933)
+            org.apache.thrift.protocol.TMap _map924 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.part_vals = new HashMap<String,String>(2*_map924.size);
+            for (int _i925 = 0; _i925 < _map924.size; ++_i925)
             {
-              String _key934; // required
-              String _val935; // required
-              _key934 = iprot.readString();
-              _val935 = iprot.readString();
-              struct.part_vals.put(_key934, _val935);
+              String _key926; // required
+              String _val927; // required
+              _key926 = iprot.readString();
+              _val927 = iprot.readString();
+              struct.part_vals.put(_key926, _val927);
             }
           }
           struct.setPart_valsIsSet(true);
@@ -100852,14 +99556,14 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_indexes_result
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list936 = iprot.readListBegin();
-                  struct.success = new ArrayList<Index>(_list936.size);
-                  for (int _i937 = 0; _i937 < _list936.size; ++_i937)
+                  org.apache.thrift.protocol.TList _list928 = iprot.readListBegin();
+                  struct.success = new ArrayList<Index>(_list928.size);
+                  for (int _i929 = 0; _i929 < _list928.size; ++_i929)
                   {
-                    Index _elem938; // required
-                    _elem938 = new Index();
-                    _elem938.read(iprot);
-                    struct.success.add(_elem938);
+                    Index _elem930; // required
+                    _elem930 = new Index();
+                    _elem930.read(iprot);
+                    struct.success.add(_elem930);
                   }
                   iprot.readListEnd();
                 }
@@ -100903,9 +99607,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_indexes_result
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
-            for (Index _iter939 : struct.success)
+            for (Index _iter931 : struct.success)
             {
-              _iter939.write(oprot);
+              _iter931.write(oprot);
             }
             oprot.writeListEnd();
           }
@@ -100952,9 +99656,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_indexes_result
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (Index _iter940 : struct.success)
+            for (Index _iter932 : struct.success)
             {
-              _iter940.write(oprot);
+              _iter932.write(oprot);
             }
           }
         }
@@ -100972,14 +99676,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_indexes_result s
         BitSet incoming = iprot.readBitSet(3);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list941 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.success = new ArrayList<Index>(_list941.size);
-            for (int _i942 = 0; _i942 < _list941.size; ++_i942)
+            org.apache.thrift.protocol.TList _list933 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.success = new ArrayList<Index>(_list933.size);
+            for (int _i934 = 0; _i934 < _list933.size; ++_i934)
             {
-              Index _elem943; // required
-              _elem943 = new Index();
-              _elem943.read(iprot);
-              struct.success.add(_elem943);
+              Index _elem935; // required
+              _elem935 = new Index();
+              _elem935.read(iprot);
+              struct.success.add(_elem935);
             }
           }
           struct.setSuccessIsSet(true);
@@ -101961,13 +100665,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_index_names_res
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list944 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list944.size);
-                  for (int _i945 = 0; _i945 < _list944.size; ++_i945)
+                  org.apache.thrift.protocol.TList _list936 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list936.size);
+                  for (int _i937 = 0; _i937 < _list936.size; ++_i937)
                   {
-                    String _elem946; // required
-                    _elem946 = iprot.readString();
-                    struct.success.add(_elem946);
+                    String _elem938; // required
+                    _elem938 = iprot.readString();
+                    struct.success.add(_elem938);
                   }
                   iprot.readListEnd();
                 }
@@ -102002,9 +100706,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_index_names_re
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter947 : struct.success)
+            for (String _iter939 : struct.success)
             {
-              oprot.writeString(_iter947);
+              oprot.writeString(_iter939);
             }
             oprot.writeListEnd();
           }
@@ -102043,9 +100747,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_index_names_res
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter948 : struct.success)
+            for (String _iter940 : struct.success)
             {
-              oprot.writeString(_iter948);
+              oprot.writeString(_iter940);
             }
           }
         }
@@ -102060,13 +100764,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_index_names_resu
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list949 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list949.size);
-            for (int _i950 = 0; _i950 < _list949.size; ++_i950)
+            org.apache.thrift.protocol.TList _list941 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list941.size);
+            for (int _i942 = 0; _i942 < _list941.size; ++_i942)
             {
-              String _elem951; // required
-              _elem951 = iprot.readString();
-              struct.success.add(_elem951);
+              String _elem943; // required
+              _elem943 = iprot.readString();
+              struct.success.add(_elem943);
             }
           }
           struct.setSuccessIsSet(true);
@@ -117804,13 +116508,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_functions_resul
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list952 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list952.size);
-                  for (int _i953 = 0; _i953 < _list952.size; ++_i953)
+                  org.apache.thrift.protocol.TList _list944 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list944.size);
+                  for (int _i945 = 0; _i945 < _list944.size; ++_i945)
                   {
-                    String _elem954; // required
-                    _elem954 = iprot.readString();
-                    struct.success.add(_elem954);
+                    String _elem946; // required
+                    _elem946 = iprot.readString();
+                    struct.success.add(_elem946);
                   }
                   iprot.readListEnd();
                 }
@@ -117845,9 +116549,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_functions_resu
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter955 : struct.success)
+            for (String _iter947 : struct.success)
             {
-              oprot.writeString(_iter955);
+              oprot.writeString(_iter947);
             }
             oprot.writeListEnd();
           }
@@ -117886,9 +116590,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_functions_resul
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter956 : struct.success)
+            for (String _iter948 : struct.success)
             {
-              oprot.writeString(_iter956);
+              oprot.writeString(_iter948);
             }
           }
         }
@@ -117903,13 +116607,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_functions_result
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list957 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list957.size);
-            for (int _i958 = 0; _i958 < _list957.size; ++_i958)
+            org.apache.thrift.protocol.TList _list949 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list949.size);
+            for (int _i950 = 0; _i950 < _list949.size; ++_i950)
             {
-              String _elem959; // required
-              _elem959 = iprot.readString();
-              struct.success.add(_elem959);
+              String _elem951; // required
+              _elem951 = iprot.readString();
+              struct.success.add(_elem951);
             }
           }
           struct.setSuccessIsSet(true);
@@ -121967,13 +120671,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_role_names_resu
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list960 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list960.size);
-                  for (int _i961 = 0; _i961 < _list960.size; ++_i961)
+                  org.apache.thrift.protocol.TList _list952 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list952.size);
+                  for (int _i953 = 0; _i953 < _list952.size; ++_i953)
                   {
-                    String _elem962; // required
-                    _elem962 = iprot.readString();
-                    struct.success.add(_elem962);
+                    String _elem954; // required
+                    _elem954 = iprot.readString();
+                    struct.success.add(_elem954);
                   }
                   iprot.readListEnd();
                 }
@@ -122008,9 +120712,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_role_names_res
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter963 : struct.success)
+            for (String _iter955 : struct.success)
             {
-              oprot.writeString(_iter963);
+              oprot.writeString(_iter955);
             }
             oprot.writeListEnd();
           }
@@ -122049,9 +120753,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_role_names_resu
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter964 : struct.success)
+            for (String _iter956 : struct.success)
             {
-              oprot.writeString(_iter964);
+              oprot.writeString(_iter956);
             }
           }
         }
@@ -122066,13 +120770,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_role_names_resul
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list965 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list965.size);
-            for (int _i966 = 0; _i966 < _list965.size; ++_i966)
+            org.apache.thrift.protocol.TList _list957 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list957.size);
+            for (int _i958 = 0; _i958 < _list957.size; ++_i958)
             {
-              String _elem967; // required
-              _elem967 = iprot.readString();
-              struct.success.add(_elem967);
+              String _elem959; // required
+              _elem959 = iprot.readString();
+              struct.success.add(_elem959);
             }
           }
           struct.setSuccessIsSet(true);
@@ -125363,14 +124067,14 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, list_roles_result s
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list968 = iprot.readListBegin();
-                  struct.success = new ArrayList<Role>(_list968.size);
-                  for (int _i969 = 0; _i969 < _list968.size; ++_i969)
+                  org.apache.thrift.protocol.TList _list960 = iprot.readListBegin();
+                  struct.success = new ArrayList<Role>(_list960.size);
+                  for (int _i961 = 0; _i961 < _list960.size; ++_i961)
                   {
-                    Role _elem970; // required
-                    _elem970 = new Role();
-                    _elem970.read(iprot);
-                    struct.success.add(_elem970);
+                    Role _elem962; // required
+                    _elem962 = new Role();
+                    _elem962.read(iprot);
+                    struct.success.add(_elem962);
                   }
                   iprot.readListEnd();
                 }
@@ -125405,9 +124109,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, list_roles_result
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
-            for (Role _iter971 : struct.success)
+            for (Role _iter963 : struct.success)
             {
-              _iter971.write(oprot);
+              _iter963.write(oprot);
             }
             oprot.writeListEnd();
           }
@@ -125446,9 +124150,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, list_roles_result s
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (Role _iter972 : struct.success)
+            for (Role _iter964 : struct.success)
             {
-              _iter972.write(oprot);
+              _iter964.write(oprot);
             }
           }
         }
@@ -125463,14 +124167,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, list_roles_result st
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list973 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.success = new ArrayList<Role>(_list973.size);
-            for (int _i974 = 0; _i974 < _list973.size; ++_i974)
+            org.apache.thrift.protocol.TList _list965 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.success = new ArrayList<Role>(_list965.size);
+            for (int _i966 = 0; _i966 < _list965.size; ++_i966)
             {
-              Role _elem975; // required
-              _elem975 = new Role();
-              _elem975.read(iprot);
-              struct.success.add(_elem975);
+              Role _elem967; // required
+              _elem967 = new Role();
+              _elem967.read(iprot);
+              struct.success.add(_elem967);
             }
           }
           struct.setSuccessIsSet(true);
@@ -128478,13 +127182,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_privilege_set_a
             case 3: // GROUP_NAMES
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list976 = iprot.readListBegin();
-                  struct.group_names = new ArrayList<String>(_list976.size);
-                  for (int _i977 = 0; _i977 < _list976.size; ++_i977)
+                  org.apache.thrift.protocol.TList _list968 = iprot.readListBegin();
+                  struct.group_names = new ArrayList<String>(_list968.size);
+                  for (int _i969 = 0; _i969 < _list968.size; ++_i969)
                   {
-                    String _elem978; // required
-                    _elem978 = iprot.readString();
-                    struct.group_names.add(_elem978);
+                    String _elem970; // required
+                    _elem970 = iprot.readString();
+                    struct.group_names.add(_elem970);
                   }
                   iprot.readListEnd();
                 }
@@ -128520,9 +127224,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_privilege_set_
           oprot.writeFieldBegin(GROUP_NAMES_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.group_names.size()));
-            for (String _iter979 : struct.group_names)
+            for (String _iter971 : struct.group_names)
             {
-              oprot.writeString(_iter979);
+              oprot.writeString(_iter971);
             }
             oprot.writeListEnd();
           }
@@ -128565,9 +127269,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_privilege_set_a
         if (struct.isSetGroup_names()) {
           {
             oprot.writeI32(struct.group_names.size());
-            for (String _iter980 : struct.group_names)
+            for (String _iter972 : struct.group_names)
             {
-              oprot.writeString(_iter980);
+              oprot.writeString(_iter972);
             }
           }
         }
@@ -128588,13 +127292,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_privilege_set_ar
         }
         if (incoming.get(2)) {
           {
-            org.apache.thrift.protocol.TList _list981 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.group_names = new ArrayList<String>(_list981.size);
-            for (int _i982 = 0; _i982 < _list981.size; ++_i982)
+            org.apache.thrift.protocol.TList _list973 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.group_names = new ArrayList<String>(_list973.size);
+            for (int _i974 = 0; _i974 < _list973.size; ++_i974)
             {
-              String _elem983; // required
-              _elem983 = iprot.readString();
-              struct.group_names.add(_elem983);
+              String _elem975; // required
+              _elem975 = iprot.readString();
+              struct.group_names.add(_elem975);
             }
           }
           struct.setGroup_namesIsSet(true);
@@ -130052,14 +128756,14 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, list_privileges_res
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list984 = iprot.readListBegin();
-                  struct.success = new ArrayList<HiveObjectPrivilege>(_list984.size);
-                  for (int _i985 = 0; _i985 < _list984.size; ++_i985)
+                  org.apache.thrift.protocol.TList _list976 = iprot.readListBegin();
+                  struct.success = new ArrayList<HiveObjectPrivilege>(_list976.size);
+                  for (int _i977 = 0; _i977 < _list976.size; ++_i977)
                   {
-                    HiveObjectPrivilege _elem986; // required
-                    _elem986 = new HiveObjectPrivilege();
-                    _elem986.read(iprot);
-                    struct.success.add(_elem986);
+                    HiveObjectPrivilege _elem978; // required
+                    _elem978 = new HiveObjectPrivilege();
+                    _elem978.read(iprot);
+                    struct.success.add(_elem978);
                   }
                   iprot.readListEnd();
                 }
@@ -130094,9 +128798,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, list_privileges_re
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.success.size()));
-            for (HiveObjectPrivilege _iter987 : struct.success)
+            for (HiveObjectPrivilege _iter979 : struct.success)
             {
-              _iter987.write(oprot);
+              _iter979.write(oprot);
             }
             oprot.writeListEnd();
           }
@@ -130135,9 +128839,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, list_privileges_res
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (HiveObjectPrivilege _iter988 : struct.success)
+            for (HiveObjectPrivilege _iter980 : struct.success)
             {
-              _iter988.write(oprot);
+              _iter980.write(oprot);
             }
           }
         }
@@ -130152,14 +128856,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, list_privileges_resu
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list989 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-            struct.success = new ArrayList<HiveObjectPrivilege>(_list989.size);
-            for (int _i990 = 0; _i990 < _list989.size; ++_i990)
+            org.apache.thrift.protocol.TList _list981 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+            struct.success = new ArrayList<HiveObjectPrivilege>(_list981.size);
+            for (int _i982 = 0; _i982 < _list981.size; ++_i982)
             {
-              HiveObjectPrivilege _elem991; // required
-              _elem991 = new HiveObjectPrivilege();
-              _elem991.read(iprot);
-              struct.success.add(_elem991);
+              HiveObjectPrivilege _elem983; // required
+              _elem983 = new HiveObjectPrivilege();
+              _elem983.read(iprot);
+              struct.success.add(_elem983);
             }
           }
           struct.setSuccessIsSet(true);
@@ -133064,13 +131768,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, set_ugi_args struct
             case 2: // GROUP_NAMES
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list992 = iprot.readListBegin();
-                  struct.group_names = new ArrayList<String>(_list992.size);
-                  for (int _i993 = 0; _i993 < _list992.size; ++_i993)
+                  org.apache.thrift.protocol.TList _list984 = iprot.readListBegin();
+                  struct.group_names = new ArrayList<String>(_list984.size);
+                  for (int _i985 = 0; _i985 < _list984.size; ++_i985)
                   {
-                    String _elem994; // required
-                    _elem994 = iprot.readString();
-                    struct.group_names.add(_elem994);
+                    String _elem986; // required
+                    _elem986 = iprot.readString();
+                    struct.group_names.add(_elem986);
                   }
                   iprot.readListEnd();
                 }
@@ -133101,9 +131805,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, set_ugi_args struc
           oprot.writeFieldBegin(GROUP_NAMES_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.group_names.size()));
-            for (String _iter995 : struct.group_names)
+            for (String _iter987 : struct.group_names)
             {
-              oprot.writeString(_iter995);
+              oprot.writeString(_iter987);
             }
             oprot.writeListEnd();
           }
@@ -133140,9 +131844,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, set_ugi_args struct
         if (struct.isSetGroup_names()) {
           {
             oprot.writeI32(struct.group_names.size());
-            for (String _iter996 : struct.group_names)
+            for (String _iter988 : struct.group_names)
             {
-              oprot.writeString(_iter996);
+              oprot.writeString(_iter988);
             }
           }
         }
@@ -133158,13 +131862,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, set_ugi_args struct)
         }
         if (incoming.get(1)) {
           {
-            org.apache.thrift.protocol.TList _list997 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.group_names = new ArrayList<String>(_list997.size);
-            for (int _i998 = 0; _i998 < _list997.size; ++_i998)
+            org.apache.thrift.protocol.TList _list989 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.group_names = new ArrayList<String>(_list989.size);
+            for (int _i990 = 0; _i990 < _list989.size; ++_i990)
             {
-              String _elem999; // required
-              _elem999 = iprot.readString();
-              struct.group_names.add(_elem999);
+              String _elem991; // required
+              _elem991 = iprot.readString();
+              struct.group_names.add(_elem991);
             }
           }
           struct.setGroup_namesIsSet(true);
@@ -133570,13 +132274,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, set_ugi_result stru
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list1000 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list1000.size);
-                  for (int _i1001 = 0; _i1001 < _list1000.size; ++_i1001)
+                  org.apache.thrift.protocol.TList _list992 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list992.size);
+                  for (int _i993 = 0; _i993 < _list992.size; ++_i993)
                   {
-                    String _elem1002; // required
-                    _elem1002 = iprot.readString();
-                    struct.success.add(_elem1002);
+                    String _elem994; // required
+                    _elem994 = iprot.readString();
+                    struct.success.add(_elem994);
                   }
                   iprot.readListEnd();
                 }
@@ -133611,9 +132315,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, set_ugi_result str
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter1003 : struct.success)
+            for (String _iter995 : struct.success)
             {
-              oprot.writeString(_iter1003);
+              oprot.writeString(_iter995);
             }
             oprot.writeListEnd();
           }
@@ -133652,9 +132356,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, set_ugi_result stru
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter1004 : struct.success)
+            for (String _iter996 : struct.success)
             {
-              oprot.writeString(_iter1004);
+              oprot.writeString(_iter996);
             }
           }
         }
@@ -133669,13 +132373,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, set_ugi_result struc
         BitSet incoming = iprot.readBitSet(2);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list1005 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list1005.size);
-            for (int _i1006 = 0; _i1006 < _list1005.size; ++_i1006)
+            org.apache.thrift.protocol.TList _list997 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list997.size);
+            for (int _i998 = 0; _i998 < _list997.size; ++_i998)
             {
-              String _elem1007; // required
-              _elem1007 = iprot.readString();
-              struct.success.add(_elem1007);
+              String _elem999; // required
+              _elem999 = iprot.readString();
+              struct.success.add(_elem999);
             }
           }
           struct.setSuccessIsSet(true);
@@ -138969,13 +137673,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_all_token_ident
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list1008 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list1008.size);
-                  for (int _i1009 = 0; _i1009 < _list1008.size; ++_i1009)
+                  org.apache.thrift.protocol.TList _list1000 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list1000.size);
+                  for (int _i1001 = 0; _i1001 < _list1000.size; ++_i1001)
                   {
-                    String _elem1010; // required
-                    _elem1010 = iprot.readString();
-                    struct.success.add(_elem1010);
+                    String _elem1002; // required
+                    _elem1002 = iprot.readString();
+                    struct.success.add(_elem1002);
                   }
                   iprot.readListEnd();
                 }
@@ -139001,9 +137705,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_all_token_iden
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter1011 : struct.success)
+            for (String _iter1003 : struct.success)
             {
-              oprot.writeString(_iter1011);
+              oprot.writeString(_iter1003);
             }
             oprot.writeListEnd();
           }
@@ -139034,9 +137738,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_all_token_ident
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter1012 : struct.success)
+            for (String _iter1004 : struct.success)
             {
-              oprot.writeString(_iter1012);
+              oprot.writeString(_iter1004);
             }
           }
         }
@@ -139048,13 +137752,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_all_token_identi
         BitSet incoming = iprot.readBitSet(1);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list1013 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list1013.size);
-            for (int _i1014 = 0; _i1014 < _list1013.size; ++_i1014)
+            org.apache.thrift.protocol.TList _list1005 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list1005.size);
+            for (int _i1006 = 0; _i1006 < _list1005.size; ++_i1006)
             {
-              String _elem1015; // required
-              _elem1015 = iprot.readString();
-              struct.success.add(_elem1015);
+              String _elem1007; // required
+              _elem1007 = iprot.readString();
+              struct.success.add(_elem1007);
             }
           }
           struct.setSuccessIsSet(true);
@@ -142087,13 +140791,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, get_master_keys_res
             case 0: // SUCCESS
               if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
                 {
-                  org.apache.thrift.protocol.TList _list1016 = iprot.readListBegin();
-                  struct.success = new ArrayList<String>(_list1016.size);
-                  for (int _i1017 = 0; _i1017 < _list1016.size; ++_i1017)
+                  org.apache.thrift.protocol.TList _list1008 = iprot.readListBegin();
+                  struct.success = new ArrayList<String>(_list1008.size);
+                  for (int _i1009 = 0; _i1009 < _list1008.size; ++_i1009)
                   {
-                    String _elem1018; // required
-                    _elem1018 = iprot.readString();
-                    struct.success.add(_elem1018);
+                    String _elem1010; // required
+                    _elem1010 = iprot.readString();
+                    struct.success.add(_elem1010);
                   }
                   iprot.readListEnd();
                 }
@@ -142119,9 +140823,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, get_master_keys_re
           oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
           {
             oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.success.size()));
-            for (String _iter1019 : struct.success)
+            for (String _iter1011 : struct.success)
             {
-              oprot.writeString(_iter1019);
+              oprot.writeString(_iter1011);
             }
             oprot.writeListEnd();
           }
@@ -142152,9 +140856,9 @@ public void write(org.apache.thrift.protocol.TProtocol prot, get_master_keys_res
         if (struct.isSetSuccess()) {
           {
             oprot.writeI32(struct.success.size());
-            for (String _iter1020 : struct.success)
+            for (String _iter1012 : struct.success)
             {
-              oprot.writeString(_iter1020);
+              oprot.writeString(_iter1012);
             }
           }
         }
@@ -142166,13 +140870,13 @@ public void read(org.apache.thrift.protocol.TProtocol prot, get_master_keys_resu
         BitSet incoming = iprot.readBitSet(1);
         if (incoming.get(0)) {
           {
-            org.apache.thrift.protocol.TList _list1021 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-            struct.success = new ArrayList<String>(_list1021.size);
-            for (int _i1022 = 0; _i1022 < _list1021.size; ++_i1022)
+            org.apache.thrift.protocol.TList _list1013 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+            struct.success = new ArrayList<String>(_list1013.size);
+            for (int _i1014 = 0; _i1014 < _list1013.size; ++_i1014)
             {
-              String _elem1023; // required
-              _elem1023 = iprot.readString();
-              struct.success.add(_elem1023);
+              String _elem1015; // required
+              _elem1015 = iprot.readString();
+              struct.success.add(_elem1015);
             }
           }
           struct.setSuccessIsSet(true);
diff --git a/metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php b/metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
index a0bd13d..b74fc53 100644
--- a/metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
+++ b/metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
@@ -78,7 +78,6 @@ interface ThriftHiveMetastoreIf extends \FacebookServiceIf {
   public function get_partitions_by_names($db_name, $tbl_name, $names);
   public function alter_partition($db_name, $tbl_name, \metastore\Partition $new_part);
   public function alter_partitions($db_name, $tbl_name, $new_parts);
-  public function alter_partitions_with_environment_context($db_name, $tbl_name, $new_parts, \metastore\EnvironmentContext $environment_context);
   public function alter_partition_with_environment_context($db_name, $tbl_name, \metastore\Partition $new_part, \metastore\EnvironmentContext $environment_context);
   public function rename_partition($db_name, $tbl_name, $part_vals, \metastore\Partition $new_part);
   public function partition_name_has_valid_characters($part_vals, $throw_exception);
@@ -3811,63 +3810,6 @@ class ThriftHiveMetastoreClient extends \FacebookServiceClient implements \metas
     return;
   }
 
-  public function alter_partitions_with_environment_context($db_name, $tbl_name, $new_parts, \metastore\EnvironmentContext $environment_context)
-  {
-    $this->send_alter_partitions_with_environment_context($db_name, $tbl_name, $new_parts, $environment_context);
-    $this->recv_alter_partitions_with_environment_context();
-  }
-
-  public function send_alter_partitions_with_environment_context($db_name, $tbl_name, $new_parts, \metastore\EnvironmentContext $environment_context)
-  {
-    $args = new \metastore\ThriftHiveMetastore_alter_partitions_with_environment_context_args();
-    $args->db_name = $db_name;
-    $args->tbl_name = $tbl_name;
-    $args->new_parts = $new_parts;
-    $args->environment_context = $environment_context;
-    $bin_accel = ($this->output_ instanceof TProtocol::$TBINARYPROTOCOLACCELERATED) && function_exists('thrift_protocol_write_binary');
-    if ($bin_accel)
-    {
-      thrift_protocol_write_binary($this->output_, 'alter_partitions_with_environment_context', TMessageType::CALL, $args, $this->seqid_, $this->output_->isStrictWrite());
-    }
-    else
-    {
-      $this->output_->writeMessageBegin('alter_partitions_with_environment_context', TMessageType::CALL, $this->seqid_);
-      $args->write($this->output_);
-      $this->output_->writeMessageEnd();
-      $this->output_->getTransport()->flush();
-    }
-  }
-
-  public function recv_alter_partitions_with_environment_context()
-  {
-    $bin_accel = ($this->input_ instanceof TProtocol::$TBINARYPROTOCOLACCELERATED) && function_exists('thrift_protocol_read_binary');
-    if ($bin_accel) $result = thrift_protocol_read_binary($this->input_, '\metastore\ThriftHiveMetastore_alter_partitions_with_environment_context_result', $this->input_->isStrictRead());
-    else
-    {
-      $rseqid = 0;
-      $fname = null;
-      $mtype = 0;
-
-      $this->input_->readMessageBegin($fname, $mtype, $rseqid);
-      if ($mtype == TMessageType::EXCEPTION) {
-        $x = new TApplicationException();
-        $x->read($this->input_);
-        $this->input_->readMessageEnd();
-        throw $x;
-      }
-      $result = new \metastore\ThriftHiveMetastore_alter_partitions_with_environment_context_result();
-      $result->read($this->input_);
-      $this->input_->readMessageEnd();
-    }
-    if ($result->o1 !== null) {
-      throw $result->o1;
-    }
-    if ($result->o2 !== null) {
-      throw $result->o2;
-    }
-    return;
-  }
-
   public function alter_partition_with_environment_context($db_name, $tbl_name, \metastore\Partition $new_part, \metastore\EnvironmentContext $environment_context)
   {
     $this->send_alter_partition_with_environment_context($db_name, $tbl_name, $new_part, $environment_context);
@@ -23210,267 +23152,6 @@ class ThriftHiveMetastore_alter_partitions_result {
 
 }
 
-class ThriftHiveMetastore_alter_partitions_with_environment_context_args {
-  static $_TSPEC;
-
-  public $db_name = null;
-  public $tbl_name = null;
-  public $new_parts = null;
-  public $environment_context = null;
-
-  public function __construct($vals=null) {
-    if (!isset(self::$_TSPEC)) {
-      self::$_TSPEC = array(
-        1 => array(
-          'var' => 'db_name',
-          'type' => TType::STRING,
-          ),
-        2 => array(
-          'var' => 'tbl_name',
-          'type' => TType::STRING,
-          ),
-        3 => array(
-          'var' => 'new_parts',
-          'type' => TType::LST,
-          'etype' => TType::STRUCT,
-          'elem' => array(
-            'type' => TType::STRUCT,
-            'class' => '\metastore\Partition',
-            ),
-          ),
-        4 => array(
-          'var' => 'environment_context',
-          'type' => TType::STRUCT,
-          'class' => '\metastore\EnvironmentContext',
-          ),
-        );
-    }
-    if (is_array($vals)) {
-      if (isset($vals['db_name'])) {
-        $this->db_name = $vals['db_name'];
-      }
-      if (isset($vals['tbl_name'])) {
-        $this->tbl_name = $vals['tbl_name'];
-      }
-      if (isset($vals['new_parts'])) {
-        $this->new_parts = $vals['new_parts'];
-      }
-      if (isset($vals['environment_context'])) {
-        $this->environment_context = $vals['environment_context'];
-      }
-    }
-  }
-
-  public function getName() {
-    return 'ThriftHiveMetastore_alter_partitions_with_environment_context_args';
-  }
-
-  public function read($input)
-  {
-    $xfer = 0;
-    $fname = null;
-    $ftype = 0;
-    $fid = 0;
-    $xfer += $input->readStructBegin($fname);
-    while (true)
-    {
-      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
-      if ($ftype == TType::STOP) {
-        break;
-      }
-      switch ($fid)
-      {
-        case 1:
-          if ($ftype == TType::STRING) {
-            $xfer += $input->readString($this->db_name);
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        case 2:
-          if ($ftype == TType::STRING) {
-            $xfer += $input->readString($this->tbl_name);
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        case 3:
-          if ($ftype == TType::LST) {
-            $this->new_parts = array();
-            $_size772 = 0;
-            $_etype775 = 0;
-            $xfer += $input->readListBegin($_etype775, $_size772);
-            for ($_i776 = 0; $_i776 < $_size772; ++$_i776)
-            {
-              $elem777 = null;
-              $elem777 = new \metastore\Partition();
-              $xfer += $elem777->read($input);
-              $this->new_parts []= $elem777;
-            }
-            $xfer += $input->readListEnd();
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        case 4:
-          if ($ftype == TType::STRUCT) {
-            $this->environment_context = new \metastore\EnvironmentContext();
-            $xfer += $this->environment_context->read($input);
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        default:
-          $xfer += $input->skip($ftype);
-          break;
-      }
-      $xfer += $input->readFieldEnd();
-    }
-    $xfer += $input->readStructEnd();
-    return $xfer;
-  }
-
-  public function write($output) {
-    $xfer = 0;
-    $xfer += $output->writeStructBegin('ThriftHiveMetastore_alter_partitions_with_environment_context_args');
-    if ($this->db_name !== null) {
-      $xfer += $output->writeFieldBegin('db_name', TType::STRING, 1);
-      $xfer += $output->writeString($this->db_name);
-      $xfer += $output->writeFieldEnd();
-    }
-    if ($this->tbl_name !== null) {
-      $xfer += $output->writeFieldBegin('tbl_name', TType::STRING, 2);
-      $xfer += $output->writeString($this->tbl_name);
-      $xfer += $output->writeFieldEnd();
-    }
-    if ($this->new_parts !== null) {
-      if (!is_array($this->new_parts)) {
-        throw new TProtocolException('Bad type in structure.', TProtocolException::INVALID_DATA);
-      }
-      $xfer += $output->writeFieldBegin('new_parts', TType::LST, 3);
-      {
-        $output->writeListBegin(TType::STRUCT, count($this->new_parts));
-        {
-          foreach ($this->new_parts as $iter778)
-          {
-            $xfer += $iter778->write($output);
-          }
-        }
-        $output->writeListEnd();
-      }
-      $xfer += $output->writeFieldEnd();
-    }
-    if ($this->environment_context !== null) {
-      if (!is_object($this->environment_context)) {
-        throw new TProtocolException('Bad type in structure.', TProtocolException::INVALID_DATA);
-      }
-      $xfer += $output->writeFieldBegin('environment_context', TType::STRUCT, 4);
-      $xfer += $this->environment_context->write($output);
-      $xfer += $output->writeFieldEnd();
-    }
-    $xfer += $output->writeFieldStop();
-    $xfer += $output->writeStructEnd();
-    return $xfer;
-  }
-
-}
-
-class ThriftHiveMetastore_alter_partitions_with_environment_context_result {
-  static $_TSPEC;
-
-  public $o1 = null;
-  public $o2 = null;
-
-  public function __construct($vals=null) {
-    if (!isset(self::$_TSPEC)) {
-      self::$_TSPEC = array(
-        1 => array(
-          'var' => 'o1',
-          'type' => TType::STRUCT,
-          'class' => '\metastore\InvalidOperationException',
-          ),
-        2 => array(
-          'var' => 'o2',
-          'type' => TType::STRUCT,
-          'class' => '\metastore\MetaException',
-          ),
-        );
-    }
-    if (is_array($vals)) {
-      if (isset($vals['o1'])) {
-        $this->o1 = $vals['o1'];
-      }
-      if (isset($vals['o2'])) {
-        $this->o2 = $vals['o2'];
-      }
-    }
-  }
-
-  public function getName() {
-    return 'ThriftHiveMetastore_alter_partitions_with_environment_context_result';
-  }
-
-  public function read($input)
-  {
-    $xfer = 0;
-    $fname = null;
-    $ftype = 0;
-    $fid = 0;
-    $xfer += $input->readStructBegin($fname);
-    while (true)
-    {
-      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
-      if ($ftype == TType::STOP) {
-        break;
-      }
-      switch ($fid)
-      {
-        case 1:
-          if ($ftype == TType::STRUCT) {
-            $this->o1 = new \metastore\InvalidOperationException();
-            $xfer += $this->o1->read($input);
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        case 2:
-          if ($ftype == TType::STRUCT) {
-            $this->o2 = new \metastore\MetaException();
-            $xfer += $this->o2->read($input);
-          } else {
-            $xfer += $input->skip($ftype);
-          }
-          break;
-        default:
-          $xfer += $input->skip($ftype);
-          break;
-      }
-      $xfer += $input->readFieldEnd();
-    }
-    $xfer += $input->readStructEnd();
-    return $xfer;
-  }
-
-  public function write($output) {
-    $xfer = 0;
-    $xfer += $output->writeStructBegin('ThriftHiveMetastore_alter_partitions_with_environment_context_result');
-    if ($this->o1 !== null) {
-      $xfer += $output->writeFieldBegin('o1', TType::STRUCT, 1);
-      $xfer += $this->o1->write($output);
-      $xfer += $output->writeFieldEnd();
-    }
-    if ($this->o2 !== null) {
-      $xfer += $output->writeFieldBegin('o2', TType::STRUCT, 2);
-      $xfer += $this->o2->write($output);
-      $xfer += $output->writeFieldEnd();
-    }
-    $xfer += $output->writeFieldStop();
-    $xfer += $output->writeStructEnd();
-    return $xfer;
-  }
-
-}
-
 class ThriftHiveMetastore_alter_partition_with_environment_context_args {
   static $_TSPEC;
 
@@ -23795,14 +23476,14 @@ class ThriftHiveMetastore_rename_partition_args {
         case 3:
           if ($ftype == TType::LST) {
             $this->part_vals = array();
-            $_size779 = 0;
-            $_etype782 = 0;
-            $xfer += $input->readListBegin($_etype782, $_size779);
-            for ($_i783 = 0; $_i783 < $_size779; ++$_i783)
+            $_size772 = 0;
+            $_etype775 = 0;
+            $xfer += $input->readListBegin($_etype775, $_size772);
+            for ($_i776 = 0; $_i776 < $_size772; ++$_i776)
             {
-              $elem784 = null;
-              $xfer += $input->readString($elem784);
-              $this->part_vals []= $elem784;
+              $elem777 = null;
+              $xfer += $input->readString($elem777);
+              $this->part_vals []= $elem777;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -23848,9 +23529,9 @@ class ThriftHiveMetastore_rename_partition_args {
       {
         $output->writeListBegin(TType::STRING, count($this->part_vals));
         {
-          foreach ($this->part_vals as $iter785)
+          foreach ($this->part_vals as $iter778)
           {
-            $xfer += $output->writeString($iter785);
+            $xfer += $output->writeString($iter778);
           }
         }
         $output->writeListEnd();
@@ -24023,14 +23704,14 @@ class ThriftHiveMetastore_partition_name_has_valid_characters_args {
         case 1:
           if ($ftype == TType::LST) {
             $this->part_vals = array();
-            $_size786 = 0;
-            $_etype789 = 0;
-            $xfer += $input->readListBegin($_etype789, $_size786);
-            for ($_i790 = 0; $_i790 < $_size786; ++$_i790)
+            $_size779 = 0;
+            $_etype782 = 0;
+            $xfer += $input->readListBegin($_etype782, $_size779);
+            for ($_i783 = 0; $_i783 < $_size779; ++$_i783)
             {
-              $elem791 = null;
-              $xfer += $input->readString($elem791);
-              $this->part_vals []= $elem791;
+              $elem784 = null;
+              $xfer += $input->readString($elem784);
+              $this->part_vals []= $elem784;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -24065,9 +23746,9 @@ class ThriftHiveMetastore_partition_name_has_valid_characters_args {
       {
         $output->writeListBegin(TType::STRING, count($this->part_vals));
         {
-          foreach ($this->part_vals as $iter792)
+          foreach ($this->part_vals as $iter785)
           {
-            $xfer += $output->writeString($iter792);
+            $xfer += $output->writeString($iter785);
           }
         }
         $output->writeListEnd();
@@ -24494,14 +24175,14 @@ class ThriftHiveMetastore_partition_name_to_vals_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size793 = 0;
-            $_etype796 = 0;
-            $xfer += $input->readListBegin($_etype796, $_size793);
-            for ($_i797 = 0; $_i797 < $_size793; ++$_i797)
+            $_size786 = 0;
+            $_etype789 = 0;
+            $xfer += $input->readListBegin($_etype789, $_size786);
+            for ($_i790 = 0; $_i790 < $_size786; ++$_i790)
             {
-              $elem798 = null;
-              $xfer += $input->readString($elem798);
-              $this->success []= $elem798;
+              $elem791 = null;
+              $xfer += $input->readString($elem791);
+              $this->success []= $elem791;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -24537,9 +24218,9 @@ class ThriftHiveMetastore_partition_name_to_vals_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter799)
+          foreach ($this->success as $iter792)
           {
-            $xfer += $output->writeString($iter799);
+            $xfer += $output->writeString($iter792);
           }
         }
         $output->writeListEnd();
@@ -24690,17 +24371,17 @@ class ThriftHiveMetastore_partition_name_to_spec_result {
         case 0:
           if ($ftype == TType::MAP) {
             $this->success = array();
-            $_size800 = 0;
-            $_ktype801 = 0;
-            $_vtype802 = 0;
-            $xfer += $input->readMapBegin($_ktype801, $_vtype802, $_size800);
-            for ($_i804 = 0; $_i804 < $_size800; ++$_i804)
+            $_size793 = 0;
+            $_ktype794 = 0;
+            $_vtype795 = 0;
+            $xfer += $input->readMapBegin($_ktype794, $_vtype795, $_size793);
+            for ($_i797 = 0; $_i797 < $_size793; ++$_i797)
             {
-              $key805 = '';
-              $val806 = '';
-              $xfer += $input->readString($key805);
-              $xfer += $input->readString($val806);
-              $this->success[$key805] = $val806;
+              $key798 = '';
+              $val799 = '';
+              $xfer += $input->readString($key798);
+              $xfer += $input->readString($val799);
+              $this->success[$key798] = $val799;
             }
             $xfer += $input->readMapEnd();
           } else {
@@ -24736,10 +24417,10 @@ class ThriftHiveMetastore_partition_name_to_spec_result {
       {
         $output->writeMapBegin(TType::STRING, TType::STRING, count($this->success));
         {
-          foreach ($this->success as $kiter807 => $viter808)
+          foreach ($this->success as $kiter800 => $viter801)
           {
-            $xfer += $output->writeString($kiter807);
-            $xfer += $output->writeString($viter808);
+            $xfer += $output->writeString($kiter800);
+            $xfer += $output->writeString($viter801);
           }
         }
         $output->writeMapEnd();
@@ -24847,17 +24528,17 @@ class ThriftHiveMetastore_markPartitionForEvent_args {
         case 3:
           if ($ftype == TType::MAP) {
             $this->part_vals = array();
-            $_size809 = 0;
-            $_ktype810 = 0;
-            $_vtype811 = 0;
-            $xfer += $input->readMapBegin($_ktype810, $_vtype811, $_size809);
-            for ($_i813 = 0; $_i813 < $_size809; ++$_i813)
+            $_size802 = 0;
+            $_ktype803 = 0;
+            $_vtype804 = 0;
+            $xfer += $input->readMapBegin($_ktype803, $_vtype804, $_size802);
+            for ($_i806 = 0; $_i806 < $_size802; ++$_i806)
             {
-              $key814 = '';
-              $val815 = '';
-              $xfer += $input->readString($key814);
-              $xfer += $input->readString($val815);
-              $this->part_vals[$key814] = $val815;
+              $key807 = '';
+              $val808 = '';
+              $xfer += $input->readString($key807);
+              $xfer += $input->readString($val808);
+              $this->part_vals[$key807] = $val808;
             }
             $xfer += $input->readMapEnd();
           } else {
@@ -24902,10 +24583,10 @@ class ThriftHiveMetastore_markPartitionForEvent_args {
       {
         $output->writeMapBegin(TType::STRING, TType::STRING, count($this->part_vals));
         {
-          foreach ($this->part_vals as $kiter816 => $viter817)
+          foreach ($this->part_vals as $kiter809 => $viter810)
           {
-            $xfer += $output->writeString($kiter816);
-            $xfer += $output->writeString($viter817);
+            $xfer += $output->writeString($kiter809);
+            $xfer += $output->writeString($viter810);
           }
         }
         $output->writeMapEnd();
@@ -25197,17 +24878,17 @@ class ThriftHiveMetastore_isPartitionMarkedForEvent_args {
         case 3:
           if ($ftype == TType::MAP) {
             $this->part_vals = array();
-            $_size818 = 0;
-            $_ktype819 = 0;
-            $_vtype820 = 0;
-            $xfer += $input->readMapBegin($_ktype819, $_vtype820, $_size818);
-            for ($_i822 = 0; $_i822 < $_size818; ++$_i822)
+            $_size811 = 0;
+            $_ktype812 = 0;
+            $_vtype813 = 0;
+            $xfer += $input->readMapBegin($_ktype812, $_vtype813, $_size811);
+            for ($_i815 = 0; $_i815 < $_size811; ++$_i815)
             {
-              $key823 = '';
-              $val824 = '';
-              $xfer += $input->readString($key823);
-              $xfer += $input->readString($val824);
-              $this->part_vals[$key823] = $val824;
+              $key816 = '';
+              $val817 = '';
+              $xfer += $input->readString($key816);
+              $xfer += $input->readString($val817);
+              $this->part_vals[$key816] = $val817;
             }
             $xfer += $input->readMapEnd();
           } else {
@@ -25252,10 +24933,10 @@ class ThriftHiveMetastore_isPartitionMarkedForEvent_args {
       {
         $output->writeMapBegin(TType::STRING, TType::STRING, count($this->part_vals));
         {
-          foreach ($this->part_vals as $kiter825 => $viter826)
+          foreach ($this->part_vals as $kiter818 => $viter819)
           {
-            $xfer += $output->writeString($kiter825);
-            $xfer += $output->writeString($viter826);
+            $xfer += $output->writeString($kiter818);
+            $xfer += $output->writeString($viter819);
           }
         }
         $output->writeMapEnd();
@@ -26615,15 +26296,15 @@ class ThriftHiveMetastore_get_indexes_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size827 = 0;
-            $_etype830 = 0;
-            $xfer += $input->readListBegin($_etype830, $_size827);
-            for ($_i831 = 0; $_i831 < $_size827; ++$_i831)
+            $_size820 = 0;
+            $_etype823 = 0;
+            $xfer += $input->readListBegin($_etype823, $_size820);
+            for ($_i824 = 0; $_i824 < $_size820; ++$_i824)
             {
-              $elem832 = null;
-              $elem832 = new \metastore\Index();
-              $xfer += $elem832->read($input);
-              $this->success []= $elem832;
+              $elem825 = null;
+              $elem825 = new \metastore\Index();
+              $xfer += $elem825->read($input);
+              $this->success []= $elem825;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -26667,9 +26348,9 @@ class ThriftHiveMetastore_get_indexes_result {
       {
         $output->writeListBegin(TType::STRUCT, count($this->success));
         {
-          foreach ($this->success as $iter833)
+          foreach ($this->success as $iter826)
           {
-            $xfer += $iter833->write($output);
+            $xfer += $iter826->write($output);
           }
         }
         $output->writeListEnd();
@@ -26861,14 +26542,14 @@ class ThriftHiveMetastore_get_index_names_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size834 = 0;
-            $_etype837 = 0;
-            $xfer += $input->readListBegin($_etype837, $_size834);
-            for ($_i838 = 0; $_i838 < $_size834; ++$_i838)
+            $_size827 = 0;
+            $_etype830 = 0;
+            $xfer += $input->readListBegin($_etype830, $_size827);
+            for ($_i831 = 0; $_i831 < $_size827; ++$_i831)
             {
-              $elem839 = null;
-              $xfer += $input->readString($elem839);
-              $this->success []= $elem839;
+              $elem832 = null;
+              $xfer += $input->readString($elem832);
+              $this->success []= $elem832;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -26904,9 +26585,9 @@ class ThriftHiveMetastore_get_index_names_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter840)
+          foreach ($this->success as $iter833)
           {
-            $xfer += $output->writeString($iter840);
+            $xfer += $output->writeString($iter833);
           }
         }
         $output->writeListEnd();
@@ -30134,14 +29815,14 @@ class ThriftHiveMetastore_get_functions_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size841 = 0;
-            $_etype844 = 0;
-            $xfer += $input->readListBegin($_etype844, $_size841);
-            for ($_i845 = 0; $_i845 < $_size841; ++$_i845)
+            $_size834 = 0;
+            $_etype837 = 0;
+            $xfer += $input->readListBegin($_etype837, $_size834);
+            for ($_i838 = 0; $_i838 < $_size834; ++$_i838)
             {
-              $elem846 = null;
-              $xfer += $input->readString($elem846);
-              $this->success []= $elem846;
+              $elem839 = null;
+              $xfer += $input->readString($elem839);
+              $this->success []= $elem839;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -30177,9 +29858,9 @@ class ThriftHiveMetastore_get_functions_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter847)
+          foreach ($this->success as $iter840)
           {
-            $xfer += $output->writeString($iter847);
+            $xfer += $output->writeString($iter840);
           }
         }
         $output->writeListEnd();
@@ -31003,14 +30684,14 @@ class ThriftHiveMetastore_get_role_names_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size848 = 0;
-            $_etype851 = 0;
-            $xfer += $input->readListBegin($_etype851, $_size848);
-            for ($_i852 = 0; $_i852 < $_size848; ++$_i852)
+            $_size841 = 0;
+            $_etype844 = 0;
+            $xfer += $input->readListBegin($_etype844, $_size841);
+            for ($_i845 = 0; $_i845 < $_size841; ++$_i845)
             {
-              $elem853 = null;
-              $xfer += $input->readString($elem853);
-              $this->success []= $elem853;
+              $elem846 = null;
+              $xfer += $input->readString($elem846);
+              $this->success []= $elem846;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -31046,9 +30727,9 @@ class ThriftHiveMetastore_get_role_names_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter854)
+          foreach ($this->success as $iter847)
           {
-            $xfer += $output->writeString($iter854);
+            $xfer += $output->writeString($iter847);
           }
         }
         $output->writeListEnd();
@@ -31688,15 +31369,15 @@ class ThriftHiveMetastore_list_roles_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size855 = 0;
-            $_etype858 = 0;
-            $xfer += $input->readListBegin($_etype858, $_size855);
-            for ($_i859 = 0; $_i859 < $_size855; ++$_i859)
+            $_size848 = 0;
+            $_etype851 = 0;
+            $xfer += $input->readListBegin($_etype851, $_size848);
+            for ($_i852 = 0; $_i852 < $_size848; ++$_i852)
             {
-              $elem860 = null;
-              $elem860 = new \metastore\Role();
-              $xfer += $elem860->read($input);
-              $this->success []= $elem860;
+              $elem853 = null;
+              $elem853 = new \metastore\Role();
+              $xfer += $elem853->read($input);
+              $this->success []= $elem853;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -31732,9 +31413,9 @@ class ThriftHiveMetastore_list_roles_result {
       {
         $output->writeListBegin(TType::STRUCT, count($this->success));
         {
-          foreach ($this->success as $iter861)
+          foreach ($this->success as $iter854)
           {
-            $xfer += $iter861->write($output);
+            $xfer += $iter854->write($output);
           }
         }
         $output->writeListEnd();
@@ -32360,14 +32041,14 @@ class ThriftHiveMetastore_get_privilege_set_args {
         case 3:
           if ($ftype == TType::LST) {
             $this->group_names = array();
-            $_size862 = 0;
-            $_etype865 = 0;
-            $xfer += $input->readListBegin($_etype865, $_size862);
-            for ($_i866 = 0; $_i866 < $_size862; ++$_i866)
+            $_size855 = 0;
+            $_etype858 = 0;
+            $xfer += $input->readListBegin($_etype858, $_size855);
+            for ($_i859 = 0; $_i859 < $_size855; ++$_i859)
             {
-              $elem867 = null;
-              $xfer += $input->readString($elem867);
-              $this->group_names []= $elem867;
+              $elem860 = null;
+              $xfer += $input->readString($elem860);
+              $this->group_names []= $elem860;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -32408,9 +32089,9 @@ class ThriftHiveMetastore_get_privilege_set_args {
       {
         $output->writeListBegin(TType::STRING, count($this->group_names));
         {
-          foreach ($this->group_names as $iter868)
+          foreach ($this->group_names as $iter861)
           {
-            $xfer += $output->writeString($iter868);
+            $xfer += $output->writeString($iter861);
           }
         }
         $output->writeListEnd();
@@ -32697,15 +32378,15 @@ class ThriftHiveMetastore_list_privileges_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size869 = 0;
-            $_etype872 = 0;
-            $xfer += $input->readListBegin($_etype872, $_size869);
-            for ($_i873 = 0; $_i873 < $_size869; ++$_i873)
+            $_size862 = 0;
+            $_etype865 = 0;
+            $xfer += $input->readListBegin($_etype865, $_size862);
+            for ($_i866 = 0; $_i866 < $_size862; ++$_i866)
             {
-              $elem874 = null;
-              $elem874 = new \metastore\HiveObjectPrivilege();
-              $xfer += $elem874->read($input);
-              $this->success []= $elem874;
+              $elem867 = null;
+              $elem867 = new \metastore\HiveObjectPrivilege();
+              $xfer += $elem867->read($input);
+              $this->success []= $elem867;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -32741,9 +32422,9 @@ class ThriftHiveMetastore_list_privileges_result {
       {
         $output->writeListBegin(TType::STRUCT, count($this->success));
         {
-          foreach ($this->success as $iter875)
+          foreach ($this->success as $iter868)
           {
-            $xfer += $iter875->write($output);
+            $xfer += $iter868->write($output);
           }
         }
         $output->writeListEnd();
@@ -33342,14 +33023,14 @@ class ThriftHiveMetastore_set_ugi_args {
         case 2:
           if ($ftype == TType::LST) {
             $this->group_names = array();
-            $_size876 = 0;
-            $_etype879 = 0;
-            $xfer += $input->readListBegin($_etype879, $_size876);
-            for ($_i880 = 0; $_i880 < $_size876; ++$_i880)
+            $_size869 = 0;
+            $_etype872 = 0;
+            $xfer += $input->readListBegin($_etype872, $_size869);
+            for ($_i873 = 0; $_i873 < $_size869; ++$_i873)
             {
-              $elem881 = null;
-              $xfer += $input->readString($elem881);
-              $this->group_names []= $elem881;
+              $elem874 = null;
+              $xfer += $input->readString($elem874);
+              $this->group_names []= $elem874;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -33382,9 +33063,9 @@ class ThriftHiveMetastore_set_ugi_args {
       {
         $output->writeListBegin(TType::STRING, count($this->group_names));
         {
-          foreach ($this->group_names as $iter882)
+          foreach ($this->group_names as $iter875)
           {
-            $xfer += $output->writeString($iter882);
+            $xfer += $output->writeString($iter875);
           }
         }
         $output->writeListEnd();
@@ -33454,14 +33135,14 @@ class ThriftHiveMetastore_set_ugi_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size883 = 0;
-            $_etype886 = 0;
-            $xfer += $input->readListBegin($_etype886, $_size883);
-            for ($_i887 = 0; $_i887 < $_size883; ++$_i887)
+            $_size876 = 0;
+            $_etype879 = 0;
+            $xfer += $input->readListBegin($_etype879, $_size876);
+            for ($_i880 = 0; $_i880 < $_size876; ++$_i880)
             {
-              $elem888 = null;
-              $xfer += $input->readString($elem888);
-              $this->success []= $elem888;
+              $elem881 = null;
+              $xfer += $input->readString($elem881);
+              $this->success []= $elem881;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -33497,9 +33178,9 @@ class ThriftHiveMetastore_set_ugi_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter889)
+          foreach ($this->success as $iter882)
           {
-            $xfer += $output->writeString($iter889);
+            $xfer += $output->writeString($iter882);
           }
         }
         $output->writeListEnd();
@@ -34565,14 +34246,14 @@ class ThriftHiveMetastore_get_all_token_identifiers_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size890 = 0;
-            $_etype893 = 0;
-            $xfer += $input->readListBegin($_etype893, $_size890);
-            for ($_i894 = 0; $_i894 < $_size890; ++$_i894)
+            $_size883 = 0;
+            $_etype886 = 0;
+            $xfer += $input->readListBegin($_etype886, $_size883);
+            for ($_i887 = 0; $_i887 < $_size883; ++$_i887)
             {
-              $elem895 = null;
-              $xfer += $input->readString($elem895);
-              $this->success []= $elem895;
+              $elem888 = null;
+              $xfer += $input->readString($elem888);
+              $this->success []= $elem888;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -34600,9 +34281,9 @@ class ThriftHiveMetastore_get_all_token_identifiers_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter896)
+          foreach ($this->success as $iter889)
           {
-            $xfer += $output->writeString($iter896);
+            $xfer += $output->writeString($iter889);
           }
         }
         $output->writeListEnd();
@@ -35211,14 +34892,14 @@ class ThriftHiveMetastore_get_master_keys_result {
         case 0:
           if ($ftype == TType::LST) {
             $this->success = array();
-            $_size897 = 0;
-            $_etype900 = 0;
-            $xfer += $input->readListBegin($_etype900, $_size897);
-            for ($_i901 = 0; $_i901 < $_size897; ++$_i901)
+            $_size890 = 0;
+            $_etype893 = 0;
+            $xfer += $input->readListBegin($_etype893, $_size890);
+            for ($_i894 = 0; $_i894 < $_size890; ++$_i894)
             {
-              $elem902 = null;
-              $xfer += $input->readString($elem902);
-              $this->success []= $elem902;
+              $elem895 = null;
+              $xfer += $input->readString($elem895);
+              $this->success []= $elem895;
             }
             $xfer += $input->readListEnd();
           } else {
@@ -35246,9 +34927,9 @@ class ThriftHiveMetastore_get_master_keys_result {
       {
         $output->writeListBegin(TType::STRING, count($this->success));
         {
-          foreach ($this->success as $iter903)
+          foreach ($this->success as $iter896)
           {
-            $xfer += $output->writeString($iter903);
+            $xfer += $output->writeString($iter896);
           }
         }
         $output->writeListEnd();
diff --git a/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote b/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote
index a5222ee..dfaa362 100755
--- a/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote
+++ b/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote
@@ -85,7 +85,6 @@ if len(sys.argv) <= 1 or sys.argv[1] == '--help':
   print '   get_partitions_by_names(string db_name, string tbl_name,  names)'
   print '  void alter_partition(string db_name, string tbl_name, Partition new_part)'
   print '  void alter_partitions(string db_name, string tbl_name,  new_parts)'
-  print '  void alter_partitions_with_environment_context(string db_name, string tbl_name,  new_parts, EnvironmentContext environment_context)'
   print '  void alter_partition_with_environment_context(string db_name, string tbl_name, Partition new_part, EnvironmentContext environment_context)'
   print '  void rename_partition(string db_name, string tbl_name,  part_vals, Partition new_part)'
   print '  bool partition_name_has_valid_characters( part_vals, bool throw_exception)'
@@ -582,12 +581,6 @@ elif cmd == 'alter_partitions':
     sys.exit(1)
   pp.pprint(client.alter_partitions(args[0],args[1],eval(args[2]),))
 
-elif cmd == 'alter_partitions_with_environment_context':
-  if len(args) != 4:
-    print 'alter_partitions_with_environment_context requires 4 args'
-    sys.exit(1)
-  pp.pprint(client.alter_partitions_with_environment_context(args[0],args[1],eval(args[2]),eval(args[3]),))
-
 elif cmd == 'alter_partition_with_environment_context':
   if len(args) != 4:
     print 'alter_partition_with_environment_context requires 4 args'
diff --git a/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py b/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py
index 3186cee..235d3f8 100644
--- a/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py
+++ b/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py
@@ -559,16 +559,6 @@ def alter_partitions(self, db_name, tbl_name, new_parts):
     """
     pass
 
-  def alter_partitions_with_environment_context(self, db_name, tbl_name, new_parts, environment_context):
-    """
-    Parameters:
-     - db_name
-     - tbl_name
-     - new_parts
-     - environment_context
-    """
-    pass
-
   def alter_partition_with_environment_context(self, db_name, tbl_name, new_part, environment_context):
     """
     Parameters:
@@ -3439,44 +3429,6 @@ def recv_alter_partitions(self, ):
       raise result.o2
     return
 
-  def alter_partitions_with_environment_context(self, db_name, tbl_name, new_parts, environment_context):
-    """
-    Parameters:
-     - db_name
-     - tbl_name
-     - new_parts
-     - environment_context
-    """
-    self.send_alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context)
-    self.recv_alter_partitions_with_environment_context()
-
-  def send_alter_partitions_with_environment_context(self, db_name, tbl_name, new_parts, environment_context):
-    self._oprot.writeMessageBegin('alter_partitions_with_environment_context', TMessageType.CALL, self._seqid)
-    args = alter_partitions_with_environment_context_args()
-    args.db_name = db_name
-    args.tbl_name = tbl_name
-    args.new_parts = new_parts
-    args.environment_context = environment_context
-    args.write(self._oprot)
-    self._oprot.writeMessageEnd()
-    self._oprot.trans.flush()
-
-  def recv_alter_partitions_with_environment_context(self, ):
-    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
-    if mtype == TMessageType.EXCEPTION:
-      x = TApplicationException()
-      x.read(self._iprot)
-      self._iprot.readMessageEnd()
-      raise x
-    result = alter_partitions_with_environment_context_result()
-    result.read(self._iprot)
-    self._iprot.readMessageEnd()
-    if result.o1 is not None:
-      raise result.o1
-    if result.o2 is not None:
-      raise result.o2
-    return
-
   def alter_partition_with_environment_context(self, db_name, tbl_name, new_part, environment_context):
     """
     Parameters:
@@ -6007,7 +5959,6 @@ def __init__(self, handler):
     self._processMap["get_partitions_by_names"] = Processor.process_get_partitions_by_names
     self._processMap["alter_partition"] = Processor.process_alter_partition
     self._processMap["alter_partitions"] = Processor.process_alter_partitions
-    self._processMap["alter_partitions_with_environment_context"] = Processor.process_alter_partitions_with_environment_context
     self._processMap["alter_partition_with_environment_context"] = Processor.process_alter_partition_with_environment_context
     self._processMap["rename_partition"] = Processor.process_rename_partition
     self._processMap["partition_name_has_valid_characters"] = Processor.process_partition_name_has_valid_characters
@@ -7123,22 +7074,6 @@ def process_alter_partitions(self, seqid, iprot, oprot):
     oprot.writeMessageEnd()
     oprot.trans.flush()
 
-  def process_alter_partitions_with_environment_context(self, seqid, iprot, oprot):
-    args = alter_partitions_with_environment_context_args()
-    args.read(iprot)
-    iprot.readMessageEnd()
-    result = alter_partitions_with_environment_context_result()
-    try:
-      self._handler.alter_partitions_with_environment_context(args.db_name, args.tbl_name, args.new_parts, args.environment_context)
-    except InvalidOperationException as o1:
-      result.o1 = o1
-    except MetaException as o2:
-      result.o2 = o2
-    oprot.writeMessageBegin("alter_partitions_with_environment_context", TMessageType.REPLY, seqid)
-    result.write(oprot)
-    oprot.writeMessageEnd()
-    oprot.trans.flush()
-
   def process_alter_partition_with_environment_context(self, seqid, iprot, oprot):
     args = alter_partition_with_environment_context_args()
     args.read(iprot)
@@ -18971,186 +18906,6 @@ def __eq__(self, other):
   def __ne__(self, other):
     return not (self == other)
 
-class alter_partitions_with_environment_context_args:
-  """
-  Attributes:
-   - db_name
-   - tbl_name
-   - new_parts
-   - environment_context
-  """
-
-  thrift_spec = (
-    None, # 0
-    (1, TType.STRING, 'db_name', None, None, ), # 1
-    (2, TType.STRING, 'tbl_name', None, None, ), # 2
-    (3, TType.LIST, 'new_parts', (TType.STRUCT,(Partition, Partition.thrift_spec)), None, ), # 3
-    (4, TType.STRUCT, 'environment_context', (EnvironmentContext, EnvironmentContext.thrift_spec), None, ), # 4
-  )
-
-  def __init__(self, db_name=None, tbl_name=None, new_parts=None, environment_context=None,):
-    self.db_name = db_name
-    self.tbl_name = tbl_name
-    self.new_parts = new_parts
-    self.environment_context = environment_context
-
-  def read(self, iprot):
-    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
-      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
-      return
-    iprot.readStructBegin()
-    while True:
-      (fname, ftype, fid) = iprot.readFieldBegin()
-      if ftype == TType.STOP:
-        break
-      if fid == 1:
-        if ftype == TType.STRING:
-          self.db_name = iprot.readString();
-        else:
-          iprot.skip(ftype)
-      elif fid == 2:
-        if ftype == TType.STRING:
-          self.tbl_name = iprot.readString();
-        else:
-          iprot.skip(ftype)
-      elif fid == 3:
-        if ftype == TType.LIST:
-          self.new_parts = []
-          (_etype772, _size769) = iprot.readListBegin()
-          for _i773 in xrange(_size769):
-            _elem774 = Partition()
-            _elem774.read(iprot)
-            self.new_parts.append(_elem774)
-          iprot.readListEnd()
-        else:
-          iprot.skip(ftype)
-      elif fid == 4:
-        if ftype == TType.STRUCT:
-          self.environment_context = EnvironmentContext()
-          self.environment_context.read(iprot)
-        else:
-          iprot.skip(ftype)
-      else:
-        iprot.skip(ftype)
-      iprot.readFieldEnd()
-    iprot.readStructEnd()
-
-  def write(self, oprot):
-    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
-      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
-      return
-    oprot.writeStructBegin('alter_partitions_with_environment_context_args')
-    if self.db_name is not None:
-      oprot.writeFieldBegin('db_name', TType.STRING, 1)
-      oprot.writeString(self.db_name)
-      oprot.writeFieldEnd()
-    if self.tbl_name is not None:
-      oprot.writeFieldBegin('tbl_name', TType.STRING, 2)
-      oprot.writeString(self.tbl_name)
-      oprot.writeFieldEnd()
-    if self.new_parts is not None:
-      oprot.writeFieldBegin('new_parts', TType.LIST, 3)
-      oprot.writeListBegin(TType.STRUCT, len(self.new_parts))
-      for iter775 in self.new_parts:
-        iter775.write(oprot)
-      oprot.writeListEnd()
-      oprot.writeFieldEnd()
-    if self.environment_context is not None:
-      oprot.writeFieldBegin('environment_context', TType.STRUCT, 4)
-      self.environment_context.write(oprot)
-      oprot.writeFieldEnd()
-    oprot.writeFieldStop()
-    oprot.writeStructEnd()
-
-  def validate(self):
-    return
-
-
-  def __repr__(self):
-    L = ['%s=%r' % (key, value)
-      for key, value in self.__dict__.iteritems()]
-    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
-
-  def __eq__(self, other):
-    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
-
-  def __ne__(self, other):
-    return not (self == other)
-
-class alter_partitions_with_environment_context_result:
-  """
-  Attributes:
-   - o1
-   - o2
-  """
-
-  thrift_spec = (
-    None, # 0
-    (1, TType.STRUCT, 'o1', (InvalidOperationException, InvalidOperationException.thrift_spec), None, ), # 1
-    (2, TType.STRUCT, 'o2', (MetaException, MetaException.thrift_spec), None, ), # 2
-  )
-
-  def __init__(self, o1=None, o2=None,):
-    self.o1 = o1
-    self.o2 = o2
-
-  def read(self, iprot):
-    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
-      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
-      return
-    iprot.readStructBegin()
-    while True:
-      (fname, ftype, fid) = iprot.readFieldBegin()
-      if ftype == TType.STOP:
-        break
-      if fid == 1:
-        if ftype == TType.STRUCT:
-          self.o1 = InvalidOperationException()
-          self.o1.read(iprot)
-        else:
-          iprot.skip(ftype)
-      elif fid == 2:
-        if ftype == TType.STRUCT:
-          self.o2 = MetaException()
-          self.o2.read(iprot)
-        else:
-          iprot.skip(ftype)
-      else:
-        iprot.skip(ftype)
-      iprot.readFieldEnd()
-    iprot.readStructEnd()
-
-  def write(self, oprot):
-    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
-      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
-      return
-    oprot.writeStructBegin('alter_partitions_with_environment_context_result')
-    if self.o1 is not None:
-      oprot.writeFieldBegin('o1', TType.STRUCT, 1)
-      self.o1.write(oprot)
-      oprot.writeFieldEnd()
-    if self.o2 is not None:
-      oprot.writeFieldBegin('o2', TType.STRUCT, 2)
-      self.o2.write(oprot)
-      oprot.writeFieldEnd()
-    oprot.writeFieldStop()
-    oprot.writeStructEnd()
-
-  def validate(self):
-    return
-
-
-  def __repr__(self):
-    L = ['%s=%r' % (key, value)
-      for key, value in self.__dict__.iteritems()]
-    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
-
-  def __eq__(self, other):
-    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
-
-  def __ne__(self, other):
-    return not (self == other)
-
 class alter_partition_with_environment_context_args:
   """
   Attributes:
@@ -19368,10 +19123,10 @@ def read(self, iprot):
       elif fid == 3:
         if ftype == TType.LIST:
           self.part_vals = []
-          (_etype779, _size776) = iprot.readListBegin()
-          for _i780 in xrange(_size776):
-            _elem781 = iprot.readString();
-            self.part_vals.append(_elem781)
+          (_etype772, _size769) = iprot.readListBegin()
+          for _i773 in xrange(_size769):
+            _elem774 = iprot.readString();
+            self.part_vals.append(_elem774)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -19402,8 +19157,8 @@ def write(self, oprot):
     if self.part_vals is not None:
       oprot.writeFieldBegin('part_vals', TType.LIST, 3)
       oprot.writeListBegin(TType.STRING, len(self.part_vals))
-      for iter782 in self.part_vals:
-        oprot.writeString(iter782)
+      for iter775 in self.part_vals:
+        oprot.writeString(iter775)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.new_part is not None:
@@ -19531,10 +19286,10 @@ def read(self, iprot):
       if fid == 1:
         if ftype == TType.LIST:
           self.part_vals = []
-          (_etype786, _size783) = iprot.readListBegin()
-          for _i787 in xrange(_size783):
-            _elem788 = iprot.readString();
-            self.part_vals.append(_elem788)
+          (_etype779, _size776) = iprot.readListBegin()
+          for _i780 in xrange(_size776):
+            _elem781 = iprot.readString();
+            self.part_vals.append(_elem781)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -19556,8 +19311,8 @@ def write(self, oprot):
     if self.part_vals is not None:
       oprot.writeFieldBegin('part_vals', TType.LIST, 1)
       oprot.writeListBegin(TType.STRING, len(self.part_vals))
-      for iter789 in self.part_vals:
-        oprot.writeString(iter789)
+      for iter782 in self.part_vals:
+        oprot.writeString(iter782)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.throw_exception is not None:
@@ -19886,10 +19641,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype793, _size790) = iprot.readListBegin()
-          for _i794 in xrange(_size790):
-            _elem795 = iprot.readString();
-            self.success.append(_elem795)
+          (_etype786, _size783) = iprot.readListBegin()
+          for _i787 in xrange(_size783):
+            _elem788 = iprot.readString();
+            self.success.append(_elem788)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -19912,8 +19667,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter796 in self.success:
-        oprot.writeString(iter796)
+      for iter789 in self.success:
+        oprot.writeString(iter789)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -20026,11 +19781,11 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.MAP:
           self.success = {}
-          (_ktype798, _vtype799, _size797 ) = iprot.readMapBegin() 
-          for _i801 in xrange(_size797):
-            _key802 = iprot.readString();
-            _val803 = iprot.readString();
-            self.success[_key802] = _val803
+          (_ktype791, _vtype792, _size790 ) = iprot.readMapBegin() 
+          for _i794 in xrange(_size790):
+            _key795 = iprot.readString();
+            _val796 = iprot.readString();
+            self.success[_key795] = _val796
           iprot.readMapEnd()
         else:
           iprot.skip(ftype)
@@ -20053,9 +19808,9 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.MAP, 0)
       oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.success))
-      for kiter804,viter805 in self.success.items():
-        oprot.writeString(kiter804)
-        oprot.writeString(viter805)
+      for kiter797,viter798 in self.success.items():
+        oprot.writeString(kiter797)
+        oprot.writeString(viter798)
       oprot.writeMapEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -20125,11 +19880,11 @@ def read(self, iprot):
       elif fid == 3:
         if ftype == TType.MAP:
           self.part_vals = {}
-          (_ktype807, _vtype808, _size806 ) = iprot.readMapBegin() 
-          for _i810 in xrange(_size806):
-            _key811 = iprot.readString();
-            _val812 = iprot.readString();
-            self.part_vals[_key811] = _val812
+          (_ktype800, _vtype801, _size799 ) = iprot.readMapBegin() 
+          for _i803 in xrange(_size799):
+            _key804 = iprot.readString();
+            _val805 = iprot.readString();
+            self.part_vals[_key804] = _val805
           iprot.readMapEnd()
         else:
           iprot.skip(ftype)
@@ -20159,9 +19914,9 @@ def write(self, oprot):
     if self.part_vals is not None:
       oprot.writeFieldBegin('part_vals', TType.MAP, 3)
       oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.part_vals))
-      for kiter813,viter814 in self.part_vals.items():
-        oprot.writeString(kiter813)
-        oprot.writeString(viter814)
+      for kiter806,viter807 in self.part_vals.items():
+        oprot.writeString(kiter806)
+        oprot.writeString(viter807)
       oprot.writeMapEnd()
       oprot.writeFieldEnd()
     if self.eventType is not None:
@@ -20357,11 +20112,11 @@ def read(self, iprot):
       elif fid == 3:
         if ftype == TType.MAP:
           self.part_vals = {}
-          (_ktype816, _vtype817, _size815 ) = iprot.readMapBegin() 
-          for _i819 in xrange(_size815):
-            _key820 = iprot.readString();
-            _val821 = iprot.readString();
-            self.part_vals[_key820] = _val821
+          (_ktype809, _vtype810, _size808 ) = iprot.readMapBegin() 
+          for _i812 in xrange(_size808):
+            _key813 = iprot.readString();
+            _val814 = iprot.readString();
+            self.part_vals[_key813] = _val814
           iprot.readMapEnd()
         else:
           iprot.skip(ftype)
@@ -20391,9 +20146,9 @@ def write(self, oprot):
     if self.part_vals is not None:
       oprot.writeFieldBegin('part_vals', TType.MAP, 3)
       oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.part_vals))
-      for kiter822,viter823 in self.part_vals.items():
-        oprot.writeString(kiter822)
-        oprot.writeString(viter823)
+      for kiter815,viter816 in self.part_vals.items():
+        oprot.writeString(kiter815)
+        oprot.writeString(viter816)
       oprot.writeMapEnd()
       oprot.writeFieldEnd()
     if self.eventType is not None:
@@ -21365,11 +21120,11 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype827, _size824) = iprot.readListBegin()
-          for _i828 in xrange(_size824):
-            _elem829 = Index()
-            _elem829.read(iprot)
-            self.success.append(_elem829)
+          (_etype820, _size817) = iprot.readListBegin()
+          for _i821 in xrange(_size817):
+            _elem822 = Index()
+            _elem822.read(iprot)
+            self.success.append(_elem822)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -21398,8 +21153,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRUCT, len(self.success))
-      for iter830 in self.success:
-        iter830.write(oprot)
+      for iter823 in self.success:
+        iter823.write(oprot)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -21540,10 +21295,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype834, _size831) = iprot.readListBegin()
-          for _i835 in xrange(_size831):
-            _elem836 = iprot.readString();
-            self.success.append(_elem836)
+          (_etype827, _size824) = iprot.readListBegin()
+          for _i828 in xrange(_size824):
+            _elem829 = iprot.readString();
+            self.success.append(_elem829)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -21566,8 +21321,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter837 in self.success:
-        oprot.writeString(iter837)
+      for iter830 in self.success:
+        oprot.writeString(iter830)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o2 is not None:
@@ -23921,10 +23676,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype841, _size838) = iprot.readListBegin()
-          for _i842 in xrange(_size838):
-            _elem843 = iprot.readString();
-            self.success.append(_elem843)
+          (_etype834, _size831) = iprot.readListBegin()
+          for _i835 in xrange(_size831):
+            _elem836 = iprot.readString();
+            self.success.append(_elem836)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -23947,8 +23702,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter844 in self.success:
-        oprot.writeString(iter844)
+      for iter837 in self.success:
+        oprot.writeString(iter837)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -24581,10 +24336,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype848, _size845) = iprot.readListBegin()
-          for _i849 in xrange(_size845):
-            _elem850 = iprot.readString();
-            self.success.append(_elem850)
+          (_etype841, _size838) = iprot.readListBegin()
+          for _i842 in xrange(_size838):
+            _elem843 = iprot.readString();
+            self.success.append(_elem843)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -24607,8 +24362,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter851 in self.success:
-        oprot.writeString(iter851)
+      for iter844 in self.success:
+        oprot.writeString(iter844)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -25081,11 +24836,11 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype855, _size852) = iprot.readListBegin()
-          for _i856 in xrange(_size852):
-            _elem857 = Role()
-            _elem857.read(iprot)
-            self.success.append(_elem857)
+          (_etype848, _size845) = iprot.readListBegin()
+          for _i849 in xrange(_size845):
+            _elem850 = Role()
+            _elem850.read(iprot)
+            self.success.append(_elem850)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -25108,8 +24863,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRUCT, len(self.success))
-      for iter858 in self.success:
-        iter858.write(oprot)
+      for iter851 in self.success:
+        iter851.write(oprot)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -25579,10 +25334,10 @@ def read(self, iprot):
       elif fid == 3:
         if ftype == TType.LIST:
           self.group_names = []
-          (_etype862, _size859) = iprot.readListBegin()
-          for _i863 in xrange(_size859):
-            _elem864 = iprot.readString();
-            self.group_names.append(_elem864)
+          (_etype855, _size852) = iprot.readListBegin()
+          for _i856 in xrange(_size852):
+            _elem857 = iprot.readString();
+            self.group_names.append(_elem857)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -25607,8 +25362,8 @@ def write(self, oprot):
     if self.group_names is not None:
       oprot.writeFieldBegin('group_names', TType.LIST, 3)
       oprot.writeListBegin(TType.STRING, len(self.group_names))
-      for iter865 in self.group_names:
-        oprot.writeString(iter865)
+      for iter858 in self.group_names:
+        oprot.writeString(iter858)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     oprot.writeFieldStop()
@@ -25815,11 +25570,11 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype869, _size866) = iprot.readListBegin()
-          for _i870 in xrange(_size866):
-            _elem871 = HiveObjectPrivilege()
-            _elem871.read(iprot)
-            self.success.append(_elem871)
+          (_etype862, _size859) = iprot.readListBegin()
+          for _i863 in xrange(_size859):
+            _elem864 = HiveObjectPrivilege()
+            _elem864.read(iprot)
+            self.success.append(_elem864)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -25842,8 +25597,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRUCT, len(self.success))
-      for iter872 in self.success:
-        iter872.write(oprot)
+      for iter865 in self.success:
+        iter865.write(oprot)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -26302,10 +26057,10 @@ def read(self, iprot):
       elif fid == 2:
         if ftype == TType.LIST:
           self.group_names = []
-          (_etype876, _size873) = iprot.readListBegin()
-          for _i877 in xrange(_size873):
-            _elem878 = iprot.readString();
-            self.group_names.append(_elem878)
+          (_etype869, _size866) = iprot.readListBegin()
+          for _i870 in xrange(_size866):
+            _elem871 = iprot.readString();
+            self.group_names.append(_elem871)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -26326,8 +26081,8 @@ def write(self, oprot):
     if self.group_names is not None:
       oprot.writeFieldBegin('group_names', TType.LIST, 2)
       oprot.writeListBegin(TType.STRING, len(self.group_names))
-      for iter879 in self.group_names:
-        oprot.writeString(iter879)
+      for iter872 in self.group_names:
+        oprot.writeString(iter872)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     oprot.writeFieldStop()
@@ -26376,10 +26131,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype883, _size880) = iprot.readListBegin()
-          for _i884 in xrange(_size880):
-            _elem885 = iprot.readString();
-            self.success.append(_elem885)
+          (_etype876, _size873) = iprot.readListBegin()
+          for _i877 in xrange(_size873):
+            _elem878 = iprot.readString();
+            self.success.append(_elem878)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -26402,8 +26157,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter886 in self.success:
-        oprot.writeString(iter886)
+      for iter879 in self.success:
+        oprot.writeString(iter879)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.o1 is not None:
@@ -27261,10 +27016,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype890, _size887) = iprot.readListBegin()
-          for _i891 in xrange(_size887):
-            _elem892 = iprot.readString();
-            self.success.append(_elem892)
+          (_etype883, _size880) = iprot.readListBegin()
+          for _i884 in xrange(_size880):
+            _elem885 = iprot.readString();
+            self.success.append(_elem885)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -27281,8 +27036,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter893 in self.success:
-        oprot.writeString(iter893)
+      for iter886 in self.success:
+        oprot.writeString(iter886)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     oprot.writeFieldStop()
@@ -27767,10 +27522,10 @@ def read(self, iprot):
       if fid == 0:
         if ftype == TType.LIST:
           self.success = []
-          (_etype897, _size894) = iprot.readListBegin()
-          for _i898 in xrange(_size894):
-            _elem899 = iprot.readString();
-            self.success.append(_elem899)
+          (_etype890, _size887) = iprot.readListBegin()
+          for _i891 in xrange(_size887):
+            _elem892 = iprot.readString();
+            self.success.append(_elem892)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
@@ -27787,8 +27542,8 @@ def write(self, oprot):
     if self.success is not None:
       oprot.writeFieldBegin('success', TType.LIST, 0)
       oprot.writeListBegin(TType.STRING, len(self.success))
-      for iter900 in self.success:
-        oprot.writeString(iter900)
+      for iter893 in self.success:
+        oprot.writeString(iter893)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     oprot.writeFieldStop()
diff --git a/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb b/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb
index 794bdc9..596cb36 100644
--- a/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb
+++ b/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb
@@ -1070,22 +1070,6 @@ module ThriftHiveMetastore
       return
     end
 
-    def alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context)
-      send_alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context)
-      recv_alter_partitions_with_environment_context()
-    end
-
-    def send_alter_partitions_with_environment_context(db_name, tbl_name, new_parts, environment_context)
-      send_message('alter_partitions_with_environment_context', Alter_partitions_with_environment_context_args, :db_name => db_name, :tbl_name => tbl_name, :new_parts => new_parts, :environment_context => environment_context)
-    end
-
-    def recv_alter_partitions_with_environment_context()
-      result = receive_message(Alter_partitions_with_environment_context_result)
-      raise result.o1 unless result.o1.nil?
-      raise result.o2 unless result.o2.nil?
-      return
-    end
-
     def alter_partition_with_environment_context(db_name, tbl_name, new_part, environment_context)
       send_alter_partition_with_environment_context(db_name, tbl_name, new_part, environment_context)
       recv_alter_partition_with_environment_context()
@@ -3125,19 +3109,6 @@ module ThriftHiveMetastore
       write_result(result, oprot, 'alter_partitions', seqid)
     end
 
-    def process_alter_partitions_with_environment_context(seqid, iprot, oprot)
-      args = read_args(iprot, Alter_partitions_with_environment_context_args)
-      result = Alter_partitions_with_environment_context_result.new()
-      begin
-        @handler.alter_partitions_with_environment_context(args.db_name, args.tbl_name, args.new_parts, args.environment_context)
-      rescue ::InvalidOperationException => o1
-        result.o1 = o1
-      rescue ::MetaException => o2
-        result.o2 = o2
-      end
-      write_result(result, oprot, 'alter_partitions_with_environment_context', seqid)
-    end
-
     def process_alter_partition_with_environment_context(seqid, iprot, oprot)
       args = read_args(iprot, Alter_partition_with_environment_context_args)
       result = Alter_partition_with_environment_context_result.new()
@@ -6446,46 +6417,6 @@ module ThriftHiveMetastore
     ::Thrift::Struct.generate_accessors self
   end
 
-  class Alter_partitions_with_environment_context_args
-    include ::Thrift::Struct, ::Thrift::Struct_Union
-    DB_NAME = 1
-    TBL_NAME = 2
-    NEW_PARTS = 3
-    ENVIRONMENT_CONTEXT = 4
-
-    FIELDS = {
-      DB_NAME => {:type => ::Thrift::Types::STRING, :name => 'db_name'},
-      TBL_NAME => {:type => ::Thrift::Types::STRING, :name => 'tbl_name'},
-      NEW_PARTS => {:type => ::Thrift::Types::LIST, :name => 'new_parts', :element => {:type => ::Thrift::Types::STRUCT, :class => ::Partition}},
-      ENVIRONMENT_CONTEXT => {:type => ::Thrift::Types::STRUCT, :name => 'environment_context', :class => ::EnvironmentContext}
-    }
-
-    def struct_fields; FIELDS; end
-
-    def validate
-    end
-
-    ::Thrift::Struct.generate_accessors self
-  end
-
-  class Alter_partitions_with_environment_context_result
-    include ::Thrift::Struct, ::Thrift::Struct_Union
-    O1 = 1
-    O2 = 2
-
-    FIELDS = {
-      O1 => {:type => ::Thrift::Types::STRUCT, :name => 'o1', :class => ::InvalidOperationException},
-      O2 => {:type => ::Thrift::Types::STRUCT, :name => 'o2', :class => ::MetaException}
-    }
-
-    def struct_fields; FIELDS; end
-
-    def validate
-    end
-
-    ::Thrift::Struct.generate_accessors self
-  end
-
   class Alter_partition_with_environment_context_args
     include ::Thrift::Struct, ::Thrift::Struct_Union
     DB_NAME = 1
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/AlterHandler.java b/metastore/src/java/org/apache/hadoop/hive/metastore/AlterHandler.java
index ac4ea1b..6249e97 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/AlterHandler.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/AlterHandler.java
@@ -56,9 +56,10 @@
    * @throws MetaException
    *           thrown if there is any other error
    */
+  @Deprecated
   void alterTable(RawStore msdb, Warehouse wh, String dbname,
-    String name, Table newTable, EnvironmentContext envContext)
-      throws InvalidOperationException, MetaException;
+      String name, Table newTable) throws InvalidOperationException,
+      MetaException;
 
   /**
    * handles alter table, the changes could be cascaded to partitions if applicable
@@ -82,7 +83,7 @@ void alterTable(RawStore msdb, Warehouse wh, String dbname,
    *           thrown if there is any other error
    */
   void alterTable(RawStore msdb, Warehouse wh, String dbname,
-      String name, Table newTable, EnvironmentContext envContext,
+      String name, Table newTable, boolean cascade,
       HMSHandler handler) throws InvalidOperationException, MetaException;
 
   /**
@@ -110,8 +111,7 @@ void alterTable(RawStore msdb, Warehouse wh, String dbname,
    */
   @Deprecated
   Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
-    final String name, final List<String> part_vals, final Partition new_part,
-    EnvironmentContext envContext)
+    final String name, final List<String> part_vals, final Partition new_part)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException;
 
   /**
@@ -137,8 +137,7 @@ Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
    * @throws MetaException
    */
   Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
-    final String name, final List<String> part_vals, final Partition new_part, EnvironmentContext environmentContext,
-    HMSHandler handler)
+    final String name, final List<String> part_vals, final Partition new_part, HMSHandler handler)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException;
 
   /**
@@ -164,8 +163,7 @@ Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
    */
   @Deprecated
   List<Partition> alterPartitions(final RawStore msdb, Warehouse wh,
-    final String dbname, final String name, final List<Partition> new_parts,
-    EnvironmentContext environmentContext)
+    final String dbname, final String name, final List<Partition> new_parts)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException;
 
   /**
@@ -191,6 +189,6 @@ Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
 
   List<Partition> alterPartitions(final RawStore msdb, Warehouse wh,
     final String dbname, final String name, final List<Partition> new_parts,
-    EnvironmentContext environmentContext,HMSHandler handler)
+    HMSHandler handler)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException;
-}
+}
\ No newline at end of file
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
index 7543d73..afa8d41 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
@@ -24,7 +24,6 @@
 import java.util.List;
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.Lists;
-
 import org.apache.commons.lang.StringUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -36,14 +35,12 @@
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.common.FileUtils;
 import org.apache.hadoop.hive.common.ObjectPair;
-import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.hadoop.hive.metastore.api.ColumnStatistics;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsDesc;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.InvalidInputException;
 import org.apache.hadoop.hive.metastore.api.InvalidObjectException;
@@ -76,19 +73,12 @@ public void setConf(Configuration conf) {
   }
 
   public void alterTable(RawStore msdb, Warehouse wh, String dbname,
-    String name, Table newt, EnvironmentContext environmentContext)
-      throws InvalidOperationException, MetaException {
-    alterTable(msdb, wh, dbname, name, newt, environmentContext, null);
+      String name, Table newt) throws InvalidOperationException, MetaException {
+    alterTable(msdb, wh, dbname, name, newt, false, null);
   }
 
   public void alterTable(RawStore msdb, Warehouse wh, String dbname,
-    String name, Table newt, EnvironmentContext environmentContext,
-    HMSHandler handler) throws InvalidOperationException, MetaException {
-
-    final boolean cascade = environmentContext != null
-        && environmentContext.isSetProperties()
-        && StatsSetupConst.TRUE.equals(environmentContext.getProperties().get(
-            StatsSetupConst.CASCADE));
+      String name, Table newt, boolean cascade, HMSHandler handler) throws InvalidOperationException, MetaException {
     if (newt == null) {
       throw new InvalidOperationException("New table is invalid: " + newt);
     }
@@ -247,12 +237,12 @@ public void alterTable(RawStore msdb, Warehouse wh, String dbname,
             msdb.alterPartition(dbname, name, part.getValues(), part);
           }
         }
-      } else if (MetaStoreUtils.requireCalStats(hiveConf, null, null, newt, environmentContext) &&
+      } else if (MetaStoreUtils.requireCalStats(hiveConf, null, null, newt) &&
         (newt.getPartitionKeysSize() == 0)) {
           Database db = msdb.getDatabase(newt.getDbName());
           // Update table stats. For partitioned table, we update stats in
           // alterPartition()
-          MetaStoreUtils.updateUnpartitionedTableStatsFast(db, newt, wh, false, true, environmentContext);
+          MetaStoreUtils.updateUnpartitionedTableStatsFast(db, newt, wh, false, true);
       }
 
       alterTableUpdateTableColumnStats(msdb, oldt, newt);
@@ -342,16 +332,16 @@ String getSimpleMessage(IOException ex) {
 
   @Override
   public Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
-    final String name, final List<String> part_vals, final Partition new_part,
-    EnvironmentContext environmentContext)
-      throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException {
-    return alterPartition(msdb, wh, dbname, name, part_vals, new_part, environmentContext, null);
+      final String name, final List<String> part_vals, final Partition new_part)
+      throws InvalidOperationException, InvalidObjectException, AlreadyExistsException,
+      MetaException {
+    return alterPartition(msdb, wh, dbname, name, part_vals, new_part, null);
   }
 
   @Override
   public Partition alterPartition(final RawStore msdb, Warehouse wh, final String dbname,
     final String name, final List<String> part_vals, final Partition new_part,
-    EnvironmentContext environmentContext, HMSHandler handler)
+    HMSHandler handler)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException {
     boolean success = false;
     Path srcPath = null;
@@ -385,8 +375,8 @@ public Partition alterPartition(final RawStore msdb, Warehouse wh, final String
       try {
         msdb.openTransaction();
         oldPart = msdb.getPartition(dbname, name, new_part.getValues());
-        if (MetaStoreUtils.requireCalStats(hiveConf, oldPart, new_part, tbl, environmentContext)) {
-          MetaStoreUtils.updatePartitionStatsFast(new_part, wh, false, true, environmentContext);
+        if (MetaStoreUtils.requireCalStats(hiveConf, oldPart, new_part, tbl)) {
+          MetaStoreUtils.updatePartitionStatsFast(new_part, wh, false, true);
         }
 
         updatePartColumnStats(msdb, dbname, name, new_part.getValues(), new_part);
@@ -492,8 +482,8 @@ public Partition alterPartition(final RawStore msdb, Warehouse wh, final String
           }
 
           new_part.getSd().setLocation(newPartLoc);
-          if (MetaStoreUtils.requireCalStats(hiveConf, oldPart, new_part, tbl, environmentContext)) {
-            MetaStoreUtils.updatePartitionStatsFast(new_part, wh, false, true, environmentContext);
+          if (MetaStoreUtils.requireCalStats(hiveConf, oldPart, new_part, tbl)) {
+            MetaStoreUtils.updatePartitionStatsFast(new_part, wh, false, true);
           }
 
           String oldPartName = Warehouse.makePartName(tbl.getPartitionKeys(), oldPart.getValues());
@@ -567,16 +557,15 @@ public Partition alterPartition(final RawStore msdb, Warehouse wh, final String
   }
 
   public List<Partition> alterPartitions(final RawStore msdb, Warehouse wh, final String dbname,
-    final String name, final List<Partition> new_parts,
-    EnvironmentContext environmentContext)
-      throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException {
-    return alterPartitions(msdb, wh, dbname, name, new_parts, environmentContext, null);
+      final String name, final List<Partition> new_parts)
+      throws InvalidOperationException, InvalidObjectException, AlreadyExistsException,
+      MetaException {
+    return alterPartitions(msdb, wh, dbname, name, new_parts, null);
   }
 
   @Override
   public List<Partition> alterPartitions(final RawStore msdb, Warehouse wh, final String dbname,
-    final String name, final List<Partition> new_parts, EnvironmentContext environmentContext,
-    HMSHandler handler)
+    final String name, final List<Partition> new_parts, HMSHandler handler)
       throws InvalidOperationException, InvalidObjectException, AlreadyExistsException, MetaException {
     List<Partition> oldParts = new ArrayList<Partition>();
     List<List<String>> partValsList = new ArrayList<List<String>>();
@@ -607,8 +596,8 @@ public Partition alterPartition(final RawStore msdb, Warehouse wh, final String
         oldParts.add(oldTmpPart);
         partValsList.add(tmpPart.getValues());
 
-        if (MetaStoreUtils.requireCalStats(hiveConf, oldTmpPart, tmpPart, tbl, environmentContext)) {
-          MetaStoreUtils.updatePartitionStatsFast(tmpPart, wh, false, true, environmentContext);
+        if (MetaStoreUtils.requireCalStats(hiveConf, oldTmpPart, tmpPart, tbl)) {
+          MetaStoreUtils.updatePartitionStatsFast(tmpPart, wh, false, true);
         }
         updatePartColumnStats(msdb, dbname, name, oldTmpPart.getValues(), tmpPart);
       }
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 0034180..c088ace 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -41,7 +41,6 @@
 import org.apache.hadoop.hive.common.JvmPauseMonitor;
 import org.apache.hadoop.hive.common.LogUtils;
 import org.apache.hadoop.hive.common.auth.HiveAuthUtils;
-import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.common.LogUtils.LogInitializationException;
 import org.apache.hadoop.hive.common.classification.InterfaceAudience;
 import org.apache.hadoop.hive.common.classification.InterfaceStability;
@@ -1499,9 +1498,9 @@ private void create_table_core(final RawStore ms, final Table tbl,
         if (HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVESTATSAUTOGATHER) &&
             !MetaStoreUtils.isView(tbl)) {
           if (tbl.getPartitionKeysSize() == 0)  { // Unpartitioned table
-            MetaStoreUtils.updateUnpartitionedTableStatsFast(db, tbl, wh, madeDir, envContext);
+            MetaStoreUtils.updateUnpartitionedTableStatsFast(db, tbl, wh, madeDir);
           } else { // Partitioned table with no partitions.
-            MetaStoreUtils.updateUnpartitionedTableStatsFast(db, tbl, wh, true, envContext);
+            MetaStoreUtils.updateUnpartitionedTableStatsFast(db, tbl, wh, true);
           }
         }
 
@@ -2094,7 +2093,7 @@ private Partition append_partition_common(RawStore ms, String dbName, String tab
 
         if (HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVESTATSAUTOGATHER) &&
             !MetaStoreUtils.isView(tbl)) {
-          MetaStoreUtils.updatePartitionStatsFast(part, wh, madeDir, envContext);
+          MetaStoreUtils.updatePartitionStatsFast(part, wh, madeDir);
         }
 
         if (ms.addPartition(part)) {
@@ -2648,7 +2647,7 @@ private void initializeAddedPartition(
         final Table tbl, final PartitionSpecProxy.PartitionIterator part, boolean madeDir) throws MetaException {
       if (HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVESTATSAUTOGATHER) &&
           !MetaStoreUtils.isView(tbl)) {
-        MetaStoreUtils.updatePartitionStatsFast(part, wh, madeDir, false, null);
+        MetaStoreUtils.updatePartitionStatsFast(part, wh, madeDir, false);
       }
 
       // set create time
@@ -3612,7 +3611,7 @@ private void rename_partition(final String db_name, final String tbl_name,
               partitionValidationPattern);
         }
 
-        oldPart = alterHandler.alterPartition(getMS(), wh, db_name, tbl_name, part_vals, new_part, envContext, this);
+        oldPart = alterHandler.alterPartition(getMS(), wh, db_name, tbl_name, part_vals, new_part, this);
         // Only fetch the table if we actually have a listener
         Table table = null;
         if (!listeners.isEmpty()) {
@@ -3649,14 +3648,7 @@ private void rename_partition(final String db_name, final String tbl_name,
 
     @Override
     public void alter_partitions(final String db_name, final String tbl_name,
-        final List<Partition> new_parts) throws InvalidOperationException, MetaException,
-        TException {
-      alter_partitions_with_environment_context(db_name, tbl_name, new_parts, null);
-    }
-
-    @Override
-    public void alter_partitions_with_environment_context(final String db_name, final String tbl_name,
-        final List<Partition> new_parts, EnvironmentContext environmentContext)
+        final List<Partition> new_parts)
         throws InvalidOperationException, MetaException,
         TException {
       startTableFunction("alter_partitions", db_name, tbl_name);
@@ -3673,7 +3665,7 @@ public void alter_partitions_with_environment_context(final String db_name, fina
         for (Partition tmpPart : new_parts) {
           firePreEvent(new PreAlterPartitionEvent(db_name, tbl_name, null, tmpPart, this));
         }
-        oldParts = alterHandler.alterPartitions(getMS(), wh, db_name, tbl_name, new_parts, environmentContext, this);
+        oldParts = alterHandler.alterPartitions(getMS(), wh, db_name, tbl_name, new_parts, this);
         Iterator<Partition> olditr = oldParts.iterator();
         // Only fetch the table if we have a listener that needs it.
         Table table = null;
@@ -3784,19 +3776,15 @@ public void alter_table(final String dbname, final String name,
         final Table newTable)
         throws InvalidOperationException, MetaException {
       // Do not set an environment context.
-      alter_table_core(dbname,name, newTable, null);
+      alter_table_core(dbname,name, newTable, null, false);
     }
 
     @Override
     public void alter_table_with_cascade(final String dbname, final String name,
         final Table newTable, final boolean cascade)
         throws InvalidOperationException, MetaException {
-      EnvironmentContext envContext = null;
-      if (cascade) {
-        envContext = new EnvironmentContext();
-        envContext.putToProperties(StatsSetupConst.CASCADE, StatsSetupConst.TRUE);
-      }
-      alter_table_core(dbname, name, newTable, envContext);
+      // Do not set an environment context.
+      alter_table_core(dbname,name, newTable, null, cascade);
     }
 
     @Override
@@ -3804,14 +3792,15 @@ public void alter_table_with_environment_context(final String dbname,
         final String name, final Table newTable,
         final EnvironmentContext envContext)
         throws InvalidOperationException, MetaException {
-      alter_table_core(dbname, name, newTable, envContext);
+      alter_table_core(dbname, name, newTable, envContext, false);
     }
 
     private void alter_table_core(final String dbname, final String name, final Table newTable,
-        final EnvironmentContext envContext)
+        final EnvironmentContext envContext, final boolean cascade)
         throws InvalidOperationException, MetaException {
       startFunction("alter_table", ": db=" + dbname + " tbl=" + name
           + " newtbl=" + newTable.getTableName());
+
       // Update the time if it hasn't been specified.
       if (newTable.getParameters() == null ||
           newTable.getParameters().get(hive_metastoreConstants.DDL_TIME) == null) {
@@ -3833,7 +3822,7 @@ private void alter_table_core(final String dbname, final String name, final Tabl
       try {
         Table oldt = get_table_core(dbname, name);
         firePreEvent(new PreAlterTableEvent(oldt, newTable, this));
-        alterHandler.alterTable(getMS(), wh, dbname, name, newTable, envContext, this);
+        alterHandler.alterTable(getMS(), wh, dbname, name, newTable, cascade, this);
         success = true;
         if (!listeners.isEmpty()) {
           MetaStoreListenerNotifier.notifyEvent(listeners,
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
index 193a6fa..c77d603 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
@@ -47,7 +47,6 @@
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.common.ObjectPair;
-import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.common.ValidTxnList;
 import org.apache.hadoop.hive.common.auth.HiveAuthUtils;
 import org.apache.hadoop.hive.common.classification.InterfaceAudience;
@@ -354,10 +353,16 @@ public void reconnect() throws MetaException {
   @Override
   public void alter_table(String dbname, String tbl_name, Table new_tbl)
       throws InvalidOperationException, MetaException, TException {
-    alter_table_with_environmentContext(dbname, tbl_name, new_tbl, null);
+    alter_table(dbname, tbl_name, new_tbl, null);
   }
 
-  public void alter_table_with_environmentContext(String dbname, String tbl_name, Table new_tbl,
+  @Override
+  public void alter_table(String dbname, String tbl_name, Table new_tbl, boolean cascade)
+      throws InvalidOperationException, MetaException, TException {
+    client.alter_table_with_cascade(dbname, tbl_name, new_tbl, cascade);
+  }
+
+  public void alter_table(String dbname, String tbl_name, Table new_tbl,
       EnvironmentContext envContext) throws InvalidOperationException, MetaException, TException {
     client.alter_table_with_environment_context(dbname, tbl_name, new_tbl, envContext);
   }
@@ -1406,15 +1411,15 @@ public int getNumPartitionsByFilter(String db_name, String tbl_name, String filt
   }
 
   @Override
-  public void alter_partition(String dbName, String tblName, Partition newPart, EnvironmentContext environmentContext)
+  public void alter_partition(String dbName, String tblName, Partition newPart)
       throws InvalidOperationException, MetaException, TException {
-    client.alter_partition_with_environment_context(dbName, tblName, newPart, environmentContext);
+    client.alter_partition(dbName, tblName, newPart);
   }
 
   @Override
-  public void alter_partitions(String dbName, String tblName, List<Partition> newParts, EnvironmentContext environmentContext)
+  public void alter_partitions(String dbName, String tblName, List<Partition> newParts)
   throws InvalidOperationException, MetaException, TException {
-    client.alter_partitions_with_environment_context(dbName, tblName, newParts, environmentContext);
+    client.alter_partitions(dbName, tblName, newParts);
 }
 
   @Override
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java b/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java
index 5ab9d55..164699c 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java
@@ -57,7 +57,6 @@
 import org.apache.hadoop.hive.metastore.api.CurrentNotificationEventId;
 import org.apache.hadoop.hive.metastore.api.FireEventRequest;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.FireEventResponse;
 import org.apache.hadoop.hive.metastore.api.Function;
@@ -690,10 +689,9 @@ void createTable(Table tbl) throws AlreadyExistsException,
   void alter_table(String defaultDatabaseName, String tblName,
       Table table) throws InvalidOperationException, MetaException, TException;
 
-  //wrapper of alter_table_with_cascade
-  void alter_table_with_environmentContext(String defaultDatabaseName, String tblName, Table table,
-      EnvironmentContext environmentContext) throws InvalidOperationException, MetaException,
-      TException;
+  //alter_table_with_cascade
+  void alter_table(String defaultDatabaseName, String tblName, Table table,
+      boolean cascade) throws InvalidOperationException, MetaException, TException;
 
   void createDatabase(Database db)
       throws InvalidObjectException, AlreadyExistsException, MetaException, TException;
@@ -779,7 +777,7 @@ boolean dropPartition(String db_name, String tbl_name,
    * @throws TException
    *           if error in communicating with metastore server
    */
-  void alter_partition(String dbName, String tblName, Partition newPart, EnvironmentContext environmentContext)
+  void alter_partition(String dbName, String tblName, Partition newPart)
       throws InvalidOperationException, MetaException, TException;
 
   /**
@@ -798,7 +796,7 @@ void alter_partition(String dbName, String tblName, Partition newPart, Environme
    * @throws TException
    *           if error in communicating with metastore server
    */
-  void alter_partitions(String dbName, String tblName, List<Partition> newParts, EnvironmentContext environmentContext)
+  void alter_partitions(String dbName, String tblName, List<Partition> newParts)
       throws InvalidOperationException, MetaException, TException;
 
   /**
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
index 1839cce..7cd2580 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
@@ -57,7 +57,6 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.HiveMetaStore.HMSHandler;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.InvalidOperationException;
 import org.apache.hadoop.hive.metastore.api.MetaException;
@@ -173,14 +172,14 @@ public static boolean containsAllFastStats(Map<String, String> partParams) {
   }
 
   public static boolean updateUnpartitionedTableStatsFast(Database db, Table tbl, Warehouse wh,
-      boolean madeDir, EnvironmentContext environmentContext) throws MetaException {
-    return updateUnpartitionedTableStatsFast(db, tbl, wh, madeDir, false, environmentContext);
+      boolean madeDir) throws MetaException {
+    return updateUnpartitionedTableStatsFast(db, tbl, wh, madeDir, false);
   }
 
   public static boolean updateUnpartitionedTableStatsFast(Database db, Table tbl, Warehouse wh,
-      boolean madeDir, boolean forceRecompute, EnvironmentContext environmentContext) throws MetaException {
+      boolean madeDir, boolean forceRecompute) throws MetaException {
     return updateUnpartitionedTableStatsFast(tbl,
-        wh.getFileStatusesForUnpartitionedTable(db, tbl), madeDir, forceRecompute, environmentContext);
+        wh.getFileStatusesForUnpartitionedTable(db, tbl), madeDir, forceRecompute);
   }
 
   /**
@@ -194,7 +193,7 @@ public static boolean updateUnpartitionedTableStatsFast(Database db, Table tbl,
    * @return true if the stats were updated, false otherwise
    */
   public static boolean updateUnpartitionedTableStatsFast(Table tbl,
-      FileStatus[] fileStatus, boolean newDir, boolean forceRecompute, EnvironmentContext environmentContext) throws MetaException {
+      FileStatus[] fileStatus, boolean newDir, boolean forceRecompute) throws MetaException {
 
     Map<String,String> params = tbl.getParameters();
 
@@ -220,13 +219,12 @@ public static boolean updateUnpartitionedTableStatsFast(Table tbl,
         LOG.info("Updating table stats fast for " + tbl.getTableName());
         populateQuickStats(fileStatus, params);
         LOG.info("Updated size of table " + tbl.getTableName() +" to "+ params.get(StatsSetupConst.TOTAL_SIZE));
-        if (environmentContext != null
-            && environmentContext.isSetProperties()
-            && StatsSetupConst.TASK.equals(environmentContext.getProperties().get(
-                StatsSetupConst.STATS_GENERATED))) {
-          StatsSetupConst.setBasicStatsState(params, StatsSetupConst.TRUE);
-        } else {
+        if(!params.containsKey(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK)) {
+          // invalidate stats requiring scan since this is a regular ddl alter case
           StatsSetupConst.setBasicStatsState(params, StatsSetupConst.FALSE);
+        } else {
+          params.remove(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK);
+          StatsSetupConst.setBasicStatsState(params, StatsSetupConst.TRUE);
         }
       }
       tbl.setParameters(params);
@@ -251,7 +249,7 @@ public static void populateQuickStats(FileStatus[] fileStatus, Map<String, Strin
 
   // check if stats need to be (re)calculated
   public static boolean requireCalStats(Configuration hiveConf, Partition oldPart,
-    Partition newPart, Table tbl, EnvironmentContext environmentContext) {
+    Partition newPart, Table tbl) {
 
     if (MetaStoreUtils.isView(tbl)) {
       return false;
@@ -267,10 +265,7 @@ public static boolean requireCalStats(Configuration hiveConf, Partition oldPart,
       return true;
     }
 
-    if (environmentContext != null
-        && environmentContext.isSetProperties()
-        && StatsSetupConst.TASK.equals(environmentContext.getProperties().get(
-            StatsSetupConst.STATS_GENERATED))) {
+    if(newPart.getParameters().containsKey(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK)) {
       return true;
     }
 
@@ -289,14 +284,14 @@ public static boolean requireCalStats(Configuration hiveConf, Partition oldPart,
     return false;
   }
 
-  public static boolean updatePartitionStatsFast(Partition part, Warehouse wh, EnvironmentContext environmentContext)
+  public static boolean updatePartitionStatsFast(Partition part, Warehouse wh)
       throws MetaException {
-    return updatePartitionStatsFast(part, wh, false, false, environmentContext);
+    return updatePartitionStatsFast(part, wh, false, false);
   }
 
-  public static boolean updatePartitionStatsFast(Partition part, Warehouse wh, boolean madeDir, EnvironmentContext environmentContext)
+  public static boolean updatePartitionStatsFast(Partition part, Warehouse wh, boolean madeDir)
       throws MetaException {
-    return updatePartitionStatsFast(part, wh, madeDir, false, environmentContext);
+    return updatePartitionStatsFast(part, wh, madeDir, false);
   }
 
   /**
@@ -310,9 +305,9 @@ public static boolean updatePartitionStatsFast(Partition part, Warehouse wh, boo
    * @return true if the stats were updated, false otherwise
    */
   public static boolean updatePartitionStatsFast(Partition part, Warehouse wh,
-      boolean madeDir, boolean forceRecompute, EnvironmentContext environmentContext) throws MetaException {
+      boolean madeDir, boolean forceRecompute) throws MetaException {
     return updatePartitionStatsFast(new PartitionSpecProxy.SimplePartitionWrapperIterator(part),
-                                    wh, madeDir, forceRecompute, environmentContext);
+                                    wh, madeDir, forceRecompute);
   }
 
   /**
@@ -326,7 +321,7 @@ public static boolean updatePartitionStatsFast(Partition part, Warehouse wh,
    * @return true if the stats were updated, false otherwise
    */
   public static boolean updatePartitionStatsFast(PartitionSpecProxy.PartitionIterator part, Warehouse wh,
-      boolean madeDir, boolean forceRecompute, EnvironmentContext environmentContext) throws MetaException {
+      boolean madeDir, boolean forceRecompute) throws MetaException {
     Map<String,String> params = part.getParameters();
     boolean updated = false;
     if (forceRecompute ||
@@ -342,13 +337,12 @@ public static boolean updatePartitionStatsFast(PartitionSpecProxy.PartitionItera
         FileStatus[] fileStatus = wh.getFileStatusesForLocation(part.getLocation());
         populateQuickStats(fileStatus, params);
         LOG.warn("Updated size to " + params.get(StatsSetupConst.TOTAL_SIZE));
-        if (environmentContext != null
-            && environmentContext.isSetProperties()
-            && StatsSetupConst.TASK.equals(environmentContext.getProperties().get(
-                StatsSetupConst.STATS_GENERATED))) {
-          StatsSetupConst.setBasicStatsState(params, StatsSetupConst.TRUE);
-        } else {
+        if(!params.containsKey(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK)) {
+          // invalidate stats requiring scan since this is a regular ddl alter case
           StatsSetupConst.setBasicStatsState(params, StatsSetupConst.FALSE);
+        } else {
+          params.remove(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK);
+          StatsSetupConst.setBasicStatsState(params, StatsSetupConst.TRUE);
         }
       }
       part.setParameters(params);
diff --git a/ql/src/java/org/apache/hadoop/hive/metastore/SynchronizedMetaStoreClient.java b/ql/src/java/org/apache/hadoop/hive/metastore/SynchronizedMetaStoreClient.java
index c473119..19a97ab 100644
--- a/ql/src/java/org/apache/hadoop/hive/metastore/SynchronizedMetaStoreClient.java
+++ b/ql/src/java/org/apache/hadoop/hive/metastore/SynchronizedMetaStoreClient.java
@@ -69,7 +69,7 @@ public synchronized Partition add_partition(Partition partition) throws TExcepti
 
   public synchronized void alter_partition(String dbName, String tblName,
       Partition newPart, EnvironmentContext environmentContext) throws TException {
-    client.alter_partition(dbName, tblName, newPart, environmentContext);
+    client.alter_partition(dbName, tblName, newPart);
   }
 
   public synchronized LockResponse checkLock(long lockid) throws TException {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index f382a61..aa556bc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -73,7 +73,6 @@
 import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.GetOpenTxnsInfoResponse;
 import org.apache.hadoop.hive.metastore.api.Index;
@@ -1036,7 +1035,7 @@ private int alterTableAlterPart(Hive db, AlterTableAlterPartDesc alterPartitionD
     tbl.getTTable().setPartitionKeys(newPartitionKeys);
 
     try {
-      db.alterTable(tabName, tbl, null);
+      db.alterTable(tabName, tbl);
     } catch (InvalidOperationException e) {
       throw new HiveException(e, ErrorMsg.GENERIC_ERROR, "Unable to alter " + tabName);
     }
@@ -1064,7 +1063,7 @@ private int touch(Hive db, AlterTableSimpleDesc touchDesc)
 
     if (touchDesc.getPartSpec() == null) {
       try {
-        db.alterTable(touchDesc.getTableName(), tbl, null);
+        db.alterTable(touchDesc.getTableName(), tbl);
       } catch (InvalidOperationException e) {
         throw new HiveException("Uable to update table");
       }
@@ -1076,7 +1075,7 @@ private int touch(Hive db, AlterTableSimpleDesc touchDesc)
         throw new HiveException("Specified partition does not exist");
       }
       try {
-        db.alterPartition(touchDesc.getTableName(), part, null);
+        db.alterPartition(touchDesc.getTableName(), part);
       } catch (InvalidOperationException e) {
         throw new HiveException(e);
       }
@@ -1425,7 +1424,7 @@ private int archive(Hive db, AlterTableSimpleDesc simpleDesc,
             authority.toString(),
             harPartitionDir.getPath()); // make in Path to ensure no slash at the end
         setArchived(p, harPath, partSpecInfo.values.size());
-        db.alterPartition(simpleDesc.getTableName(), p, null);
+        db.alterPartition(simpleDesc.getTableName(), p);
       }
     } catch (Exception e) {
       throw new HiveException("Unable to change the partition info for HAR", e);
@@ -1631,7 +1630,7 @@ private int unarchive(Hive db, AlterTableSimpleDesc simpleDesc)
     for(Partition p: partitions) {
       setUnArchived(p);
       try {
-        db.alterPartition(simpleDesc.getTableName(), p, null);
+        db.alterPartition(simpleDesc.getTableName(), p);
       } catch (InvalidOperationException e) {
         throw new HiveException(e);
       }
@@ -3402,9 +3401,9 @@ private int alterTable(Hive db, AlterTableDesc alterTbl) throws HiveException {
 
     try {
       if (allPartitions == null) {
-        db.alterTable(alterTbl.getOldName(), tbl, alterTbl.getIsCascade(), alterTbl.getEnvironmentContext());
+        db.alterTable(alterTbl.getOldName(), tbl, alterTbl.getIsCascade());
       } else {
-        db.alterPartitions(tbl.getTableName(), allPartitions, alterTbl.getEnvironmentContext());
+        db.alterPartitions(tbl.getTableName(), allPartitions);
       }
     } catch (InvalidOperationException e) {
       LOG.error("alter table: " + stringifyException(e));
@@ -3563,19 +3562,11 @@ private int alterTableOrSinglePartition(AlterTableDesc alterTbl, Table tbl, Part
       }
       sd.setCols(alterTbl.getNewCols());
     } else if (alterTbl.getOp() == AlterTableDesc.AlterTableTypes.ADDPROPS) {
-      if (part != null) {
-        part.getTPartition().getParameters().putAll(alterTbl.getProps());
-      } else {
-        tbl.getTTable().getParameters().putAll(alterTbl.getProps());
-      }
+      tbl.getTTable().getParameters().putAll(alterTbl.getProps());
     } else if (alterTbl.getOp() == AlterTableDesc.AlterTableTypes.DROPPROPS) {
       Iterator<String> keyItr = alterTbl.getProps().keySet().iterator();
       while (keyItr.hasNext()) {
-        if (part != null) {
-          part.getTPartition().getParameters().remove(keyItr.next());
-        } else {
-          tbl.getTTable().getParameters().remove(keyItr.next());
-        }
+        tbl.getTTable().getParameters().remove(keyItr.next());
       }
     } else if (alterTbl.getOp() == AlterTableDesc.AlterTableTypes.ADDSERDEPROPS) {
       StorageDescriptor sd = retrieveStorageDescriptor(tbl, part);
@@ -4178,7 +4169,7 @@ private int createTable(Hive db, CreateTableDesc crtTbl) throws HiveException {
     if (crtTbl.getReplaceMode()){
       // replace-mode creates are really alters using CreateTableDesc.
       try {
-        db.alterTable(tbl.getDbName()+"."+tbl.getTableName(),tbl,null);
+        db.alterTable(tbl.getDbName()+"."+tbl.getTableName(),tbl);
       } catch (InvalidOperationException e) {
         throw new HiveException("Unable to alter table. " + e.getMessage(), e);
       }
@@ -4364,7 +4355,7 @@ private int createView(Hive db, CreateViewDesc crtView) throws HiveException {
       }
       oldview.checkValidity();
       try {
-        db.alterTable(crtView.getViewName(), oldview, null);
+        db.alterTable(crtView.getViewName(), oldview);
       } catch (InvalidOperationException e) {
         throw new HiveException(e);
       }
@@ -4469,31 +4460,28 @@ private int exchangeTablePartition(Hive db,
       if (table.isPartitioned()) {
         for (Partition partition : db.getPartitions(table)) {
           locations.add(partition.getDataLocation());
-          EnvironmentContext environmentContext = new EnvironmentContext();
-          if (needToUpdateStats(partition.getParameters(), environmentContext)) {
-            db.alterPartition(table.getDbName(), table.getTableName(), partition, environmentContext);
+          if (needToUpdateStats(partition.getParameters())) {
+            db.alterPartition(table.getDbName(), table.getTableName(), partition);
           }
         }
       } else {
         locations.add(table.getPath());
-        EnvironmentContext environmentContext = new EnvironmentContext();
-        if (needToUpdateStats(table.getParameters(), environmentContext)) {
-          db.alterTable(table.getDbName()+"."+table.getTableName(), table, environmentContext);
+        if (needToUpdateStats(table.getParameters())) {
+          db.alterTable(table.getDbName()+"."+table.getTableName(), table);
         }
       }
     } else {
       for (Partition partition : db.getPartitionsByNames(table, partSpec)) {
         locations.add(partition.getDataLocation());
-        EnvironmentContext environmentContext = new EnvironmentContext();
-        if (needToUpdateStats(partition.getParameters(), environmentContext)) {
-          db.alterPartition(table.getDbName(), table.getTableName(), partition, environmentContext);
+        if (needToUpdateStats(partition.getParameters())) {
+          db.alterPartition(table.getDbName(), table.getTableName(), partition);
         }
       }
     }
     return locations;
   }
 
-  private boolean needToUpdateStats(Map<String,String> props, EnvironmentContext environmentContext) {
+  private boolean needToUpdateStats(Map<String,String> props) {
     if (null == props) {
       return false;
     }
@@ -4508,7 +4496,7 @@ private boolean needToUpdateStats(Map<String,String> props, EnvironmentContext e
     }
     //first set basic stats to true
     StatsSetupConst.setBasicStatsState(props, StatsSetupConst.TRUE);
-    environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED, StatsSetupConst.TASK);
+    props.put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, StatsSetupConst.TRUE);
     //then invalidate column stats
     StatsSetupConst.clearColumnStatsState(props);
     return statsPresent;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
index 71acc36..b93203d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
@@ -595,7 +595,7 @@ private void updatePartitionBucketSortColumns(Table table, Partition partn,
     }
 
     if (updateBucketCols || updateSortCols) {
-      db.alterPartition(table.getDbName(), table.getTableName(), partn, null);
+      db.alterPartition(table.getDbName(), table.getTableName(), partn);
     }
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsNoJobTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsNoJobTask.java
index aafd72e..f089964 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsNoJobTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsNoJobTask.java
@@ -35,7 +35,6 @@
 import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.InvalidOperationException;
 import org.apache.hadoop.hive.ql.DriverContext;
 import org.apache.hadoop.hive.ql.QueryPlan;
@@ -175,6 +174,7 @@ public void run() {
           parameters.put(StatsSetupConst.RAW_DATA_SIZE, String.valueOf(rawDataSize));
           parameters.put(StatsSetupConst.TOTAL_SIZE, String.valueOf(fileSize));
           parameters.put(StatsSetupConst.NUM_FILES, String.valueOf(numFiles));
+          parameters.put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, StatsSetupConst.TRUE);
 
           partUpdates.put(tPart.getSd().getLocation(), new Partition(table, tPart));
 
@@ -266,10 +266,9 @@ private int aggregateStats(ExecutorService threadPool) {
             parameters.put(StatsSetupConst.RAW_DATA_SIZE, String.valueOf(rawDataSize));
             parameters.put(StatsSetupConst.TOTAL_SIZE, String.valueOf(fileSize));
             parameters.put(StatsSetupConst.NUM_FILES, String.valueOf(numFiles));
-            EnvironmentContext environmentContext = new EnvironmentContext();
-            environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED, StatsSetupConst.TASK);
+            parameters.put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, StatsSetupConst.TRUE);
 
-            db.alterTable(tableFullName, new Table(tTable), environmentContext);
+            db.alterTable(tableFullName, new Table(tTable));
 
             String msg = "Table " + tableFullName + " stats: [" + toString(parameters) + ']';
             LOG.debug(msg);
@@ -316,10 +315,7 @@ private int updatePartitions() throws InvalidOperationException, HiveException {
         return -1;
       } else {
         LOG.debug("Bulk updating partitions..");
-        EnvironmentContext environmentContext = new EnvironmentContext();
-        environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED, StatsSetupConst.TASK);
-        db.alterPartitions(tableFullName, Lists.newArrayList(partUpdates.values()),
-            environmentContext);
+        db.alterPartitions(tableFullName, Lists.newArrayList(partUpdates.values()));
         LOG.debug("Bulk updated " + partUpdates.values().size() + " partitions.");
       }
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
index 35e420f..8bb1618 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
@@ -37,7 +37,6 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.MetaStoreUtils;
 import org.apache.hadoop.hive.metastore.Warehouse;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
 import org.apache.hadoop.hive.ql.DriverContext;
@@ -144,7 +143,6 @@ private int aggregateStats() {
     StatsAggregator statsAggregator = null;
     int ret = 0;
     StatsCollectionContext scc = null;
-    EnvironmentContext environmentContext = null;
     try {
       // Stats setup:
       final Warehouse wh = new Warehouse(conf);
@@ -192,11 +190,10 @@ private int aggregateStats() {
 
         // write table stats to metastore
         if (!getWork().getNoStatsAggregator()) {
-          environmentContext = new EnvironmentContext();
-          environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED, StatsSetupConst.TASK);
+          parameters.put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, StatsSetupConst.TRUE);
         }
 
-        db.alterTable(tableFullName, new Table(tTable), environmentContext);
+        db.alterTable(tableFullName, new Table(tTable));
 
         console.printInfo("Table " + tableFullName + " stats: [" + toString(parameters) + ']');
       } else {
@@ -280,9 +277,7 @@ public Void call() throws Exception {
           updateQuickStats(parameters, fileStatusMap.get(partn.getName()));
 
           if (!getWork().getNoStatsAggregator()) {
-            environmentContext = new EnvironmentContext();
-            environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED,
-                StatsSetupConst.TASK);
+            parameters.put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, StatsSetupConst.TRUE);
           }
           updates.add(new Partition(table, tPart));
 
@@ -290,7 +285,7 @@ public Void call() throws Exception {
               " stats: [" + toString(parameters) + ']');
         }
         if (!updates.isEmpty()) {
-          db.alterPartitions(tableFullName, updates, environmentContext);
+          db.alterPartitions(tableFullName, updates);
         }
       }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/UpdateInputAccessTimeHook.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/UpdateInputAccessTimeHook.java
index 48f3b28..0e8807e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/UpdateInputAccessTimeHook.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/UpdateInputAccessTimeHook.java
@@ -66,7 +66,7 @@ public void run(SessionState sess, Set<ReadEntity> inputs,
         case TABLE: {
           Table t = db.getTable(re.getTable().getTableName());
           t.setLastAccessTime(lastAccessTime);
-          db.alterTable(t.getDbName() + "." + t.getTableName(), t, null);
+          db.alterTable(t.getDbName() + "." + t.getTableName(), t);
           break;
         }
         case PARTITION: {
@@ -74,9 +74,9 @@ public void run(SessionState sess, Set<ReadEntity> inputs,
           Table t = db.getTable(p.getTable().getTableName());
           p = db.getPartition(t, p.getSpec(), false);
           p.setLastAccessTime(lastAccessTime);
-          db.alterPartition(t.getTableName(), p, null);
+          db.alterPartition(t.getTableName(), p);
           t.setLastAccessTime(lastAccessTime);
-          db.alterTable(t.getDbName() + "." + t.getTableName(), t, null);
+          db.alterTable(t.getDbName() + "." + t.getTableName(), t);
           break;
         }
         default:
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java b/ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java
index 02f7f55..eeb343b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java
@@ -71,13 +71,13 @@ protected int execute(DriverContext driverContext) {
         FileStatus fstat = fs.getFileStatus(path);
 
         part.getParameters().put(HiveIndex.INDEX_TABLE_CREATETIME, Long.toString(fstat.getModificationTime()));
-        db.alterPartition(tbl.getTableName(), part, null);
+        db.alterPartition(tbl.getTableName(), part);
       } else {
         Path url = new Path(tbl.getPath().toString());
         FileSystem fs = url.getFileSystem(conf);
         FileStatus fstat = fs.getFileStatus(url);
         tbl.getParameters().put(HiveIndex.INDEX_TABLE_CREATETIME, Long.toString(fstat.getModificationTime()));
-        db.alterTable(tbl.getDbName() + "." + tbl.getTableName(), tbl, null);
+        db.alterTable(tbl.getDbName() + "." + tbl.getTableName(), tbl);
       }
     } catch (Exception e) {
       e.printStackTrace();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 6ba6b67..83e4f05 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -87,7 +87,6 @@
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
 import org.apache.hadoop.hive.metastore.api.CompactionType;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.FireEventRequest;
 import org.apache.hadoop.hive.metastore.api.FireEventRequestData;
@@ -550,12 +549,12 @@ public void createTable(String tableName, List<String> columns, List<String> par
    *           if the changes in metadata is not acceptable
    * @throws TException
    */
-  public void alterTable(String tblName, Table newTbl, EnvironmentContext environmentContext)
+  public void alterTable(String tblName, Table newTbl)
       throws InvalidOperationException, HiveException {
-    alterTable(tblName, newTbl, false, environmentContext);
+    alterTable(tblName, newTbl, false);
   }
 
-  public void alterTable(String tblName, Table newTbl, boolean cascade, EnvironmentContext environmentContext)
+  public void alterTable(String tblName, Table newTbl, boolean cascade)
       throws InvalidOperationException, HiveException {
     String[] names = Utilities.getDbTableName(tblName);
     try {
@@ -564,13 +563,7 @@ public void alterTable(String tblName, Table newTbl, boolean cascade, Environmen
         newTbl.getParameters().remove(hive_metastoreConstants.DDL_TIME);
       }
       newTbl.checkValidity();
-      if (environmentContext == null) {
-        environmentContext = new EnvironmentContext();
-      }
-      if (cascade) {
-        environmentContext.putToProperties(StatsSetupConst.CASCADE, StatsSetupConst.TRUE);
-      }
-      getMSC().alter_table_with_environmentContext(names[0], names[1], newTbl.getTTable(), environmentContext);
+      getMSC().alter_table(names[0], names[1], newTbl.getTTable(), cascade);
     } catch (MetaException e) {
       throw new HiveException("Unable to alter table. " + e.getMessage(), e);
     } catch (TException e) {
@@ -617,10 +610,10 @@ public void alterIndex(String dbName, String baseTblName, String idxName, Index
    *           if the changes in metadata is not acceptable
    * @throws TException
    */
-  public void alterPartition(String tblName, Partition newPart, EnvironmentContext environmentContext)
+  public void alterPartition(String tblName, Partition newPart)
       throws InvalidOperationException, HiveException {
     String[] names = Utilities.getDbTableName(tblName);
-    alterPartition(names[0], names[1], newPart, environmentContext);
+    alterPartition(names[0], names[1], newPart);
   }
 
   /**
@@ -636,7 +629,7 @@ public void alterPartition(String tblName, Partition newPart, EnvironmentContext
    *           if the changes in metadata is not acceptable
    * @throws TException
    */
-  public void alterPartition(String dbName, String tblName, Partition newPart, EnvironmentContext environmentContext)
+  public void alterPartition(String dbName, String tblName, Partition newPart)
       throws InvalidOperationException, HiveException {
     try {
       // Remove the DDL time so that it gets refreshed
@@ -644,7 +637,7 @@ public void alterPartition(String dbName, String tblName, Partition newPart, Env
         newPart.getParameters().remove(hive_metastoreConstants.DDL_TIME);
       }
       newPart.checkValidity();
-      getMSC().alter_partition(dbName, tblName, newPart.getTPartition(), environmentContext);
+      getMSC().alter_partition(dbName, tblName, newPart.getTPartition());
 
     } catch (MetaException e) {
       throw new HiveException("Unable to alter partition. " + e.getMessage(), e);
@@ -664,7 +657,7 @@ public void alterPartition(String dbName, String tblName, Partition newPart, Env
    *           if the changes in metadata is not acceptable
    * @throws TException
    */
-  public void alterPartitions(String tblName, List<Partition> newParts, EnvironmentContext environmentContext)
+  public void alterPartitions(String tblName, List<Partition> newParts)
       throws InvalidOperationException, HiveException {
     String[] names = Utilities.getDbTableName(tblName);
     List<org.apache.hadoop.hive.metastore.api.Partition> newTParts =
@@ -677,7 +670,7 @@ public void alterPartitions(String tblName, List<Partition> newParts, Environmen
         }
         newTParts.add(tmpPart.getTPartition());
       }
-      getMSC().alter_partitions(names[0], names[1], newTParts, environmentContext);
+      getMSC().alter_partitions(names[0], names[1], newTParts);
     } catch (MetaException e) {
       throw new HiveException("Unable to alter partition. " + e.getMessage(), e);
     } catch (TException e) {
@@ -1498,18 +1491,18 @@ public Partition loadPartition(Path loadPath, Table tbl,
           /* Add list bucketing location mappings. */
           skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);
           newCreatedTpart.getSd().setSkewedInfo(skewedInfo);
-          if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+          if(!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
             newTPart.getParameters().put(StatsSetupConst.COLUMN_STATS_ACCURATE, "false");
           }
-          alterPartition(tbl.getDbName(), tbl.getTableName(), new Partition(tbl, newCreatedTpart), null);
+          alterPartition(tbl.getDbName(), tbl.getTableName(), new Partition(tbl, newCreatedTpart));
           newTPart = getPartition(tbl, partSpec, true, newPartPath.toString(), inheritTableSpecs,
               newFiles);
           return new Partition(tbl, newCreatedTpart);
         }
-        if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+        if(!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
           StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);
         }
-        alterPartition(tbl.getDbName(), tbl.getTableName(), new Partition(tbl, newTPart.getTPartition()), null);
+        alterPartition(tbl.getDbName(), tbl.getTableName(), new Partition(tbl, newTPart.getTPartition()));
       }
     } catch (IOException e) {
       LOG.error(StringUtils.stringifyException(e));
@@ -1777,8 +1770,10 @@ public void loadTable(Path loadPath, String tableName, boolean replace,
         throw new HiveException("addFiles: filesystem error in check phase", e);
       }
     }
-    if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+    if(!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
       StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);
+    }  else {
+      tbl.getParameters().put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, "true");
     }
 
     //column stats will be inaccurate
@@ -1800,7 +1795,7 @@ public void loadTable(Path loadPath, String tableName, boolean replace,
 
     if (!holdDDLTime) {
       try {
-        alterTable(tableName, tbl, null);
+        alterTable(tableName, tbl);
       } catch (InvalidOperationException e) {
         throw new HiveException(e);
       }
@@ -1846,7 +1841,7 @@ public Partition createPartition(Table tbl, Map<String, String> partSpec) throws
           out.add(new Partition(tbl, outPart));
         }
       } else {
-        getMSC().alter_partitions(addPartitionDesc.getDbName(), addPartitionDesc.getTableName(), in, null);
+        getMSC().alter_partitions(addPartitionDesc.getDbName(), addPartitionDesc.getTableName(), in);
         List<String> part_names = new ArrayList<String>();
         for (org.apache.hadoop.hive.metastore.api.Partition p: in){
           part_names.add(Warehouse.makePartName(tbl.getPartitionKeys(), p.getValues()));
@@ -2057,7 +2052,7 @@ private void alterPartitionSpec(Table tbl,
     if (!org.apache.commons.lang.StringUtils.isEmpty(tbl.getDbName())) {
       fullName = tbl.getDbName() + "." + tbl.getTableName();
     }
-    alterPartition(fullName, new Partition(tbl, tpart), null);
+    alterPartition(fullName, new Partition(tbl, tpart));
   }
 
   private void fireInsertEvent(Table tbl, Map<String, String> partitionSpec, List<Path> newFiles)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
index 501d4c5..e2b9452 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
@@ -285,23 +285,20 @@ public boolean tableExists(String databaseName, String tableName) throws MetaExc
   }
 
   @Override
-  public void alter_table(String dbname, String tbl_name,
-      org.apache.hadoop.hive.metastore.api.Table new_tbl) throws InvalidOperationException,
-      MetaException, TException {
+  public void alter_table(String dbname, String tbl_name, org.apache.hadoop.hive.metastore.api.Table new_tbl,
+      boolean cascade) throws InvalidOperationException, MetaException, TException {
     org.apache.hadoop.hive.metastore.api.Table old_tbl = getTempTable(dbname, tbl_name);
     if (old_tbl != null) {
-      // actually temp table does not support partitions, cascade is not
-      // applicable here
+      //actually temp table does not support partitions, cascade is not applicable here
       alterTempTable(dbname, tbl_name, old_tbl, new_tbl, null);
       return;
     }
-    super.alter_table(dbname, tbl_name, new_tbl);
+    super.alter_table(dbname, tbl_name, new_tbl, cascade);
   }
 
   @Override
-  public void alter_table_with_environmentContext(String dbname, String tbl_name,
-      org.apache.hadoop.hive.metastore.api.Table new_tbl, EnvironmentContext envContext)
-      throws InvalidOperationException, MetaException, TException {
+  public void alter_table(String dbname, String tbl_name, org.apache.hadoop.hive.metastore.api.Table new_tbl,
+      EnvironmentContext envContext) throws InvalidOperationException, MetaException, TException {
     // First try temp table
     org.apache.hadoop.hive.metastore.api.Table old_tbl = getTempTable(dbname, tbl_name);
     if (old_tbl != null) {
@@ -310,7 +307,7 @@ public void alter_table_with_environmentContext(String dbname, String tbl_name,
     }
 
     // Try underlying client
-    super.alter_table_with_environmentContext(dbname, tbl_name, new_tbl, envContext);
+    super.alter_table(dbname,  tbl_name,  new_tbl, envContext);
   }
 
   @Override
@@ -435,7 +432,7 @@ private void alterTempTable(String dbname, String tbl_name,
 
     org.apache.hadoop.hive.metastore.api.Table newtCopy = deepCopyAndLowerCaseTable(newt);
     MetaStoreUtils.updateUnpartitionedTableStatsFast(newtCopy,
-        getWh().getFileStatusesForSD(newtCopy.getSd()), false, true, envContext);
+        getWh().getFileStatusesForSD(newtCopy.getSd()), false, true);
     Table newTable = new Table(newtCopy);
     String newDbName = newTable.getDbName();
     String newTableName = newTable.getTableName();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index b0fc914..bc4ec01 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -46,14 +46,12 @@
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.common.JavaUtils;
-import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.metastore.MetaStoreUtils;
 import org.apache.hadoop.hive.metastore.TableType;
 import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.Index;
 import org.apache.hadoop.hive.metastore.api.MetaException;
@@ -116,7 +114,6 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.ql.plan.FetchWork;
-import org.apache.hadoop.hive.ql.plan.HiveOperation;
 import org.apache.hadoop.hive.ql.plan.ListBucketingCtx;
 import org.apache.hadoop.hive.ql.plan.LoadTableDesc;
 import org.apache.hadoop.hive.ql.plan.LockDatabaseDesc;
@@ -269,11 +266,9 @@ public void analyzeInternal(ASTNode input) throws SemanticException {
       } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_PARTCOLTYPE) {
         analyzeAlterTablePartColType(qualified, ast);
       } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_PROPERTIES) {
-        analyzeAlterTableProps(qualified, null, ast, false, false);
+        analyzeAlterTableProps(qualified, ast, false, false);
       } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_DROPPROPERTIES) {
-        analyzeAlterTableProps(qualified, null, ast, false, true);
-      } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_UPDATESTATS) {
-        analyzeAlterTableProps(qualified, partSpec, ast, false, false);
+        analyzeAlterTableProps(qualified, ast, false, true);
       } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_SKEWED) {
         analyzeAltertableSkewedby(qualified, ast);
       } else if (ast.getType() == HiveParser.TOK_ALTERTABLE_EXCHANGEPARTITION) {
@@ -384,9 +379,9 @@ public void analyzeInternal(ASTNode input) throws SemanticException {
       String[] qualified = getQualifiedTableName((ASTNode) ast.getChild(0));
       ast = (ASTNode) ast.getChild(1);
       if (ast.getType() == HiveParser.TOK_ALTERVIEW_PROPERTIES) {
-        analyzeAlterTableProps(qualified, null, ast, true, false);
+        analyzeAlterTableProps(qualified, ast, true, false);
       } else if (ast.getType() == HiveParser.TOK_ALTERVIEW_DROPPROPERTIES) {
-        analyzeAlterTableProps(qualified, null, ast, true, true);
+        analyzeAlterTableProps(qualified, ast, true, true);
       } else if (ast.getType() == HiveParser.TOK_ALTERVIEW_ADDPARTS) {
         analyzeAlterTableAddParts(qualified, ast, true);
       } else if (ast.getType() == HiveParser.TOK_ALTERVIEW_DROPPARTS) {
@@ -1298,56 +1293,25 @@ private void validateAlterTableType(Table tbl, AlterTableTypes op, boolean expec
     }
   }
 
-  private void analyzeAlterTableProps(String[] qualified, HashMap<String, String> partSpec,
-      ASTNode ast, boolean expectView, boolean isUnset) throws SemanticException {
+  private void analyzeAlterTableProps(String[] qualified, ASTNode ast, boolean expectView, boolean isUnset)
+      throws SemanticException {
 
     String tableName = getDotName(qualified);
     HashMap<String, String> mapProp = getProps((ASTNode) (ast.getChild(0))
         .getChild(0));
-    EnvironmentContext environmentContext = null;
-    if (SessionState.get().getCommandType()
-        .equals(HiveOperation.ALTERTABLE_UPDATETABLESTATS.getOperationName())
-        || SessionState.get().getCommandType()
-            .equals(HiveOperation.ALTERTABLE_UPDATEPARTSTATS.getOperationName())) {
-      // we need to check if the properties are valid, especially for stats.
-      boolean changeStatsSucceeded = false;
-      for (Entry<String, String> entry : mapProp.entrySet()) {
-        // we make sure that we do not change anything if there is anything
-        // wrong.
-        if (entry.getKey().equals(StatsSetupConst.ROW_COUNT)
-            || entry.getKey().equals(StatsSetupConst.RAW_DATA_SIZE)) {
-          try {
-            Long.parseLong(entry.getValue());
-            changeStatsSucceeded = true;
-          } catch (Exception e) {
-            throw new SemanticException("AlterTable " + entry.getKey() + " failed with value "
-                + entry.getValue());
-          }
-        } else {
-          throw new SemanticException("AlterTable UpdateStats " + entry.getKey()
-              + " failed because the only valid keys are" + StatsSetupConst.ROW_COUNT + " and "
-              + StatsSetupConst.RAW_DATA_SIZE);
-        }
-      }
-      if (changeStatsSucceeded) {
-        environmentContext = new EnvironmentContext();
-        environmentContext.putToProperties(StatsSetupConst.STATS_GENERATED, StatsSetupConst.USER);
-      }
-    }
     AlterTableDesc alterTblDesc = null;
     if (isUnset == true) {
-      alterTblDesc = new AlterTableDesc(AlterTableTypes.DROPPROPS, partSpec, expectView);
+      alterTblDesc = new AlterTableDesc(AlterTableTypes.DROPPROPS, expectView);
       if (ast.getChild(1) != null) {
         alterTblDesc.setDropIfExists(true);
       }
     } else {
-      alterTblDesc = new AlterTableDesc(AlterTableTypes.ADDPROPS, partSpec, expectView);
+      alterTblDesc = new AlterTableDesc(AlterTableTypes.ADDPROPS, expectView);
     }
     alterTblDesc.setProps(mapProp);
-    alterTblDesc.setEnvironmentContext(environmentContext);
     alterTblDesc.setOldName(tableName);
 
-    addInputsOutputsAlterTable(tableName, partSpec, alterTblDesc);
+    addInputsOutputsAlterTable(tableName, null, alterTblDesc);
 
     rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
         alterTblDesc), conf));
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
index c58a3aa..ec53182 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
@@ -148,7 +148,6 @@ TOK_ALTERTABLE_UNARCHIVE;
 TOK_ALTERTABLE_SERDEPROPERTIES;
 TOK_ALTERTABLE_SERIALIZER;
 TOK_ALTERTABLE_UPDATECOLSTATS;
-TOK_ALTERTABLE_UPDATESTATS;
 TOK_TABLE_PARTITION;
 TOK_ALTERTABLE_FILEFORMAT;
 TOK_ALTERTABLE_LOCATION;
@@ -996,7 +995,6 @@ alterTblPartitionStatementSuffix
   | alterStatementSuffixClusterbySortby
   | alterStatementSuffixCompact
   | alterStatementSuffixUpdateStatsCol
-  | alterStatementSuffixUpdateStats
   | alterStatementSuffixRenameCol
   | alterStatementSuffixAddCol
   ;
@@ -1083,13 +1081,6 @@ alterStatementSuffixUpdateStatsCol
     ->^(TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties $comment?)
     ;
 
-alterStatementSuffixUpdateStats
-@init { pushMsg("update basic statistics", state); }
-@after { popMsg(state); }
-    : KW_UPDATE KW_STATISTICS KW_SET tableProperties
-    ->^(TOK_ALTERTABLE_UPDATESTATS tableProperties)
-    ;
-
 alterStatementChangeColPosition
     : first=KW_FIRST|KW_AFTER afterCol=identifier
     ->{$first != null}? ^(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
index 0384bfc..e21c34f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
@@ -151,9 +151,6 @@
     tablePartitionCommandType.put(HiveParser.TOK_ALTERTABLE_UPDATECOLSTATS,
         new HiveOperation[] {HiveOperation.ALTERTABLE_UPDATETABLESTATS,
             HiveOperation.ALTERTABLE_UPDATEPARTSTATS});
-    tablePartitionCommandType.put(HiveParser.TOK_ALTERTABLE_UPDATESTATS,
-        new HiveOperation[] {HiveOperation.ALTERTABLE_UPDATETABLESTATS,
-        HiveOperation.ALTERTABLE_UPDATEPARTSTATS});
   }
 
   public static BaseSemanticAnalyzer get(HiveConf conf, ASTNode tree)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/AlterTableDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/AlterTableDesc.java
index f53852e..24cf1da 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/AlterTableDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/AlterTableDesc.java
@@ -18,8 +18,6 @@
 
 package org.apache.hadoop.hive.ql.plan;
 
-import org.apache.hadoop.hive.metastore.api.EnvironmentContext;
-
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
@@ -117,7 +115,6 @@
   boolean isDropIfExists = false;
   boolean isTurnOffSorting = false;
   boolean isCascade = false;
-  EnvironmentContext environmentContext;
 
   public AlterTableDesc() {
   }
@@ -181,16 +178,15 @@ public AlterTableDesc(String name, HashMap<String, String> partSpec, List<FieldS
    *          type of alter op
    */
   public AlterTableDesc(AlterTableTypes alterType) {
-    this(alterType, null, false);
+    this(alterType, false);
   }
 
   /**
    * @param alterType
    *          type of alter op
    */
-  public AlterTableDesc(AlterTableTypes alterType, HashMap<String, String> partSpec, boolean expectView) {
+  public AlterTableDesc(AlterTableTypes alterType, boolean expectView) {
     op = alterType;
-    this.partSpec = partSpec;
     this.expectView = expectView;
   }
 
@@ -740,12 +736,4 @@ public static boolean doesAlterTableTypeSupportPartialPartitionSpec(AlterTableTy
     return alterTableTypesWithPartialSpec.contains(type);
   }
 
-  public EnvironmentContext getEnvironmentContext() {
-    return environmentContext;
-  }
-
-  public void setEnvironmentContext(EnvironmentContext environmentContext) {
-    this.environmentContext = environmentContext;
-  }
-
 }
diff --git a/ql/src/test/queries/clientnegative/updateBasicStats.q b/ql/src/test/queries/clientnegative/updateBasicStats.q
deleted file mode 100644
index b9e642d..0000000
--- a/ql/src/test/queries/clientnegative/updateBasicStats.q
+++ /dev/null
@@ -1,5 +0,0 @@
-set hive.mapred.mode=nonstrict;
-
-create table s as select * from src limit 10;
-
-alter table s update statistics set ('numRows'='NaN');
diff --git a/ql/src/test/queries/clientpositive/updateBasicStats.q b/ql/src/test/queries/clientpositive/updateBasicStats.q
deleted file mode 100644
index daa8029..0000000
--- a/ql/src/test/queries/clientpositive/updateBasicStats.q
+++ /dev/null
@@ -1,54 +0,0 @@
-set hive.mapred.mode=nonstrict;
-
-create table s as select * from src limit 10;
-
-explain select * from s;
-
-alter table s update statistics set('numRows'='12');
-
-explain select * from s;
-
-analyze table s compute statistics;
-
-explain select * from s;
-
-alter table s update statistics set('numRows'='1212', 'rawDataSize'='500500');
-
-explain select * from s;
-
-CREATE TABLE calendarp (`year` int)  partitioned by (p int);
-
-insert into table calendarp partition (p=1) values (2010), (2011), (2012); 
-
-explain select * from calendarp where p=1;
-
-alter table calendarp partition (p=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000');
-
-explain select * from calendarp where p=1;
-
-create table src_stat_part_two(key string, value string) partitioned by (px int, py string);
-
-insert overwrite table src_stat_part_two partition (px=1, py='a')
-  select * from src limit 1;
-
-insert overwrite table src_stat_part_two partition (px=1, py='b')
-  select * from src limit 10;
-
-insert overwrite table src_stat_part_two partition (px=2, py='b')
-  select * from src limit 100;
-
-explain select * from src_stat_part_two where px=1 and py='a';
-
-explain select * from src_stat_part_two where px=1;
-
-alter table src_stat_part_two partition (px=1, py='a') update statistics set('numRows'='1000020000', 'rawDataSize'='300040000');
-
-explain select * from src_stat_part_two where px=1 and py='a';
-
-explain select * from src_stat_part_two where px=1;
-
-alter table src_stat_part_two partition (px=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000');
-
-explain select * from src_stat_part_two where px=1 and py='a';
-
-explain select * from src_stat_part_two where px=1;
diff --git a/ql/src/test/results/clientnegative/updateBasicStats.q.out b/ql/src/test/results/clientnegative/updateBasicStats.q.out
deleted file mode 100644
index 3c4fe39..0000000
--- a/ql/src/test/results/clientnegative/updateBasicStats.q.out
+++ /dev/null
@@ -1,11 +0,0 @@
-PREHOOK: query: create table s as select * from src limit 10
-PREHOOK: type: CREATETABLE_AS_SELECT
-PREHOOK: Input: default@src
-PREHOOK: Output: database:default
-PREHOOK: Output: default@s
-POSTHOOK: query: create table s as select * from src limit 10
-POSTHOOK: type: CREATETABLE_AS_SELECT
-POSTHOOK: Input: default@src
-POSTHOOK: Output: database:default
-POSTHOOK: Output: default@s
-FAILED: SemanticException AlterTable numRows failed with value NaN
diff --git a/ql/src/test/results/clientpositive/updateBasicStats.q.out b/ql/src/test/results/clientpositive/updateBasicStats.q.out
deleted file mode 100644
index 6cd16fb..0000000
--- a/ql/src/test/results/clientpositive/updateBasicStats.q.out
+++ /dev/null
@@ -1,375 +0,0 @@
-PREHOOK: query: create table s as select * from src limit 10
-PREHOOK: type: CREATETABLE_AS_SELECT
-PREHOOK: Input: default@src
-PREHOOK: Output: database:default
-PREHOOK: Output: default@s
-POSTHOOK: query: create table s as select * from src limit 10
-POSTHOOK: type: CREATETABLE_AS_SELECT
-POSTHOOK: Input: default@src
-POSTHOOK: Output: database:default
-POSTHOOK: Output: default@s
-PREHOOK: query: explain select * from s
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from s
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: s
-          Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: alter table s update statistics set('numRows'='12')
-PREHOOK: type: ALTERTABLE_UPDATETABLESTATS
-PREHOOK: Input: default@s
-PREHOOK: Output: default@s
-POSTHOOK: query: alter table s update statistics set('numRows'='12')
-POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS
-POSTHOOK: Input: default@s
-POSTHOOK: Output: default@s
-PREHOOK: query: explain select * from s
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from s
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: s
-          Statistics: Num rows: 12 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 12 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: analyze table s compute statistics
-PREHOOK: type: QUERY
-PREHOOK: Input: default@s
-PREHOOK: Output: default@s
-POSTHOOK: query: analyze table s compute statistics
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@s
-POSTHOOK: Output: default@s
-PREHOOK: query: explain select * from s
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from s
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: s
-          Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: alter table s update statistics set('numRows'='1212', 'rawDataSize'='500500')
-PREHOOK: type: ALTERTABLE_UPDATETABLESTATS
-PREHOOK: Input: default@s
-PREHOOK: Output: default@s
-POSTHOOK: query: alter table s update statistics set('numRows'='1212', 'rawDataSize'='500500')
-POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS
-POSTHOOK: Input: default@s
-POSTHOOK: Output: default@s
-PREHOOK: query: explain select * from s
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from s
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: s
-          Statistics: Num rows: 1212 Data size: 500500 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 1212 Data size: 500500 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: CREATE TABLE calendarp (`year` int)  partitioned by (p int)
-PREHOOK: type: CREATETABLE
-PREHOOK: Output: database:default
-PREHOOK: Output: default@calendarp
-POSTHOOK: query: CREATE TABLE calendarp (`year` int)  partitioned by (p int)
-POSTHOOK: type: CREATETABLE
-POSTHOOK: Output: database:default
-POSTHOOK: Output: default@calendarp
-PREHOOK: query: insert into table calendarp partition (p=1) values (2010), (2011), (2012)
-PREHOOK: type: QUERY
-PREHOOK: Output: default@calendarp@p=1
-POSTHOOK: query: insert into table calendarp partition (p=1) values (2010), (2011), (2012)
-POSTHOOK: type: QUERY
-POSTHOOK: Output: default@calendarp@p=1
-POSTHOOK: Lineage: calendarp PARTITION(p=1).year EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
-PREHOOK: query: explain select * from calendarp where p=1
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from calendarp where p=1
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: calendarp
-          Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: year (type: int), 1 (type: int)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 3 Data size: 12 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: alter table calendarp partition (p=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-PREHOOK: Input: default@calendarp
-PREHOOK: Output: default@calendarp@p=1
-POSTHOOK: query: alter table calendarp partition (p=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-POSTHOOK: Input: default@calendarp
-POSTHOOK: Input: default@calendarp@p=1
-POSTHOOK: Output: default@calendarp@p=1
-PREHOOK: query: explain select * from calendarp where p=1
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from calendarp where p=1
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: calendarp
-          Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: year (type: int), 1 (type: int)
-            outputColumnNames: _col0, _col1
-            Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: create table src_stat_part_two(key string, value string) partitioned by (px int, py string)
-PREHOOK: type: CREATETABLE
-PREHOOK: Output: database:default
-PREHOOK: Output: default@src_stat_part_two
-POSTHOOK: query: create table src_stat_part_two(key string, value string) partitioned by (px int, py string)
-POSTHOOK: type: CREATETABLE
-POSTHOOK: Output: database:default
-POSTHOOK: Output: default@src_stat_part_two
-PREHOOK: query: insert overwrite table src_stat_part_two partition (px=1, py='a')
-  select * from src limit 1
-PREHOOK: type: QUERY
-PREHOOK: Input: default@src
-PREHOOK: Output: default@src_stat_part_two@px=1/py=a
-POSTHOOK: query: insert overwrite table src_stat_part_two partition (px=1, py='a')
-  select * from src limit 1
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
-POSTHOOK: Output: default@src_stat_part_two@px=1/py=a
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=1,py=a).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=1,py=a).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: insert overwrite table src_stat_part_two partition (px=1, py='b')
-  select * from src limit 10
-PREHOOK: type: QUERY
-PREHOOK: Input: default@src
-PREHOOK: Output: default@src_stat_part_two@px=1/py=b
-POSTHOOK: query: insert overwrite table src_stat_part_two partition (px=1, py='b')
-  select * from src limit 10
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
-POSTHOOK: Output: default@src_stat_part_two@px=1/py=b
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=1,py=b).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=1,py=b).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: insert overwrite table src_stat_part_two partition (px=2, py='b')
-  select * from src limit 100
-PREHOOK: type: QUERY
-PREHOOK: Input: default@src
-PREHOOK: Output: default@src_stat_part_two@px=2/py=b
-POSTHOOK: query: insert overwrite table src_stat_part_two partition (px=2, py='b')
-  select * from src limit 100
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
-POSTHOOK: Output: default@src_stat_part_two@px=2/py=b
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=2,py=b).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: src_stat_part_two PARTITION(px=2,py=b).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 1 Data size: 11 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), 'a' (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1 Data size: 11 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: explain select * from src_stat_part_two where px=1
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 11 Data size: 115 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 11 Data size: 115 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: alter table src_stat_part_two partition (px=1, py='a') update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-PREHOOK: Input: default@src_stat_part_two
-PREHOOK: Output: default@src_stat_part_two@px=1/py=a
-POSTHOOK: query: alter table src_stat_part_two partition (px=1, py='a') update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-POSTHOOK: Input: default@src_stat_part_two
-POSTHOOK: Input: default@src_stat_part_two@px=1/py=a
-POSTHOOK: Output: default@src_stat_part_two@px=1/py=a
-PREHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), 'a' (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: explain select * from src_stat_part_two where px=1
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 1000020010 Data size: 300040104 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1000020010 Data size: 300040104 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: alter table src_stat_part_two partition (px=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-PREHOOK: Input: default@src_stat_part_two
-PREHOOK: Output: default@src_stat_part_two@px=1/py=a
-PREHOOK: Output: default@src_stat_part_two@px=1/py=b
-POSTHOOK: query: alter table src_stat_part_two partition (px=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
-POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS
-POSTHOOK: Input: default@src_stat_part_two
-POSTHOOK: Input: default@src_stat_part_two@px=1/py=a
-POSTHOOK: Input: default@src_stat_part_two@px=1/py=b
-POSTHOOK: Output: default@src_stat_part_two@px=1/py=a
-POSTHOOK: Output: default@src_stat_part_two@px=1/py=b
-PREHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1 and py='a'
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), 'a' (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1000020000 Data size: 300040000 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-PREHOOK: query: explain select * from src_stat_part_two where px=1
-PREHOOK: type: QUERY
-POSTHOOK: query: explain select * from src_stat_part_two where px=1
-POSTHOOK: type: QUERY
-STAGE DEPENDENCIES:
-  Stage-0 is a root stage
-
-STAGE PLANS:
-  Stage: Stage-0
-    Fetch Operator
-      limit: -1
-      Processor Tree:
-        TableScan
-          alias: src_stat_part_two
-          Statistics: Num rows: 2000040000 Data size: 600080000 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
-            outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2000040000 Data size: 600080000 Basic stats: COMPLETE Column stats: NONE
-            ListSink
-
-- 
1.7.9.5


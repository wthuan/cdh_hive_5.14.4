From efd107f07ce29f2f703e24f1747e846c3eaffe5d Mon Sep 17 00:00:00 2001
From: Peter Vary <pvary@cloudera.com>
Date: Mon, 9 Oct 2017 12:09:06 +0200
Subject: [PATCH 1304/1363] CDH-60173: HIVE-17706: Add a possibility to run
 the BeeLine tests on the default database (Peter
 Vary, reviewed by Barna Zsombor Klara)

(cherry picked from commit 1dccdeadaba35a0206b17d512ef1cf9aced374b8)

Change-Id: Ica51b30fbaa19caef3f5381ab96b51a2b70bf3ed
---
 .../hadoop/hive/cli/control/CoreBeeLineDriver.java |    6 +-
 .../main/java/org/apache/hive/beeline/QFile.java   |   67 ++++++---
 .../apache/hive/beeline/QFileBeeLineClient.java    |  142 ++++++++++++++++----
 .../clientpositive/beeline/smb_mapjoin_11.q.out    |    6 +-
 .../clientpositive/beeline/smb_mapjoin_12.q.out    |    4 +-
 .../clientpositive/beeline/smb_mapjoin_13.q.out    |    8 +-
 6 files changed, 177 insertions(+), 56 deletions(-)

diff --git a/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreBeeLineDriver.java b/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreBeeLineDriver.java
index b44ffbd..66ccd6f 100644
--- a/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreBeeLineDriver.java
+++ b/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreBeeLineDriver.java
@@ -49,7 +49,7 @@
   private final File testDataDirectory;
   private final File testScriptDirectory;
   private boolean overwrite = false;
-  private boolean rewriteSourceTables = true;
+  private boolean useSharedDatabase = false;
   private MiniHS2 miniHS2;
   private QFileClientBuilder clientBuilder;
   private QFileBuilder fileBuilder;
@@ -111,7 +111,7 @@ boolean getBooleanPropertyValue(String name, boolean defaultValue) {
   public void beforeClass() throws Exception {
     overwrite = getBooleanPropertyValue("test.output.overwrite", Boolean.FALSE);
 
-    rewriteSourceTables = getBooleanPropertyValue("test.rewrite.source.tables", Boolean.TRUE);
+    useSharedDatabase = getBooleanPropertyValue("test.beeline.shared.database", Boolean.FALSE);
 
     String beeLineUrl = System.getProperty("test.beeline.url");
     if (StringUtils.isEmpty(beeLineUrl)) {
@@ -132,7 +132,7 @@ public void beforeClass() throws Exception {
         .setLogDirectory(logDirectory)
         .setQueryDirectory(queryDirectory)
         .setResultsDirectory(resultsDirectory)
-        .setRewriteSourceTables(rewriteSourceTables)
+        .setUseSharedDatabase(useSharedDatabase)
         .setComparePortable(comparePortable);
 
     runInfraScript(initScript, new File(logDirectory, "init.beeline"),
diff --git a/itests/util/src/main/java/org/apache/hive/beeline/QFile.java b/itests/util/src/main/java/org/apache/hive/beeline/QFile.java
index 1b0f24c..613fd98 100644
--- a/itests/util/src/main/java/org/apache/hive/beeline/QFile.java
+++ b/itests/util/src/main/java/org/apache/hive/beeline/QFile.java
@@ -71,6 +71,7 @@
   private static final String[] COMMANDS_TO_REMOVE = {"EXPLAIN", "DESCRIBE[\\s\\n]+EXTENDED", "DESCRIBE[\\s\\n]+FORMATTED"};
 
   private String name;
+  private String databaseName;
   private File inputFile;
   private File rawOutputFile;
   private File outputFile;
@@ -81,7 +82,7 @@
   private static RegexFilterSet staticFilterSet = getStaticFilterSet();
   private static RegexFilterSet portableFilterSet = getPortableFilterSet();
   private RegexFilterSet specificFilterSet;
-  private boolean rewriteSourceTables;
+  private boolean useSharedDatabase;
   private Converter converter;
   private boolean comparePortable;
 
@@ -91,6 +92,10 @@ public String getName() {
     return name;
   }
 
+  public String getDatabaseName() {
+    return databaseName;
+  }
+
   public File getInputFile() {
     return inputFile;
   }
@@ -123,6 +128,10 @@ public Converter getConverter() {
     return converter;
   }
 
+  public boolean isUseSharedDatabase() {
+    return useSharedDatabase;
+  }
+
   public String getDebugHint() {
     return String.format(DEBUG_HINT, inputFile, rawOutputFile, outputFile, expectedOutputFile,
         logFile, beforeExecuteLogFile, afterExecuteLogFile,
@@ -130,13 +139,13 @@ public String getDebugHint() {
   }
 
   /**
-   * Filters the sql commands if necessary.
+   * Filters the sql commands if necessary - eg. not using the shared database.
    * @param commands The array of the sql commands before filtering
    * @return The filtered array of the sql command strings
    * @throws IOException File read error
    */
   public String[] filterCommands(String[] commands) throws IOException {
-    if (rewriteSourceTables) {
+    if (!useSharedDatabase) {
       for (int i=0; i<commands.length; i++) {
         if (USE_PATTERN.matcher(commands[i]).matches()) {
           System.err.println(String.format(USE_COMMAND_WARNING, inputFile, commands[i]));
@@ -173,8 +182,8 @@ private String replaceTableNames(String source) {
    */
   private String revertReplaceTableNames(String source) {
     for (String table : srcTables) {
-      source = source.replaceAll("(?is)(\\s+)default\\." + table + "([\\s;\\n\\)])", "$1" + table
-          + "$2");
+      source = source.replaceAll("(?is)(?<!name:?|alias:?)(\\s+)default\\.(" + table
+          + ")([\\s;\\n\\),])", "$1$2$3");
     }
     return source;
   }
@@ -195,18 +204,28 @@ private String sortInputOutput(String source) {
     return source;
   }
 
+  /**
+   * Filters the generated output file
+   * @throws IOException
+   */
   public void filterOutput() throws IOException {
     String output = FileUtils.readFileToString(rawOutputFile, "UTF-8");
     if (comparePortable) {
       output = portableFilterSet.filter(output);
     }
     output = staticFilterSet.filter(specificFilterSet.filter(output));
-    if (rewriteSourceTables) {
+    if (!useSharedDatabase) {
       output = sortInputOutput(revertReplaceTableNames(output));
     }
     FileUtils.writeStringToFile(outputFile, output);
   }
 
+  /**
+   * Compare the filtered file with the expected golden file
+   * @return The comparison data
+   * @throws IOException If there is a problem accessing the golden or generated file
+   * @throws InterruptedException If there is a problem running the diff command
+   */
   public QTestProcessExecResult compareResults() throws IOException, InterruptedException {
     if (!expectedOutputFile.exists()) {
       throw new IOException("Expected results file does not exist: " + expectedOutputFile);
@@ -214,6 +233,10 @@ public QTestProcessExecResult compareResults() throws IOException, InterruptedEx
     return executeDiff();
   }
 
+  /**
+   * Overwrite the golden file with the generated output
+   * @throws IOException If there is a problem accessing the golden or generated file
+   */
   public void overwriteResults() throws IOException {
     FileUtils.copyFile(outputFile, expectedOutputFile);
   }
@@ -313,7 +336,11 @@ private static RegexFilterSet getStaticFilterSet() {
         .addFilter(".*file:.*\n", MASK_PATTERN)
         .addFilter(".*hdfs:.*\n", MASK_PATTERN)
         .addFilter(".*file\\..*\n", MASK_PATTERN)
+        .addFilter(".*Location.*\n", MASK_PATTERN)
+        .addFilter(".*LOCATION '.*\n", MASK_PATTERN)
+        .addFilter(".*Output:.*/data/files/.*\n", MASK_PATTERN)
         .addFilter(".*CreateTime.*\n", MASK_PATTERN)
+        .addFilter(".*last_modified_.*\n", MASK_PATTERN)
         .addFilter(".*transient_lastDdlTime.*\n", MASK_PATTERN)
         .addFilter(".*lastUpdateTime.*\n", MASK_PATTERN)
         .addFilter(".*lastAccessTime.*\n", MASK_PATTERN)
@@ -345,7 +372,7 @@ private static RegexFilterSet getPortableFilterSet() {
     private File queryDirectory;
     private File logDirectory;
     private File resultsDirectory;
-    private boolean rewriteSourceTables;
+    private boolean useSharedDatabase;
     private boolean comparePortable;
 
     public QFileBuilder() {
@@ -366,8 +393,8 @@ public QFileBuilder setResultsDirectory(File resultsDirectory) {
       return this;
     }
 
-    public QFileBuilder setRewriteSourceTables(boolean rewriteSourceTables) {
-      this.rewriteSourceTables = rewriteSourceTables;
+    public QFileBuilder setUseSharedDatabase(boolean useSharedDatabase) {
+      this.useSharedDatabase = useSharedDatabase;
       return this;
     }
 
@@ -379,19 +406,27 @@ public QFileBuilder setComparePortable(boolean compareProtable) {
     public QFile getQFile(String name) throws IOException {
       QFile result = new QFile();
       result.name = name;
+      if (!useSharedDatabase) {
+        result.databaseName = "test_db_" + name.toLowerCase();
+        result.specificFilterSet = new RegexFilterSet()
+            .addFilter("(PREHOOK|POSTHOOK): (Output|Input): database:" + result.databaseName + "\n",
+                "$1: $2: database:default\n")
+            .addFilter("(PREHOOK|POSTHOOK): (Output|Input): " + result.databaseName + "@",
+                "$1: $2: default@")
+            .addFilter("name(:?) " + result.databaseName + "\\.(.*)\n", "name$1 default.$2\n")
+            .addFilter("alias(:?) " + result.databaseName + "\\.(.*)\n", "alias$1 default.$2\n")
+            .addFilter("/" + result.databaseName + ".db/", "/");
+      } else {
+        result.databaseName = "default";
+        result.specificFilterSet = new RegexFilterSet();
+      }
       result.inputFile = new File(queryDirectory, name + ".q");
       result.rawOutputFile = new File(logDirectory, name + ".q.out.raw");
       result.outputFile = new File(logDirectory, name + ".q.out");
       result.logFile = new File(logDirectory, name + ".q.beeline");
       result.beforeExecuteLogFile = new File(logDirectory, name + ".q.beforeExecute.log");
       result.afterExecuteLogFile = new File(logDirectory, name + ".q.afterExecute.log");
-      result.rewriteSourceTables = rewriteSourceTables;
-      result.specificFilterSet = new RegexFilterSet()
-          .addFilter("(PREHOOK|POSTHOOK): (Output|Input): database:" + name + "\n",
-              "$1: $2: database:default\n")
-          .addFilter("(PREHOOK|POSTHOOK): (Output|Input): " + name + "@", "$1: $2: default@")
-          .addFilter("name(:?) " + name + "\\.(.*)\n", "name$1 default.$2\n")
-          .addFilter("/" + name + ".db/", "/");
+      result.useSharedDatabase = useSharedDatabase;
       result.converter = Converter.NONE;
       String input = FileUtils.readFileToString(result.inputFile, "UTF-8");
       if (input.contains("-- SORT_QUERY_RESULTS")) {
diff --git a/itests/util/src/main/java/org/apache/hive/beeline/QFileBeeLineClient.java b/itests/util/src/main/java/org/apache/hive/beeline/QFileBeeLineClient.java
index fa222ff..e4384bc 100644
--- a/itests/util/src/main/java/org/apache/hive/beeline/QFileBeeLineClient.java
+++ b/itests/util/src/main/java/org/apache/hive/beeline/QFileBeeLineClient.java
@@ -18,12 +18,18 @@
 
 package org.apache.hive.beeline;
 
+import org.apache.commons.lang3.ArrayUtils;
+import org.apache.hadoop.hive.ql.QTestUtil;
 import org.apache.hive.beeline.ConvertedOutputFile.Converter;
 
 import java.io.File;
 import java.io.IOException;
 import java.io.PrintStream;
+import java.sql.DatabaseMetaData;
+import java.sql.ResultSet;
 import java.sql.SQLException;
+import java.util.HashSet;
+import java.util.Set;
 
 /**
  * QFile test client using BeeLine. It can be used to submit a list of command strings, or a QFile.
@@ -32,6 +38,26 @@
   private BeeLine beeLine;
   private PrintStream beelineOutputStream;
   private File logFile;
+  private String[] TEST_FIRST_COMMANDS = new String[] {
+    "!set outputformat tsv2",
+    "!set verbose false",
+    "!set silent true",
+    "!set showheader false",
+    "USE default;",
+    "SHOW TABLES;",
+  };
+  private String[] TEST_SET_LOG_COMMANDS = new String[] {
+    "set hive.in.test.short.logs=true;",
+    "set hive.in.test.remove.logs=false;",
+  };
+  private String[] TEST_RESET_COMMANDS = new String[] {
+    "set hive.testing.short.logs=false;",
+    "!set verbose true",
+    "!set silent false",
+    "!set showheader true",
+    "!set outputformat table",
+    "USE default;"
+  };
 
   protected QFileBeeLineClient(String jdbcUrl, String jdbcDriver, String username, String password,
       File log) throws IOException {
@@ -53,6 +79,47 @@ protected QFileBeeLineClient(String jdbcUrl, String jdbcDriver, String username,
         });
   }
 
+  private Set<String> getDatabases() throws SQLException {
+    Set<String> databases = new HashSet<String>();
+
+    DatabaseMetaData metaData = beeLine.getDatabaseMetaData();
+    // Get the databases
+    try (ResultSet schemasResultSet = metaData.getSchemas()) {
+      while (schemasResultSet.next()) {
+        databases.add(schemasResultSet.getString("TABLE_SCHEM"));
+      }
+    }
+    return databases;
+  }
+
+  private Set<String> getTables() throws SQLException {
+    Set<String> tables = new HashSet<String>();
+
+    DatabaseMetaData metaData = beeLine.getDatabaseMetaData();
+    // Get the tables in the default database
+    String[] types = new String[] {"TABLE"};
+    try (ResultSet tablesResultSet = metaData.getTables(null, "default", "%", types)) {
+      while (tablesResultSet.next()) {
+        tables.add(tablesResultSet.getString("TABLE_NAME"));
+      }
+    }
+    return tables;
+  }
+
+  private Set<String> getViews() throws SQLException {
+    Set<String> views = new HashSet<String>();
+
+    DatabaseMetaData metaData = beeLine.getDatabaseMetaData();
+    // Get the tables in the default database
+    String[] types = new String[] {"VIEW"};
+    try (ResultSet tablesResultSet = metaData.getTables(null, "default", "%", types)) {
+      while (tablesResultSet.next()) {
+        views.add(tablesResultSet.getString("TABLE_NAME"));
+      }
+    }
+    return views;
+  }
+
   public void execute(String[] commands, File resultFile, Converter converter)
       throws Exception {
     beeLine.runCommands(
@@ -70,39 +137,58 @@ public void execute(String[] commands, File resultFile, Converter converter)
   }
 
   private void beforeExecute(QFile qFile) throws Exception {
-    execute(
-        new String[] {
-          "!set outputformat tsv2",
-          "!set verbose false",
-          "!set silent true",
-          "!set showheader false",
-          "USE default;",
-          "SHOW TABLES;",
-          "DROP DATABASE IF EXISTS `" + qFile.getName() + "` CASCADE;",
-          "CREATE DATABASE `" + qFile.getName() + "`;",
-          "USE `" + qFile.getName() + "`;",
-          "set hive.in.test.short.logs=true;",
-          "set hive.in.test.remove.logs=false;",
-        },
-        qFile.getBeforeExecuteLogFile(),
-        Converter.NONE);
+    String[] commands = TEST_FIRST_COMMANDS;
+
+    String[] extraCommands;
+    if (qFile.isUseSharedDatabase()) {
+      // If we are using a shared database, then remove not known databases, tables, views.
+
+      Set<String> dropCommands = new HashSet();
+      for(String database : getDatabases()) {
+        if (!database.equals("default")) {
+          dropCommands.add("DROP DATABASE `" + database + "` CASCADE;");
+        }
+      }
+
+      Set<String> srcTables = QTestUtil.getSrcTables();
+      for(String table : getTables()) {
+        if (!srcTables.contains(table)) {
+          dropCommands.add("DROP TABLE `" + table + "` PURGE;");
+        }
+      }
+
+      for(String view : getViews()) {
+        dropCommands.add("DROP VIEW `" + view + "`;");
+      }
+
+      extraCommands = dropCommands.toArray(new String[]{});
+    } else {
+      // If we are using a test specific database, then we just drop the database, and recreate
+      extraCommands = new String[] {
+        "DROP DATABASE IF EXISTS `" + qFile.getDatabaseName() + "` CASCADE;",
+        "CREATE DATABASE `" + qFile.getDatabaseName() + "`;",
+        "USE `" + qFile.getDatabaseName() + "`;"
+      };
+    }
+    commands = ArrayUtils.addAll(commands, extraCommands);
+    commands = ArrayUtils.addAll(commands, TEST_SET_LOG_COMMANDS);
+    execute(commands, qFile.getBeforeExecuteLogFile(), Converter.NONE);
     beeLine.setIsTestMode(true);
   }
 
   private void afterExecute(QFile qFile) throws Exception {
     beeLine.setIsTestMode(false);
-    execute(
-        new String[] {
-          "set hive.in.test.short.logs=false;",
-          "!set verbose true",
-          "!set silent false",
-          "!set showheader true",
-          "!set outputformat table",
-          "USE default;",
-          "DROP DATABASE IF EXISTS `" + qFile.getName() + "` CASCADE;",
-        },
-        qFile.getAfterExecuteLogFile(),
-        Converter.NONE);
+    String[] commands = TEST_RESET_COMMANDS;
+
+    if (!qFile.isUseSharedDatabase()) {
+      // If we are using a test specific database, then we just drop the database
+      String[] extraCommands = new String[] {
+          "DROP DATABASE IF EXISTS `" + qFile.getDatabaseName() + "` CASCADE;"
+      };
+      commands = ArrayUtils.addAll(commands, extraCommands);
+    }
+
+    execute(commands, qFile.getAfterExecuteLogFile(), Converter.NONE);
   }
 
   public void execute(QFile qFile) throws Exception {
diff --git a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_11.q.out b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_11.q.out
index 132ea4e..bcf1e8a 100644
--- a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_11.q.out
+++ b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_11.q.out
@@ -177,7 +177,7 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               bucket_count 16
               bucket_field_name key
               columns key,value
@@ -1891,7 +1891,7 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               bucket_count 16
               bucket_field_name key
               columns key,value
@@ -2016,7 +2016,7 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               bucket_count 16
               bucket_field_name key
               columns key,value
diff --git a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_12.q.out b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_12.q.out
index 8701cd8..289fb25 100644
--- a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_12.q.out
+++ b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_12.q.out
@@ -190,7 +190,7 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               bucket_count 16
               bucket_field_name key
               columns key,value
@@ -446,7 +446,7 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               bucket_count 16
               bucket_field_name key
               columns key,value
diff --git a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_13.q.out b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_13.q.out
index e75d534..dee48a3 100644
--- a/ql/src/test/results/clientpositive/beeline/smb_mapjoin_13.q.out
+++ b/ql/src/test/results/clientpositive/beeline/smb_mapjoin_13.q.out
@@ -152,7 +152,7 @@ STAGE PLANS:
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               SORTBUCKETCOLSPREFIX TRUE
               bucket_count 16
               bucket_field_name key
@@ -174,7 +174,7 @@ STAGE PLANS:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                COLUMN_STATS_ACCURATE true
+                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                 SORTBUCKETCOLSPREFIX TRUE
                 bucket_count 16
                 bucket_field_name key
@@ -370,7 +370,7 @@ STAGE PLANS:
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              COLUMN_STATS_ACCURATE true
+              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
               SORTBUCKETCOLSPREFIX TRUE
               bucket_count 16
               bucket_field_name key
@@ -392,7 +392,7 @@ STAGE PLANS:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                COLUMN_STATS_ACCURATE true
+                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                 SORTBUCKETCOLSPREFIX TRUE
                 bucket_count 16
                 bucket_field_name key
-- 
1.7.9.5

